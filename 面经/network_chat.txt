## Tcp与Udp区别 `203`


TCP和UDP都是互联网传输协议，二者的主要区别在于以下几个方面：

1. 连接与无连接：TCP是面向连接的协议，通信前需要建立连接，通信结束后需要关闭连接；而UDP是无连接的协议，通信时不需要建立连接。UDP的优点是无连接性能快，缺点是不可靠。

2. 可靠性： TCP保证数据传递的可靠性，在数据传输过程中会进行差错控制、流量控制等管理，确保数据完整、正确、有序地到达目的地。而UDP则不保证传输可靠性，数据传输时可能会出现数据丢失、重复、乱序等问题。

3. 数据包大小：TCP在传输过程中需要进行分段，每个数据段大小最大为64KB；而UDP则没有分段的限制，可以一次传输大量的数据包。

4. 速度：TCP相对于UDP会慢一些，因为TCP在传输数据时需要进行确认、重传、流量控制等操作，而UDP则不做这些操作，所以传输速度更快。

5. 应用场景：TCP更适用于数据传输较大、对可靠性要求较高的场景，如网页浏览、文件传输等；而UDP更适用于数据传输较少，响应速度要求高、可靠性要求不高的场景，如DNS请求、在线游戏等。

## Http、Https、两者区别 `197`


Http是Hyper Text Transfer Protocol(超文本传输协议)的缩写，是一种用于在Web浏览器和Web服务器之间传输数据的应用层协议。

Https是HTTP协议的一种安全版本，通过SSL/TLS协议加密HTTP通讯内容，从而保证通讯过程中不被窃听和篡改。

两者的主要区别如下：

1. 数据传输安全性：Http的数据传输是明文传输的，网络上的任何人都可以拦截和查看数据；而Https采用SSL/TLS协议对请求和响应进行加密，保证数据传输的安全性。

2. 传输速度：由于Https需要进行加密和解密的操作，所以在数据传输的过程中，Https比Http要慢。

3. 端口号：Http的默认端口号是80，Https的默认端口号是443。

4. 证书认证：Https通信需要使用证书，每一个网站都需要有自己的数字证书。而Http不需要数字证书。

5. 使用场景：Http主要用于Web开发、数据传输等方面，而Https主要用于保护用户的敏感信息，如银行、电商等领域。

总之，Https相比Http，更加安全可靠，但也更耗费资源和时间成本。

## TCP三次握手过程及状态变化 `150`


TCP三次握手是建立TCP连接的过程，包括客户端和服务器端之间的通讯。三次握手过程分为以下几个状态：

1. CLOSED：初始状态下，客户端和服务器端的连接都是关闭状态。

2. SYN-SEND：当客户端想要建立连接时，它首先发送一个SYN包给服务器端，同时客户端进入SYN-SEND状态，等待服务器端回应。

3. SYN-RECEIVED：服务器端接收到客户端发送的SYN包后，就会发送一个SYN-ACK包作为回应，表示服务器端已经收到了客户端的请求，并且准备好建立连接。此时，服务器端进入SYN-RECEIVED状态。

4. ESTABLISHED：一旦客户端收到了服务器端的SYN-ACK包，它就会发送一个ACK包确认，连接就可以建立起来了。客户端和服务器端都进入ESTABLISHED状态，可以开始传输数据。

5. FIN-WAIT-1：当客户端想要关闭连接时，它会先向服务器端发送一个FIN包，表示客户端已经没有数据需要发送了，并且请求服务器端关闭连接。此时，客户端进入FIN-WAIT-1状态，等待服务器端的回应。

6. CLOSE-WAIT：服务器端接收到客户端发送的FIN包后，它会发送一个ACK包作为回应，并且进入CLOSE-WAIT状态。在这个状态下，服务器端还可以发送数据给客户端。

7. FIN-WAIT-2：当服务器端也想要关闭连接时，它会发送一个FIN包给客户端，并且进入FIN-WAIT-2状态，等待客户端的回应。

8. LAST-ACK：客户端接收到服务器端发送的FIN包后，它会发送一个ACK包作为回应，并且进入LAST-ACK状态。服务器端进入TIME-WAIT状态，等待最后一个ACK包的到来。

9. TIME-WAIT：服务器端处于TIME-WAIT状态的时间是为了确保最后一个ACK包能够到达客户端，从而保证连接被正确地关闭。在这个状态下，服务器端不会发送或接收任何数据。

10. CLOSED：最终，客户端和服务器端都会进入CLOSED状态，TCP连接被关闭。

## 浏览器上输入地址后的整个请求过程 `144`


浏览器输入地址后的整个请求过程如下：

1. DNS解析：浏览器首先向DNS服务器发出域名解析请求，获取域名对应的IP地址。

2. TCP连接：浏览器与服务器建立TCP连接，进行三次握手，确保可靠性。

3. 发送HTTP请求：浏览器向服务器发送HTTP请求，请求中包含请求方式、请求头、请求体等信息。

4. 服务器响应：服务器接收到浏览器发送的请求，根据请求做出相应的处理，并将响应结果返回给浏览器。响应包含状态码、响应头、响应体等信息。

5. 接收文件：浏览器接收到服务器返回的响应结果。如果响应的是HTML页面，浏览器会对页面的格式和内容进行解析，并向服务器请求页面中的其他资源，如图片、视频等。

6. 渲染页面：浏览器将页面的HTML、CSS、JS等文件解析完成后展示给用户。

7. 断开连接：浏览器与服务器断开TCP连接，请求结束。

以上就是浏览器输入地址后的整个请求过程。在此过程中，DNS解析、TCP连接、HTTP请求等环节的优化都会影响网页加载速度和用户体验。

## OSI七层、五层模型，每一层的作用 `136`


OSI七层参考模型是一个开放式的标准化网络架构，将网络协议的通信过程分解为7个不同的层次，每一层都提供一定的服务和处理数据。五层模型是在OSI七层模型基础上进行了简化，将其中的物理层和数据链路层合并成了一层，称为物理链路层，共分为：应用层、传输层、网络层、物理链路层和数据链路层。具体每一层的作用如下：

OSI七层模型：

1.物理层：定义电气和物理接口的规范，如传输介质的类型、传输速率、时序等，将数据转换为能够在物理媒介上传输的数据流。

2.数据链路层：在物理层上建立数据链路并管理其错误，使得数据能以可靠且有序的方式进行传输。

3.网络层：提供数据包的传送服务，并确定所要选择的路线，使数据得以在网络中传输。

4.传输层：向两个应用程序传输所要传输的数据，确保两个应用程序传输的数据不会被丢失和破坏。

5.会话层：通过一定的方式使操作系统和其他应用程序之间建立了特定的连接，以维护网络上的会话。

6.表示层：对数据的格式、代码和加密进行翻译和处理，确保数据可读可用。

7.应用层：为用户提供服务，允许用户访问网络中数据资源，包括文件、服务等。

五层模型：

1.应用层：为用户提供各种应用服务，如电子邮件、文件传输等。

2.传输层：对上层数据进行传输处理，保证数据传输的正确性和可靠性。

3.网络层：确定数据包在网络中的传输路径。

4.物理链路层：管理和控制物理设备，实现二进制数据流的传输。

5.网络接口层（数据链路层）：对数据的处理和传输，提供数据流控制和错误检测功能。

## Tcp三次握手四次挥手及对应的状态 `134`


TCP协议的三次握手和四次挥手是指TCP连接的建立和关闭过程，其目的是在客户端和服务器之间建立可靠的数据传输通道。下面我们来详细了解一下这个过程。

## 三次握手

在TCP连接的建立过程中，客户端与服务器之间要进行三次握手。

1. 客户端向服务器发送一个SYN(同步)标志位的数据包，表示客户端请求建立连接，此时客户端的状态变为“SYN_SENT”。
2. 服务器收到请求后向客户端发送一个ACK(确认)标志位的数据包，并将标志位SYN和ACK都置为1，表示接受连接请求，并发回一个确认消息，此时服务端的状态变为“SYN_RECEIVED”。
3. 最后，客户端向服务器发送一个ACK标志位的数据包，表示连接建立成功，此时客户端的状态变为“ESTABLISHED”，服务器也处于“ESTABLISHED”的状态。

## 四次挥手

TCP连接的关闭过程需要进行四次挥手，具体过程如下：

1. 客户端向服务器发送一个FIN(结束连接)标志位的数据包，表示结束数据传输，但仍可以接收数据，此时客户端的状态变为“FIN_WAIT_1”。
2. 服务器收到请求后向客户端发送一个ACK(确认)标志位的数据包，并将标志位FIN和ACK都置为1，表示接收到客户端的关闭请求，此时服务器的状态变为“CLOSE_WAIT”，等待数据传输完成。
3. 客户端收到服务器的确认消息后，进入“FIN_WAIT_2”状态，等待服务器发送关闭请求。
4. 当服务器的数据传输完成后，向客户端发送一个FIN标志位的数据包，表示可以断开连接，此时服务器的状态为“LAST_ACK”。
5. 客户端收到服务器的关闭请求后，向服务器发送一个ACK标志位的数据包，表示接受关闭请求，此时客户端的状态变为“TIME_WAIT”。
6. 当服务器收到确认消息后，关闭连接，此时服务器的状态变为“CLOSED”，客户端在等待一段时间后，也关闭连接，状态变为“CLOSED”。

综上所述，TCP连接的建立和关闭过程对应的状态如下：

- SYN_SENT：客户端发送连接建立请求。
- SYN_RECEIVED：服务器接受连接建立请求。
- ESTABLISHED：连接建立成功，可以进行数据传输。
- FIN_WAIT_1：客户端发送结束连接请求。
- CLOSE_WAIT：服务器等待数据传输完成。
- FIN_WAIT_2：客户端等待服务器发送结束连接请求。
- LAST_ACK：服务器发送结束连接请求。
- TIME_WAIT：等待时间，以确保所有消息都已经传输完成。
- CLOSED：连接已经关闭。

## Tcp流量控制与拥塞控制 `109`


TCP（Transmission Control Protocol）是一种可靠的传输协议，能够确保数据的可靠传输。在 TCP 协议中，流量控制和拥塞控制是两种不同的机制，其主要区别在控制的范围和对象上。

1. 流量控制

在 TCP 协议中，流量控制是指发送方和接收方之间控制数据流量的机制。流量控制主要是为了避免接收方来不及处理过多的数据而导致数据丢失或者延迟。TCP 协议通过发送窗口来控制流量，发送方会根据接收方的窗口大小来调整自己的发送速率。

例如，如果接收方的窗口大小为 10，那么发送方就不会一次性发送超过 10 个数据包。如果接收方处理完这 10 个数据包后，再通知发送方自己的窗口已经扩大到了 20，发送方就可以继续发送数据了。

2. 拥塞控制

拥塞控制是指控制网络拥塞的机制，在 TCP 协议中主要是为了保证网络的可靠性和稳定性。拥塞控制主要是为了避免过多的数据包同时传输而导致网络拥塞，从而使网络性能降低或者导致数据丢失。

TCP 协议通过拥塞窗口来控制拥塞，发送方的拥塞窗口会根据网络的拥塞程度进行调整。例如，在网络拥塞时，发送方会降低自己的发送速率，调整拥塞窗口，避免继续发送数据导致网络拥塞。

总体来说，流量控制和拥塞控制都是为了确保数据的可靠传输和避免网络拥堵，它们都是TCP协议不可或缺的重要组成部分。

## Tcp如何保证可靠传输 `95`


TCP（传输控制协议）是一种网络协议，用于在计算机网络上保证可靠地传输数据。TCP 采用了以下一些机制来保障可靠传输：

1. 重传机制
当发送方发送的数据在一定的时间内未收到接收方确认信息时，TCP 发送方会自动重传这些数据。

2. 校验和
TCP 在传输过程中会对数据包进行校验和计算，确保数据包的完整性。

3. 流量控制
TCP 接收方通过向发送方发送确认信息(ACK)，告诉发送方已经接收到了数据。当接收方的缓冲区已满时，它将发送一个窗口大小值告诉发送方它能可接收多少数量的数据包。当发送方收到窗口大小值后，它会根据窗口大小来调整发送数据的速度，确保接收方缓冲区不会溢出。

4. 拥塞控制
TCP 通过拥塞控制算法来确保在网络过载的情况下，数据包不会被堵塞或者丢失。如果 TCP 检测到网络中有拥塞出现，它会减小发送数据的速率，以避免网络拥塞，进而直到网络恢复正常。

综上所述，TCP 通过重传机制、校验和、流量控制和拥塞控制等机制来保证数据的可靠传输。

## http协议的几种方法（get、post、delete等） `89`


HTTP协议的几种方法：

1. GET：向指定资源发出“显示”请求，返回资源内容。一般不使用该方法向服务器传递敏感信息，因为参数在URL中可见。

2. POST：向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。参数包含在请求体中，不会在URL中可见。

3. DELETE：请求服务器删除指定的资源。

4. PUT：向指定资源位置上传最新内容，覆盖原始内容。

5. HEAD：获取指定资源的响应头，不返回响应体。该方法常用于检查资源是否存在或已修改。

6. OPTIONS：查询指定资源支持的HTTP请求方法。

7. TRACE：回显服务器收到的请求，主要用于测试或诊断。

其中，GET和POST是最常用的方法，GET用于获取资源，POST用于提交资源。DELETE和PUT一般用于RESTful风格的API开发。HEAD和OPTIONS大多用于服务器的自检和诊断。TRACE方法理论上会暴露服务器和客户端之间的通信细节，通常禁用。

## Https的加密流程 `80`


HTTPS是基于传输层安全协议（TLS）的一种安全的 HTTP 协议。它通过使用 TLS/SSL 协议来保护 Web 服务器和客户端之间的数据传输，确保数据传输的安全性和完整性。

HTTPS的加密流程如下：

1. 客户端向服务端发起 HTTPS 请求。
2. 服务端生成一份数字证书，其中包含公钥和相关的信息。
3. 服务端将生成的数字证书发送回客户端。
4. 客户端收到数字证书，检查证书合法性，如果证书有效且可信，客户端生成一个随机的加密密钥（session key）。
5. 客户端使用服务端的公钥来加密生成的session key，并将加密后的session key发送回服务器。
6. 服务端使用自己的私钥来解密收到的session key，从而得到客户端的session key。
7. 服务端使用客户端的session key来进行数据加密，并将加密后的数据发送回客户端。
8. 客户端使用自己的session key来对收到的数据进行解密，并对数据进行处理后呈现给用户。

这样通过 HTTPS 传输的数据都是经过加密的，且只有服务器和客户端知道加密和解密的密钥，其他人是无法获得明文数据的，从而保证了数据传输的安全性。

## http缓存（强缓存和协商缓存） `77`


HTTP缓存是指在客户端或代理服务器上存储经常使用的web资源，以便稍后可以更快地访问该资源。 

HTTP缓存有两种类型: 强缓存和协商缓存。

1. 强缓存

当客户端发起一个必须交互的请求时，将会获取一份资源的完整副本，并在本地进行缓存。接下来，如果客户端再次请求这个资源，浏览器会先检查本地缓存是否存在该资源的副本，如果存在且未过期，则直接使用该缓存，不再发起请求。

强缓存的过期时间可以通过Expires和Cache-Control两个响应头来设置，其中Expires是一个时间戳，表示缓存过期的具体时间，而Cache-Control则是一个相对时间，可以通过max-age来接收时间(单位是秒)。如果Expires和Cache-Control同时存在，Cache-Control优先级更高。

2. 协商缓存

当缓存资源未超时或已过期，浏览器通过缓存协商机制来判断是否需要更新缓存。由于强缓存的缓存时间是由服务器提供的，因此使用协商缓存机制可以解决一些问题，例如服务器更新文件时，原始的缓存会使客户端看到旧的数据。在协商缓存的过程中，浏览器会向服务器发送请求，通过比较修改时间等信息确定文件是否已经被更新，如果文件已经被更新，则获取新版本。如果未更新，则使用已缓存的副本。

协商缓存机制可以通过两个头部来实现：Last-Modified和ETag。 Last-Modified是文件的上次修改时间，而ETag是文件的版本号。服务器会将这些信息传递给浏览器，下一次请求时浏览器会带上If-Modified-Since和If-None-Match头，表示请求资源的版本号和上一次修改时间，如果服务器收到请求，判断文件未被修改，则返回304 Not Modified响应来让浏览器继续使用缓存文件。

总之，强缓存使用client的本地缓存，减少网络请求，协商缓存通过与server的交互，确认请求资源是否更新，按需更新，充分利用缓存。不同情况下可以选择不同的方式，根据实际情况来选择怎么设置HTTP缓存。

## Http2.0、Http1.1、Http1.0有哪些特性 `73`


HTTP是一种应用协议，常用的有HTTP1.0，HTTP1.1和HTTP2.0。各版本的HTTP在特性上存在一些差异，下面是它们的主要特点：

1. HTTP1.0

HTTP1.0是最早的HTTP协议版本，具有以下特点:

- 无状态：HTTP1.0协议是无状态协议，无法保存之前请求的信息，每个请求都是独立的。

- 每次请求连接：HTTP1.0协议每次请求都需要建立连接，请求响应之后立即断开连接。

- 无需压缩：HTTP1.0不支持内容压缩，这样会导致传输的数据比较大，影响性能。

2. HTTP1.1

HTTP1.1是在HTTP1.0的基础上发展起来的，主要包括以下特点:

- 持续连接：HTTP1.1支持持久连接技术，即同一个连接可以在多个请求响应之间持续保持。

- 分块传输：支持分块传输，可以先传输一个头部，而不是等待整个文档下载完成之后再进行传输。

- 内容压缩：HTTP1.1支持内容压缩技术，可以有效地减少传输的数据量，提高传输效率。

- Host 请求头：HTTP1.1支持Host请求头，可以在一个IP上运行多个Web站点。

3. HTTP2.0

HTTP2.0是HTTP1.1的升级版，引入了一些新的特点：

- 多路复用：HTTP2.0支持多路复用技术，可以通过一个连接同时发送多个请求和响应。

- 二进制协议：HTTP2.0采用二进制协议（HTTP1.x采用的是文本协议），可以有效减少传输数据量。

- 服务器推送：HTTP2.0支持服务器推送技术，服务器可以在客户端请求页面之前将一些资源推送给客户端，提高加载速度。

- 请求优先级：HTTP2.0支持请求优先级，客户端可以指定请求的优先级，可以更快的响应用户请求。

以上是HTTP1.0、HTTP1.1、HTTP2.0的主要特点，不同版本的HTTP协议在效率、速度、功能等方面都有较大的差别。开发者在选择HTTP协议版本的时候，需要根据实际情况进行评估，确定最适合自己应用的协议版本。

## TCP为什么要三次握手 `72`


TCP协议是面向连接的协议，要在正式数据传送前，必须要通过三次握手建立连接。三次握手的过程如下：

1. 客户端发送一个SYN请求报文给服务器，SYN(同步序列编号)表示序列编号同步请求。客户端发送这个报文时，将随机产生一个初始的序列号seq=J，并将SYN标志位置为1，然后等待服务器的确认。

2. 服务器收到客户端的SYN请求报文后会回复两个报文。第一个报文中ACK确认从客户端发送的SYN请求报文；第二个报文中SYN标志位置为1，也产生一个序列号seq=K。因为服务器也要向客户端发送一个SYN请求，所以需要确认客户端的SYN请求，即需要将ACK标志置为1，以告诉客户端自己已经收到了他的SYN请求，可以进行下一步操作。同时，服务器也会将自己的SYN请求发给客户端，表明它也要建立一条TCP连接，并将其初始化序列号seq=K+1。

3. 客户端收到服务器回发的确认后，客户端发送最后一个确认报文，其中ACK标志置为1，并将序列号设置为ACK=K+1。由此完成了TCP连接的建立。服务器收到这个确认后，也可以开始发送真正的数据了。

三次握手的目的在于保证服务器与客户端的状态同步，以确保双方已准备好进行TCP通信。如果只有两次握手，则可能会出现以下的情况：

1. 第一次握手时，客户端发送了SYN请求，但是由于某种原因，这个请求在传输过程中被丢弃了。

2. 服务器接收到客户端的SYN请求后，发送了确认请求，但是这个确认请求在传输过程中也被丢弃了。

3. 这时候，客户端并不知道服务器已经准备好，以为请求没有被接收到，再次发送请求。

4. 服务器收到第二个SYN请求时，会认为这是客户端重新发送的连接请求，在确认连接后，开始发送数据。

5. 由于之前客户端发送的第一个SYN请求被丢弃了，客户端并不知道服务器已经准备好，所以不会发送ACK确认报文。

6. 这时候，服务器一直在发送数据，但是客户端并不理会，因为它并没有收到数据，也没有发送确认请求。

7. 服务器会认为客户端已经断开连接，于是关闭连接。

8. 客户端收到服务器的关闭请求后，认为是连接出现了问题，关闭连接。

这样就会造成资源的浪费，而三次握手可以满足TCP协议的要求，避免出现上述的问题。

## Get与Post的区别 `72`


HTTP请求中，Get和Post方法都是常用的两种请求方法。

1. GET请求：

- 作用：一般用于请求数据或者查询数据，获取远程服务器上的某个资源。
- 特点：
   - 请求参数一般是在URL后面，以key-value形式出现，使用'?'分割。
   - 请求参数长度有限制，一般不超过2KB，因此不适合上传大量数据。
   - 结果可被缓存，所以速度较快。
   - 对于安全性要求高，以及需要更改服务器上的数据时，不安全。

2. POST请求：

- 作用：用来向远程服务器提交数据，通常用于新增或者修改数据。
- 特点：
   - 请求参数放在请求体中，因此数据量大，能承载更多数据。
   - 请求参数的大小没有限制。
   - 结果不能被缓存，因此速度相对较慢。
   - POST请求是安全的，因为请求的数据不会出现在URL中，而是放在请求体中。

综上所述：

GET和POST请求的最大区别在于传参的方式和数据量的大小，而其他一些特点则是由这两个特点所决定。由于每个场景有不同的需求，因此在不同的场景下，我们可以选择使用GET或者POST请求。

## 说一说对跨域的了解 `65`


跨域指的是在浏览器中向不同源(协议、域名、端口号均不同)的服务器发起请求。浏览器出于安全方面的考虑，会限制脚本跨域访问数据。

常见的解决跨域的方式:
1. JSONP：通过动态插入 script 标签，指定 src 为跨域请求的 url，服务器返回一段函数调用代码，客户端执行该函数即可；不支持 POST 请求。
2. CORS：服务端在响应头中增加 Access-Control-Allow-Origin 字段。
3. 代理：将跨域请求转发到同源地址，再由该地址发起请求。

实际开发中，跨域问题经常会遇到。了解一些跨域知识是很有必要的。

## TCP四次挥手过程及状态变化 `61`


TCP (Transmission Control Protocol) 是一种可靠的、面向连接的协议，用于在网络中传输数据。在TCP连接的关闭过程中，客户端和服务器需要进行四次挥手，以确保数据传输的完整性和可靠性。四次挥手的过程如下：

1. 客户端发送 FIN 报文段：客户端在完成数据传送后，向服务器发送一个 FIN 报文段，表示数据已经传输完成，请求关闭连接。

2. 服务器发送 ACK 报文段：服务器收到客户端发送的 FIN 报文段后，发送 ACK 报文段，表示收到了客户端的请求，可以关闭连接。

3. 服务器发送 FIN 报文段：服务器在完成数据传送后，向客户端发送 FIN 报文段，表示服务器已经完成数据发送，并请求关闭连接。

4. 客户端发送 ACK 报文段：客户端收到服务器发送的 FIN 报文段后，发送 ACK 报文段，表示收到了服务器的请求，可以关闭连接。

在四次挥手的过程中，客户端和服务器的连接状态会有所变化。初始状态为 ESTABLISHED (已建立) 状态，四次挥手后，连接状态变为 CLOSED (已关闭) 状态。具体变化如下：

客户端：

- 初始状态：ESTABLISHED

- 发送 FIN 报文段后，等待服务器的确认：FIN_WAIT_1

- 收到服务器的确认后，等待服务器的 FIN 报文段：FIN_WAIT_2

- 收到服务器的 FIN 报文段后，发送确认报文段：TIME_WAIT

- 收到服务器的确认报文段后，连接关闭：CLOSED

服务器：

- 初始状态：ESTABLISHED

- 收到客户端发送的 FIN 报文段后，发送确认报文段：CLOSE_WAIT

- 发送 FIN 报文段后，等待客户端的确认：LAST_ACK

- 收到客户端的确认报文段后，连接关闭：CLOSED

总之，由于 TCP 协议具有可靠性和面向连接性，因此在四次挥手的过程中，需要确保数据的传输完整性和可靠性，以确保连接的正常关闭。

## DNS工作原理 `57`


DNS（Domain Name System），即域名系统，是互联网中负责域名解析的系统。

当我们在浏览器中打开一个网址时，首先会进行 DNS 解析，将域名转换为 IP 地址，以便浏览器能够正确访问网站。

DNS 解析的过程如下：

1.首先，浏览器会检查缓存中是否已有该域名对应的 IP 地址，如果有则直接使用。

2.如果没有，浏览器会访问本地 DNS 服务器，查看是否有该域名对应的 IP 地址。如果有，则会返回给浏览器，并将结果缓存在本地 DNS 缓存中。

3.如果本地 DNS 服务器中没有该域名对应的 IP 地址，则会向 DNS 根服务器发送请求。DNS 根服务器并不直接返回结果，而是告诉本地 DNS 服务器需要查询哪个顶级域（比如.com、.cn等）的 DNS 服务器。

4.本地 DNS 服务器向顶级域 DNS 服务器发送请求，询问该域名对应的 IP 地址。

5.顶级域 DNS 服务器向本地 DNS 服务器返回下一级 DNS 服务器地址。也就是告诉本地 DNS 服务器应该去哪个二级域名 DNS 服务器查询该域名的 IP 地址。

6.本地 DNS 服务器向下一级 DNS 服务器发送请求，查找该域名对应的 IP 地址，并将结果返回给浏览器。同时，结果也会缓存在本地 DNS 服务器中，以便下次查询时直接使用。

总之，DNS 解析基于层级分布式的查询体系，通过逐层查询最终查找到域名对应的 IP 地址。

## Cookie与Session原理与区别 `51`


Cookie 和 Session 都是用来在 Web 应用程序中记录用户状态的常用技术。Cookie 和 Session 之间的区别主要体现在这两个技术是如何存储和跟踪用户会话的方式。

Cookie：

Cookie 实际上是一段文本信息，该信息由服务器通过 HTTP 协议发送给浏览器，每次浏览器向服务器发出请求时，这些信息也将随请求一同发送给服务器。这样就可以让服务器识别每个用户，根据用户的需求返回不同的响应。一般来说，Cookie 的作用是保存用户的登录状态，记住用户喜欢的设置（如显示语言和字体大小等），并且可以追踪用户的行踪记录和点击流量。

Session：

Session 是基于 Cookie 实现的一种管理用户状态和跟踪信息的技术。Session 基本上是一个用于存储用户特定数据的服务器端数据结构。当用户在 Web 应用程序中进行登录时，服务器可能会创建一个 Session 对象来唯一标识该用户，并在该 Session 对象中存储用户的会话信息。服务器会随后将一个包含 Session ID 的 Cookie 发送到用户的浏览器，该 Cookie 允许浏览器将该 ID 相关联并在随后的请求中将该 ID 发送回服务器。此后，服务器将使用该 ID 来检索 Session 对象，并将该对象用于存储用户在 Web 应用程序中执行的所有操作。

区别：

Cookie 保存在客户端，而 Session 保存在服务器端。

Cookie 对浏览器中存储的数据量存在限制，而 Session 不会受到这种限制。

Cookie 对网络传输和身份验证安全性可能存在隐患，因为 Cookie 中包含的信息是明文传输的。 Session 利用服务器端涉及到的保密信息（如私钥、密码哈希等）来加强安全性。

总的来说，Cookie 是处理客户端状态的一种常用技术，而 Session 则是用来管理和跟踪用户的会话状态的一种技术，虽然两者都用于记录用户状态，但主要区别在于存储位置、数据容量大小和传输安全性。

## Http状态码 `51`


HTTP状态码是服务器向客户端返回的表示请求状态的三位数字编号。它们被包含在HTTP响应消息头中，以通知浏览器或其他客户端应该采取哪些操作。

常见的HTTP状态码及其含义如下：

1xx（信息类）：表示成功接收请求，需要继续处理。

2xx（成功）：表示成功接收请求并处理，通常表示请求被正常处理；

- 200 OK：表示请求已成功，请求所希望的响应头或数据可以在消息体中找到。
- 201 Created：表示请求已经被成功处理，并创建了一个新的资源。
- 204 No Content：表示请求已成功，但响应报文不含实体的主体部分（即没有返回任何数据）。

3xx（重定向）：表示请求需要进一步操作，以完成请求。

- 301 Moved Permanently：请求的网页已永久移动到新位置。
- 302 Found（或者Moved Temporarily）：请求的网页已暂时移动到新位置。
- 304 Not Modified：自从上次请求后，请求的网页未修改过。因此，服务器返回此响应时，不会返回网页内容。

4xx（客户端错误）：表示客户端在请求过程中发生了错误。

- 400 Bad Request：请求中存在语法问题，服务器无法理解。
- 401 Unauthorized：表示请求需要身份验证。
- 404 Not Found：表示请求失败，请求的资源未找到。

5xx（服务器错误）：表示服务器在处理请求时发生了错误。

- 500 Internal Server Error：表示服务器在执行请求时遇到了错误。
- 503 Service Unavailable：表示服务器当前无法处理请求，可能是由于过载或维护。

以上就是常见的HTTP状态码及其含义。当我们在开发中遇到HTTP状态码时，应该根据状态码的含义分析原因，并采取相应的措施处理。

## 四次挥手timewait的作用 `50`
四次挥手指的是TCP连接的关闭过程，其中timewait是其中一个状态，在完成四次挥手后，客户端会进入timewait状态。它的主要作用有以下几点：

1. 确保最后一个ACK能够被接收：在TCP的连接关闭过程中，如果客户端最后一段ACK发送过去后立即关闭连接，而服务端没有及时接收到这个ACK，那么服务端可能会认为数据传输没有完全完成，而重新发送FIN包，进而客户端要再重复四次挥手的过程。因此，为了确保服务端能够接收到最后一个ACK，客户端需要在timewait状态等待一段时间（通常是2MSL，MSL是报文最大生存时间，通常为30秒），这段时间内不会发送或接收任何数据。

2. 防止"旧连接"受到干扰：在timewait状态下，客户端不会接受属于"旧连接"的任何数据段，以防该数据段用于干扰新连接。

3. 确保不产生错误的连接：在链接关闭后，客户端仍有时间收到服务端发送的ACK包。如果新的连接使用与旧连接相同的IP地址和端口号，则可能会收到错误的数据，因此timewait握手状态可用于确认不存在旧的连接。

总结来说，timewait状态的作用是确保连接的完整性、安全性和稳定性，防止数据错误和干扰，并为下一次连接奠定良好的基础。

## 同源策略以及解决方案 `48`


同源策略（Same-Origin Policy, SOP）是一种安全策略，它是浏览器中的一个重要保护机制，属于Web安全的基础。同源策略是指，浏览器允许一个页面的脚本只能访问来自同一站点的窗口和文档的属性，不允许脚本跨域进行访问，这样在一定程度上可以避免了跨站点脚本攻击（XSS）、跨站点请求伪造（CSRF）等安全问题。

具体来说，同源策略的限制如下：

1. 域名相同
2. 协议相同（HTTP/HTTPS）
3. 端口号相同

解决方案：

1. JSONP : JSON with Padding 
JSONP 是一种实现跨域请求的方法，利用 JSON 数据具有可执行性的特点实现的。在客户端动态生成 <script> 标签，同时指定回调函数名，并要求服务器在返回数据时将数据 wrapped 在该函数调用中，从而实现跨域请求的目的。

2. CORS : Cross-Origin Resource Sharing 
CORS（Cross-Origin Resource Sharing）是一种通过添加请求头来实现跨域访问的标准。浏览器会检查响应头是否包括 Access-Control-Allow-Origin 字段，若包括则根据其值（Origin/ *） 来确定是否允许跨域请求。

3. 代理(proxy)方式
将数据请求转发到自己的服务器上，在服务器上请求数据，然后再将数据返回给本地服务器，再将请求结果返回给客户端。这样，客户端就看不到自己向其他域名的服务器进行请求，实现了跨域访问。

4. postMessage方法 
postMessage 方法是 HTML5 新增的一种跨文档通信机制。它提供了一个安全的跨域访问方案，可以在不同的窗口、甚至不同的文档和不同的站点间传递消息，而且不受同源策略的限制。在一个页面中使用 postMessage 发送消息，另外一个页面中使用 onmessage 事件来接收这个消息。

## Http响应状态码 `40`


HTTP响应状态码是在客户端发起请求后，服务器响应客户端的结果之一。常见的HTTP响应状态码有以下几种：

1xx（信息类）：表示请求已经被服务器接收，继续处理中。

2xx（成功类）：表示服务器已经成功处理请求，常见的有：

- 200 OK：请求成功
- 201 Created：服务器已成功创建资源
- 204 No Content：服务器成功处理了请求，但没有返回任何内容

3xx（重定向类）：表示需要客户端采取进一步操作才能完成请求，常见的有：

- 301 Moved Permanently：资源被永久移动到新位置
- 302 Found：资源被临时移动到新位置
- 304 Not Modified：客户端可以使用缓存的版本

4xx（客户端错误类）：表示客户端请求有误，常见的有：

- 400 Bad Request：请求无法被服务器理解
- 401 Unauthorized：请求未经授权
- 403 Forbidden：服务器拒绝请求
- 404 Not Found：请求资源不存在

5xx（服务器错误类）：表示服务器处理请求出错，常见的有：

- 500 Internal Server Error：服务器内部错误
- 502 Bad Gateway：网关错误
- 503 Service Unavailable：服务不可用

当我们在使用HTTP协议访问网站时，如果得到了服务器返回的状态码，我们就可以根据状态码来判断请求是否成功。如果请求失败，我们就可以根据不同的状态码找到失败原因，进一步优化我们的应用程序。

## 常见网络攻击类型 怎么防范xsrf `37`


常见的网络攻击类型包括：DDoS攻击、SQL注入攻击、跨站脚本攻击（XSS）、跨站请求伪造（CSRF）、中间人攻击、网络钓鱼攻击等。其中，XSRF攻击是一种常见的Web安全漏洞，攻击者通过伪造用户的请求，迫使用户提交非本意的请求，导致一系列问题，包括信息泄漏、数据篡改等。

要防范XSRF攻击，可以采取以下措施：

1. 验证Referer：Referer是HTTP请求头中的一个字段，标识了当前请求来自哪个页面。可以通过验证Referer值，确定请求是否来自同一域名下的页面，以防止XSRF攻击。

2. 使用token：在每个表单中添加额外一个token值，验证提交的表单请求是否合法，从而防范XSRF攻击。

3. 限制cookie访问：对于敏感操作，如资金转账、修改密码等，可以限制cookie的访问范围，只允许特定的页面进行访问。

4. 采用验证码：在重要的操作中添加验证码，防止机器人恶意攻击。

5. 禁止使用GET方式提交表单：GET方式提交表单可以被攻击者轻松地篡改和伪造，而POST方式提交表单可以让攻击者难以发动攻击。因此，可以采用POST方式提交表单，以增加防范XSRF攻击的难度。

总之，要防范XSRF攻击，需要重视Web安全，了解攻击技术，并采取合适的技术手段进行防御。

## Tcp/ip的四层协议 `35`


TCP/IP协议是计算机网络通信的基础协议。它是由互联网工程任务组（Internet Engineering Task Force, IETF）开发的一组网络协议。TCP/IP协议族里有四个层次，每一层都有相应的协议和功能，下面我们来介绍一下四层协议。

1. 应用层（Application Layer）

应用层协议是TCP/IP协议族中最高层的协议，其目的是为应用程序提供通用数据交换服务。常见的应用层协议包括HTTP、FTP、DNS、SMTP、POP3等。应用层协议通过TCP或UDP协议与传输层进行通信。

2. 传输层（Transport Layer）

传输层协议主要解决两个问题：可靠地传输数据和定义传输数据的端口号。传输层协议有TCP和UDP两种。TCP协议提供面向连接、可靠的服务，确保数据包的完整性和有序性。UDP协议则是面向无连接的服务，尽最大努力传输数据包，不提供错误检测和纠错机制。

3. 网络层（Network Layer）

网络层协议主要负责数据的路由与转发及网际互连。网络层的主要协议就是IP协议。IP协议是一种无连接、不可靠的协议，它负责将数据包从源地址传递到目的地址，通过缩小路由器的选择范围，最终实现数据的传输。此外，还有ICMP协议，用于网络测试和故障排除。

4. 数据链路层（Data Link Layer）

数据链路层协议负责将数据包从一个网络节点传输到另一个网络节点，这些网络节点可以是相邻的设备，比如交换机和网卡。数据链路层协议定义了如何将数据包封装为帧，以及如何访问物理介质来传输数据。常见的数据链路层协议包括以太网、ATM、PPP等。

## TCP为什么要四次挥手 `34`


TCP是一种面向连接的传输协议，为保证数据能够稳定传输，在连接的生命周期中需要进行连接的建立和连接的释放。而在TCP连接的释放过程中，TCP采用了四次挥手的方式来保证连接的正常关闭，其原因有以下两点：

1. TCP连接是全双工的，数据的传输是双向的，因此在关闭连接时需要双方都能够知道对方已经准备好关闭连接。第一次挥手是由客户端发送FIN报文，表示客户端不再发送数据，但是仍然可以接收数据，此时服务端需要确认收到此报文，表示准备好关闭输出流，并发送ACK报文响应客户端。第二次挥手是服务端发送FIN报文，表示服务端不再发送数据，但是仍然可以接收数据，此时客户端需要确认收到此报文，并发送ACK响应服务端，表示准备好关闭连接。第三次挥手是客户端发送FIN报文，表示客户端关闭输出流，此时服务端需要确认收到此报文，表示客户端已经关闭输出流，并发送ACK响应客户端，表示服务端已经准备好关闭连接。最后一次挥手是服务端发送ACK报文，表示收到客户端关闭输出流的通知，服务端关闭连接。

2. 在TCP连接中，可能存在未发送完毕的数据包，如果直接关闭连接，可能会丢失未发送完毕的数据包，导致数据的不完整。因此，TCP连接的关闭需要经历四次挥手的过程，保证双方都能够知道对方是否存在未发送完毕的数据包，从而确保数据的完整性。

综上所述，TCP采用四次挥手的方式来保证连接的正常关闭，避免数据丢失或不完整，保证数据能够正常传输。

## TCP滑动窗口的作用 `29`
TCP滑动窗口是一种流量控制机制，用于控制数据在网络中的传输速率。TCP协议在发送数据时，将数据分成一个个报文段，并为每个报文段附加一个序号。这些序号代表了数据在整个数据流中的位置。

滑动窗口指定了发送方和接收方在任意时刻所能发送或接收的数据量大小。这个窗口的大小是通过TCP连接的双方互相协商得到的。发送方将数据段连续地编上序号，并依次发送，接收方根据接收到的序号对报文段进行排序，判断是否丢失，从而决定是否发送ACK确认收到的数据。

TCP滑动窗口的作用有以下几点：

1. 控制数据的流量：TCP滑动窗口机制通过控制发送方和接收方的发送速率来避免网络拥塞，确保数据的安全传输。

2. 优化数据传输效率：TCP滑动窗口机制可以根据带宽、延迟等因素来调整数据发送的速率，以最大限度地利用网络带宽，提高数据传输效率。

3. 处理网络状况差的情况：网络状况不好时，TCP滑动窗口的机制可以适当降低发送速率，以避免数据包的丢失和重传。同时，TCP滑动窗口可以及时地反馈给发送方数据是否有丢失，从而便于后续处理。

总之，TCP滑动窗口是一个非常重要的机制，能够保证TCP连接的稳定性和可靠性，同时提高网络传输效率，对于网络通信体系的性能很是关键。

## Http请求、响应的报文格式 `29`


HTTP（Hypertext Transfer Protocol）是用于传输 Web 内容的应用协议。HTTP 协议使用了两种报文：请求报文和响应报文，下面分别介绍。

HTTP 请求报文格式：
```
HTTP Method URI Protocol/Version
Header name: Header value
Header name: Header value
…
Header name: Header value

Request body
```

- HTTP Method：请求方法（GET，POST，DELETE 等）。
- URI：请求的资源路径。例如，`http://example.com/index.html` 的请求报文中，URI 为 `/index.html`。
- Protocol/Version：协议和版本号。通常为 `HTTP/1.1` 或者 `HTTP/2`。
- Header name: Header value：请求头部信息，格式为“Header 名称: Header 值”。常见的 Header 包括 `User-Agent`，`Referer`，`Accept-Language` 等。
- Request body：请求报文主体，不是必须存在的，通常用于 POST 方法提交数据。

HTTP 响应报文格式：
```
Protocol/Version Status code Reason phrase
Header name: Header value
Header name: Header value
…
Header name: Header value

Response body
```

- Protocol/Version：协议和版本号。通常为 `HTTP/1.1` 或者 `HTTP/2`。
- Status code：状态码，3位的数字，表示服务器对请求的处理结果。
- Reason phrase：状态码对应的文本提示，可有可无。
- Header name: Header value：响应头，格式为“Header 名称: Header 值”。常见的 Header 包括 `Content-Type`，`Content-Length`，`Server` 等。
- Response body：响应报文主体，通常包含所请求资源的内容。例如，访问网页时返回的就是 HTML 代码。

## TCP为什么粘包？如何处理 `25`


TCP（Transmission Control Protocol）协议粘包是因为它是基于流（Stream）传输的，当发送的数据没有固定的长度，也没有确定的结束标志时，就会发生粘包现象。

TCP协议中，为了提高传输效率和减少传输次数，TCP发送端会将多个数据包合并成一个TCP数据段进行发送，而在接收端，TCP会将接收到的数据缓存在接收缓冲区中，等待应用程序进行读取。因此，在应用程序没有及时处理缓冲区中的数据时，多个TCP数据段就会被合并在一起，从而产生了粘包现象。

一般解决TCP粘包问题的方法有以下几种：

1. 消息定长：在应用层协议中，规定应用层数据的长度，然后在传输的时候就不会发生粘包现象。但是这种方法会浪费空间，因为不是所有的消息都是一样的长度。

2. 特殊字符分割：在数据包中添加特殊的结束符或分隔符，如换行符或制表符等。接收方在接收到数据时，通过分隔符来判断消息的边界。但是这种方法有可能会被攻击者利用来进行注入攻击。

3. 在消息头中添加消息长度信息：在消息头中添加一个表示消息长度的字段，接收方接收到消息后，先读取消息头中的长度字段，然后根据消息长度来接收完整的消息。但是这种方法比其他方法更加复杂。

4. 利用第三方协议：如Netty中提供的LengthFieldBasedFrameDecoder解码器，可以自动处理TCP粘包和拆包问题。这种方法比较简单，但是需要额外引入第三方包。

总结起来，在使用TCP协议传输数据时，应尽量避免出现粘包问题，可以选择合适的数据传输协议或者使用第三方组件来解决，以确保数据的完整性和正确性。

## 对称加密与非对称加密的关系 `25`


对称加密和非对称加密都是加密算法中常用的两种方式。

对称加密是指加密和解密使用同一个密钥的加密方式。加密过程中使用的密钥和解密过程中使用的密钥是相同的。对称加密算法的优点是加解密速度快，但缺点是密钥不易管理和分配。

非对称加密是指加密和解密使用不同密钥的加密方式。非对称加密算法包括两个密钥，分别是公钥和私钥。加密用公钥，解密用私钥。非对称加密的优点是密钥管理方便，缺点是加解密速度较慢。

对称加密和非对称加密的关系在于非对称加密算法的公钥和私钥的传输需要使用对称加密方式，以保证密钥传输的安全性。在传输公钥和私钥之前，需要使用对称加密算法对密钥进行加密，加密后传输给接收方，然后接收方使用对称加密算法对密钥进行解密，获得公钥或私钥。这样就可以确保非对称加密算法的安全性和完整性。

## 如何设计可靠的UDP `20`


UDP是一种无连接的传输协议，它虽然在数据传输上有着很高的效率，但是它也存在丢包、乱序、重复等问题。因此，在设计UDP时，需要考虑如何解决这些问题，提高UDP的可靠性。

以下是一些可靠的UDP设计方法：

1. 序列号与确认机制：在每个UDP数据包中添加一个序列号，在接收方收到数据包后，向发送方发送确认消息，告诉发送方已经接收到了序列号为n的数据包。如果发送方在一定时间内没有收到确认消息，就会重新发送数据包。

2. 重传机制：在发送方发送数据包后，如果一定时间内没有收到接收方的确认消息，就会重新发送这个数据包。为了防止接收方收到重复的数据包，数据包中可以添加一个时间戳。接收方在收到数据包时，如果发现这个数据包的时间戳比上一次接收到的时间戳还要小，就会丢弃这个数据包。

3. 拥塞控制：为了避免网络拥塞，可以在发送方设置一个发送窗口大小。发送窗口大小表示一次可以发送多少个数据包。如果接收方收到的数据包太多，就会向发送方发送一个拥塞消息，告诉发送方需要降低发送窗口大小。

4. FEC纠错码：Forward Error Correction (FEC)是一种纠错码技术，它可以在数据包中添加一些冗余信息，使得接收方可以通过这些冗余信息计算出原始数据，从而避免数据丢失和重复。

总之，设计可靠的UDP需要考虑多方面的因素，如数据包的序列号，确认机制，重传机制，拥塞控制，FEC纠错码等。只有综合考虑这些因素，才能让UDP在可靠性和效率上达到一个平衡。

## Http header(头)的内容 `18`


HTTP头是指在浏览器和Web服务器之间进行通信时，用于传输信息的一种结构化数据。HTTP头信息由字段名和对应的值组成。常见的HTTP头包括：

1. User-Agent：浏览器或者客户端的标识字符串；
2. Accept：客户端所能接收的数据类型；
3. Accept-Encoding：客户端所能接收的数据压缩类型；
4. Accept-Language：客户端所希望得到的语言版本；
5. Connection：客户端想采用的连接方式；
6. Host：客户端所要访问的域名或IP地址；
7. Referer：表示浏览器是从哪个地址链接到当前页面的；
8. Cookie：保存在客户端的标识信息，用于维持用户的登录状态等；
9. Cache-Control：控制缓存数据的行为；
10. Content-Type：指定客户端提交数据的类型。

HTTP头信息可以通过浏览器的开发者工具进行查看，对于网站开发和接口调试非常有帮助。

## Http与Tcp的关系与区别 `14`
HTTP（Hypertext Transfer Protocol）和TCP（Transmission Control Protocol）是两个独立的协议，分别在不同的OSI模型层中运行，但它们是相互依赖的。

HTTP协议是应用层协议，用于在网络中传输超文本信息。HTTP在传输数据时，通常借助TCP协议来传输数据。

TCP协议是传输层协议，它给应用层提供面向连接的数据传输服务。TCP主要职责是分割数据、发送应答、流控制、网络拥塞控制等。

在一个HTTP请求中，首先要建立TCP连接，然后客户端发送请求给服务器，服务器接收请求并返回响应给客户端，最后关闭TCP连接。媒介是TCP，消息格式则由HTTP来定义。

区别：

1. TCP属于传输层协议，HTTP属于应用层协议

2. TCP是面向连接的、可靠的协议，而HTTP是无连接、不可靠的协议

3. TCP能够保证数据在传输过程中不丢失，而HTTP无法保证

4. HTTP传输的数据格式是HTML、XML等，而TCP传输的是字节流

## closewait的作用 `13`
Closewait是TCP协议中的一种状态，表示一个TCP连接已经收到了对方的FIN包，并且发出了自己的ACK包，但是该连接还没有被正式关闭，因为还有一些数据包没有被收到或发送完成。

具体来说，当一端的应用程序调用关闭连接的API时，该TCP连接进入FIN_WAIT_1状态，此时TCP会向对端发送一个FIN（表示自己的数据发送完毕）和一个ACK（确认对方的数据已经接受完毕）。对端接受到FIN和ACK后，会回复一个ACK，表示接受到了自己的FIN和ACK。此时该TCP连接进入FIN_WAIT_2状态，等待对方发送FIN。对方发送FIN后，会向该连接发送一个ACK，表示已经接收到对方的FIN，此时该连接进入CLOSE_WAIT状态，等待本地应用程序关闭连接。

总的来说，CLOSE_WAIT表示本地应用程序已经关闭连接，但是TCP连接还没有被彻底关闭，因为还有一些数据包没有被收到或发送完成。这个状态通常是由于应用程序没有正确地关闭连接，或者接收到FIN包而没有及时响应，或者网络中出现了异常等原因导致的。一般情况下，CLOSE_WAIT状态不会持续很久，TCP连接会在一段时间后自动关闭。如果连接长时间处于CLOSE_WAIT状态，可能会导致资源占用和系统性能问题。

## 简述ARP协议流程 `12`


ARP（Address Resolution Protocol）协议是一种解决网络层（IPv4）地址与数据链路层（MAC）地址之间映射的协议。ARP协议的作用是在通信过程中根据IP地址获取其对应的MAC地址，以便数据包能够正确发送到目的地。

下面是ARP协议的详细流程：

1.主机A发送ARP请求：主机A首先检查自己的ARP缓存表（即已经获得的IP地址与MAC地址的映射表），如果没有要查找的IP地址，就会发送一个ARP请求报文，其中包含了要查找的IP地址。ARP请求报文包括源IP地址、源MAC地址、目的IP地址和目的MAC地址（广播地址FF-FF-FF-FF-FF-FF）。

2.局域网内所有主机都能收到ARP请求：由于ARP请求的目的MAC地址为广播地址FF-FF-FF-FF-FF-FF，因此网络内的所有主机都会收到这个请求。

3.被请求的主机响应ARP请求：如果被请求的主机（主机B）发现ARP请求报文中的IP地址与自己的IP地址匹配，就会向主机A发送一个ARP响应报文。ARP响应报文包括源IP地址、源MAC地址（即主机B的MAC地址）、目的IP地址和目的MAC地址（即主机A的MAC地址）。

4.主机A更新ARP缓存表：主机A在收到ARP响应报文后会将主机B的IP地址和MAC地址加入到自己的ARP缓存表中，以便之后再次发送数据包时可以直接使用这个映射关系。

5.主机A发送数据包：如果主机A要发送数据包到主机B，就先检查自己的ARP缓存表中是否有主机B的MAC地址，如果有就直接将数据包发给主机B的MAC地址，如果没有就先发送一份ARP请求报文查询主机B的MAC地址，然后再将数据包发给主机B。

整个ARP流程非常简单，但它是网络通信中非常重要的一环，可以确保数据包能够被正确地发送到目的地。

## websocket是如何保证通信可靠 `12`


WebSocket 是 HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议，与 HTTP 协议兼容，运行在相同的端口上，对 Web 服务器和客户端都没有太大的要求。

WebSocket 协议中，客户端和服务器通过 HTTP 协议进行握手，成功后便可以开始进行全双工的数据通信。WebSocket 的特点是建立在 TCP 协议之上，服务器端的实现比较容易。

WebSocket 保证通信可靠的方式有以下几种：

1. 心跳机制：客户端和服务器建立 WebSocket 后，会通过定时发送心跳包的方式来保证连接的存活性。当服务器端长时间没有接收到客户端的心跳包，就认为客户端已经断开连接。这个时间一般通过配置来确定。

2. 应答机制：当客户端发送数据给服务器端后，服务器需要做出应答，告诉客户端数据是否正确接收。如果客户端没有收到服务器端的应答，就会重新发送数据。

3. 断线重连：当客户端和服务器端的连接断开时，客户端会尝试重新连接服务器。WebSocket 客户端和服务器端都可以设置重连次数和重连间隔。

4. 消息队列：在 WebSocket 中，服务器端发送的消息如果没有立即被客户端接收到，服务器可以将消息放入消息队列中等待客户端接收。

总之，WebSocket 通过建立在 TCP 协议之上的全双工通信，加上心跳机制、应答机制、断线重连机制和消息队列等方式，来保证通信的可靠性。

## 列举拥塞控制的几种算法 `11`
拥塞控制是指在现有网络负载大、网络数据包丢失、路由器阻塞、网络拥塞等情况下，通过调整数据传输流量大小和发送速率，使网络始终能够在最优状态下运行。以下是几种常见的拥塞控制算法：

1. TCP Tahoe算法：是TCP中最早的拥塞控制算法，当网络拥塞时，每次仅减少一个MSS（Maximum Segment Size）的数据包，接下来每次重复实行上述过程，直到网络拥塞消失。

2. TCP Reno算法：改进于Tahoe算法，当网络拥塞时，通过快速重传和快速恢复算法进行实时重传和恢复，从而避免TCP连接因流量过大而中断。

3. TCP Vegas算法：将延迟时间作为去拥塞策略的主要指标，通过监测RTT（Round-trip time，往返时间）值动态计算网络拥塞程度，并且以此动态调整发送速率。

4. TCP Westwood算法：在对网络拥塞程度判断的基础上，还考虑到网络带宽变化的情况，通过动态调整发送速率和发送窗口大小，从而更好地适应网络带宽的变化。

5. AIMD（Additive Increase，Multiplicative Decrease）算法：通过不断增加拥塞窗口的容量，增加数据发送的速率，一旦发现网络拥塞，就以一定比例减少拥塞窗口大小，控制数据传输流量。

## https如何保证可靠性 `11`


HTTPS（Hypertext Transfer Protocol Secure）是一种安全的 HTTP 协议。HTTPS 的安全性主要基于以下两个方面：

1. SSL/TLS 加密协议

HTTPS 采用了 SSL（Secure Sockets Layer）或 TLS（Transport Layer Security）协议来加密数据。利用 SSL/TLS 加密协议，客户端与服务器之间的数据可以进行加密传输，保证了传输的机密性，防止敏感信息被窃取或篡改。SSL/TLS 协议的安全性源于使用了公钥加密和私钥解密的方式来进行数据的加密和解密。

2. 数字证书验证

HTTPS 还采用了数字证书的方式来验证服务器的身份。数字证书是由证书颁发机构（CA）签名后的服务器公钥，是一种有效防止中间人攻击（Man-in-the-Middle）的方法。当客户端与服务器建立连接时，服务器会向客户端发送数字证书，客户端则会去信任的 CA 验证服务器的身份，确保在通信过程中信息不会被中间人篡改。

综上所述，HTTPS 通过 SSL/TLS 协议的加密以及数字证书验证，从而保证数据的机密性、完整性和真实性，增强了通信的可靠性。

## Https的TLS的工作原理 `11`


HTTPS（Hyper Text Transfer Protocol Secure）是一种用于安全通信的HTTP协议，TLS（Transport Layer Security）是HTTPS使用的安全传输协议。

TLS主要解决了以下三个安全问题：

1.数据传输过程中的信息泄露问题：TLS通过使用对称加密技术对传输的数据进行加密，仅允许接收方对其进行解密。双方通过握手协议确定对称密钥，然后使用对称密钥加密和解密传输数据。

2.数据传输过程中的数据完整性问题：TLS通过使用消息认证码（MAC）对传输的数据进行认证，确保数据在传输过程中不被篡改。

3.证书认证问题：TLS通过使用公钥加密技术，保证了客户端与服务端之间的身份认证。在HTTPS通信开始前，服务器会向客户端发送自己的数字证书，客户端会使用预装的证书机构的公钥对数字证书进行验证。如果验证通过，客户端会生成一个随机的对称密钥并使用服务端的公钥进行加密，服务端通过私钥解密，从而建立了一条安全的加密通道。

通信建立时，TLS使用握手协议来协商会话参数并验证证书。握手协议包括以下阶段：

1.客户端发送ClientHello消息，包含TLS版本、加密算法、压缩算法等信息。

2.服务器返回ServerHello消息，选择一组客户端支持的加密算法、TLS版本、数字证书等信息。

3.服务器返回Certificate消息，包含数字证书链。

4.服务器返回ServerKeyExchange消息，包含服务器公钥、Diffie-Hellman交换的参数等信息。

5.服务器返回CertificateRequest消息，请求客户端证书。

6.服务器返回ServerHelloDone消息，通知握手结束。

7.客户端返回Certificate消息，如果需要客户端证书的话。

8.客户端返回ClientKeyExchange消息，包含客户端公钥、Diffie-Hellman交换的参数等信息。

9.客户端也可能返回CertificateVerify消息，用于验证客户端证书。

10.客户端发送ChangeCipherSpec消息，通知服务器从现在开始使用加密通信。

11.客户端发送Finished消息，包含前面在握手阶段产生的所有消息的HASH值。

12.服务器同样发送Finished消息，ACK确认客户端的Finished消息。

最后，客户端和服务器之间建立了一条安全通道，可以进行加密传输数据。

## NIO的实现模型 `11`


NIO（Non-blocking I/O，非阻塞 I/O）是 Java 平台的核心库 Java NIO （New I/O）引入的一种 I/O 模型。相比传统的阻塞式 I/O，NIO 的特点在于可以通过单线程处理多个请求的 I/O 操作，提高了系统的响应能力。

实现模型主要有以下三种：

1. Reactor 模式：应该是最常用最经典的一种模式，核心是一个 Reactor 对象，负责监听所有连接，有一个或多个 Handler 处理 I/O 事件。

2. Proactor 模式：与 Reactor 模式不同之处在于，Proactor 模式是在 I/O 操作完成后才向应用程序通知结果，然后由另一个 Handler 处理结果。

3. Worker Thread 模型：每当有一个连接到来时，就会创建一个新的线程去处理，类似于传统的阻塞式 I/O。

其中 Reactor 模式是最为常用的一种，它将 I/O 事件的处理逻辑分为两个部分：一个是对事件进行分发，称为 Acceptor。一个是对事件进行逐个处理，称为 Handler。整个模式就是一个 Acceptor 接受连接请求，然后由一个或多个 Handler 处理 I/O 事件的过程。

在 Reactor 模式中，Reactor 对象会监听 Selector 上的事件，每当 Selector 上面有事件发生时（如连接请求、读写数据），就会调用相应的事件处理器来处理这些事件。在 Reactor 的模式中，所有事件处理都在同一个线程中完成。这个线程就是 Reactor 线程。所有的 I/O 事件都由 Reactor 线程完成了，具有极高的效率。

总的来说，NIO 的实现模型是基于事件驱动的，通过监听 I/O 事件并调用相应的事件处理器来实现。这种模型具有高效、可扩展等优点，非常适合高负载、高并发的场景。

## http请求中的跨域问题 `10`


跨域问题指的是在 Web 应用中，如果浏览器在当前 Web 页面中向不同域名的服务器发起 HTTP 请求时，浏览器就会向请求的源地址服务器发起一个“预检请求”，也就是所谓的 OPTIONS 请求，用于确定是否允许在目标地址上使用指定的 HTTP 方法。这种情况下，服务器需要进行一些特殊的处理才能让跨域请求被正确处理并响应。

主要有以下几种解决跨域问题的方式：

1. JSONP（JSON with Padding）—— 利用 javascript 可以跨域、动态创建 script 标签的特性，实现跨域通信。

2. CORS（Cross Origin Resource Sharing）——通过在服务器端设置一些 HTTP 头信息，可以实现浏览器与服务器之间的跨域请求。

3. 代理（服务器代理和客户端代理）——通过在客户端或者服务器端设置代理，将跨域请求变成同域请求。 

4. postMessage——在不同窗口间传递数据，以此达到跨域通信的目的。

5. WebSocket——使用 WebSocket 进行跨域请求（如：HTTP 请求中使用 WebSocket 进行跨域请求）。 

需要注意的是，跨域问题导致的危害有很多，比如：会导致 XSS 攻击或 CSRF 攻击，所以在解决跨域问题时，应当保证安全性，避免个人重要信息等数据泄露问题的发生。

## Http报文格式 `10`


HTTP报文是Web数据传输的基本单元。它由报文头部和报文主体两个部分组成。HTTP报文格式如下：

```
请求报文格式：
HTTP method URL HTTP/版本号
Header1: value1
Header2: value2

请求body


响应报文格式：
HTTP/版本号 状态码 状态信息
Header1: value1
Header2: value2

响应body
```

HTTP报文主要包含以下几个部分：

1. 请求行：请求行包含请求方法、URL和HTTP版本信息，格式为`METHOD URL HTTP/VERSION`，例如`GET /index.html HTTP/1.1`

2. 请求头：请求头包含请求信息的描述，每对描述都用一个独立的`Header-Value`形式表示，例如`User-Agent: Mozilla/5.0`

3. 空行：在报文头部和报文主体之间必须有一个空行来分隔两部分

4. 请求主体：请求主体可包含请求发送的数据，比如POST请求中的表单数据等。

响应报文也包含类似的格式和内容，不同的是状态行中包含的是HTTP状态码，例如`HTTP/1.1 200 OK`， 可以表示请求成功。

总的来说，HTTP报文格式规定了在HTTP请求和响应过程中的各种信息内容的格式，用于Web数据的传输。

## Socket与WebSocket的区别与联系 `10`
Socket和WebSocket都是网络编程中的通信协议，不同之处在于Socket是传统的TCP/IP协议上的通信方式，而WebSocket是HTML5提供的一种新协议，它基于HTTP协议实现了一个持久化的、双向通信的通信通道。

下面是它们的具体区别和联系：

区别：

1. 底层协议不同：Socket是基于传统的TCP/IP协议，而WebSocket是基于HTTP协议。

2. 通信目的不同：Socket主要用于传递二进制数据，而WebSocket的设计初衷是在客户端和服务器之间建立实时的全双工通信通道。

3. 通信方式不同：Socket采用C/S（客户端/服务器）模式，而WebSocket采用B/S（浏览器/服务器）模式。

联系：

1. 两者都可以实现客户端与服务器之间的双向通信。

2. 两者都需要建立连接，只是连接的方式不同。

3. 两者都可以用于实现实时通信，特别是在实时性要求比较高的场景。

总的来说，WebSocket相对于Socket而言，具有更好的性能、更低的延迟和更高的吞吐量，因此在Web应用开发中使用WebSocket更为普遍。

## 列举应用层协议 `9`


应用层协议是计算机网络中的一种协议，用于应用程序之间的通信和数据交换。以下是一些常见的应用层协议：

1. HTTP协议——用于万维网上的数据交换，包括HTML文件、图片、视频等。

2. FTP协议——用于在客户端和服务器之间传输文件，支持匿名和用户认证。

3. SMTP协议——用于发送和接收邮件，通过SMTP服务器将邮件从发送者传输到接收者。

4. POP3协议——用于接收邮件，将电子邮件从邮件服务器传输到用户计算机。

5. IMAP协议——也用于接收邮件，但允许用户管理邮件服务器上的邮件，如删除、移动等操作。

6. DNS协议——用于将域名解析为IP地址，在客户端和服务器之间传输数据。

7. Telnet协议——允许用户远程登录服务器，执行命令并在终端上查看输出结果。

8. SSH协议——和Telnet协议相似，但提供了安全加密和身份验证功能。

9. SNMP协议——用于管理和监控网络设备，如路由器、交换机等。

10. IRC协议——用于实现Internet上的聊天室，允许用户实时通信。

以上这些协议都是应用层协议，在计算机网络中起着重要的作用。

## RPC框架的工作流程 `9`


RPC（Remote Procedure Call，远程过程调用）是一种协议和编程语言无关的技术，用于实现分布式系统中不同节点之间的通信和数据交互。RPC框架是用于简化RPC实现的工具集，它可以自动生成RPC客户端和服务端的代码，提供数据序列化和反序列化、协议切换等繁琐的操作。

RPC框架的工作流程一般分为四个阶段：服务调用、序列化、网络传输、反序列化。下面详细介绍每个阶段的流程：

1. 服务调用：客户端发起一个方法调用请求，将方法名、参数列表等信息封装成一个调用对象。

2. 序列化：调用对象需要在网络上传输，因此需要先将其序列化成二进制或者其他可传输的格式。这一步需要根据协议的规范，通过序列化算法将调用对象转换成二进制流。

3. 网络传输：序列化后的数据通过网络传输到服务端。在此过程中，需要进行路由和网关的选择，保证客户端调用的数据被正确地传输到目标服务端。

4. 反序列化：服务端收到数据后，需要进行相反的操作，即反序列化，将二进制流转换成调用对象。反序列化过程需要使用与序列化过程相同的算法。

5. 执行服务方法：服务端收到调用请求后，根据方法名和参数列表执行相应的方法，并将执行结果返回给客户端。

6. 序列化：服务端需要将执行结果序列化成二进制流，以便通过网络传输给客户端。

7. 网络传输：序列化后的数据通过网络传输给客户端。

8. 反序列化：客户端收到数据后，需要进行反序列化操作，将二进制流转换成返回结果对象。

9. 结果处理：客户端得到执行结果后，根据协议的规范进行结果处理。具体的处理方式可以是将结果对象直接返回给调用方，可以是将结果输出到日志中，也可以是其他方式。

以上就是RPC框架的工作流程，每个阶段都需要用到不同的技术和算法，如数据结构、网络编程、反射等，在实现RPC框架时需要综合考虑这些要素。

## SYN洪泛攻击与应对方案 `8`


SYN洪泛攻击是一种网络攻击，它利用TCP三次握手过程中的SYN报文，向目标服务器发送大量的SYN请求，但是不会完成后续的ACK确认，这会大量占用服务器资源，最终导致服务器异常甚至崩溃。

为了应对SYN洪泛攻击，可以采取以下几种方案：

1. 过滤无效的SYN请求：在应用层或网络层，通过过滤机制，将大量无效的SYN请求过滤掉，降低服务器的无效响应。

2. SYN cookies：利用SYN cookies技术，将部分数据封装在SYN报文中，在不占用服务器资源的情况下，验证请求的有效性，确保正常用户能够被正确响应。

3. 增加服务器负载均衡：通过将请求均衡到不同的服务器上，分散服务器的负载，减少某一台服务器受到攻击的影响。

4. 强化安全防护：在服务器端增加安全防护软件或硬件设备，能够从多个层面对服务器进行防护，减少攻击的影响。

5. 联合防御：攻击者可能在多个网络节点发起攻击，需要联合多方防御，合力应对攻击。

综上所述，SYN洪泛攻击是一种比较常见的网络攻击，需要采取多种防御手段，充分保护服务器安全。

## Tcp与Udp相关协议 `8`


TCP（Transmission Control Protocol）和UDP（User Datagram Protocol）是两种网络协议，在数据传输时都有自己的特点和优势:

1. TCP协议:

TCP协议是面向连接的，双向可靠传输的协议，它建立连接后，数据传输前，会进行三次握手，来确保通信能够成功。三次握手是指:

- 第一次握手: 客户端发送SYN标志，请求建立连接。
- 第二次握手: 服务器接收到SYN标志，回复SYN-ACK标志。
- 第三次握手: 客户端接收到SYN-ACK标志，发送ACK标志。

TCP协议可以保证数据传输的可靠性，它通过数据确认和重传机制来确保数据的完整性。因此，在网络质量较差、需要传输大量数据时，TCP协议是较为常用的选择。

2. UDP协议:

UDP协议是一种无连接的、不可靠传输的协议，它不需要建立连接，数据传输时直接将数据报发送出去。因此，UDP协议的传输速度与TCP协议相比较快，而且占用网络资源较少。

尽管UDP协议不能保证数据传输的成功率和数据的完整性，但在实时性要求较高的场景下，通常会选择UDP协议。例如，在实时游戏和视频流传输中，UDP协议被广泛使用。

总的来说，TCP和UDP协议具有各自的优势和适用场景，需要根据实际情况选择适当的传输协议。

## Https为什么安全？ `8`


HTTPS（Hyper Text Transfer Protocol Secure）是基于 HTTP 协议并加入 SSL/TLS 协议的安全协议。HTTPS 协议具有以下安全性：

1. 数据加密：HTTPS 通过使用 SSL/TLS 协议，对数据进行加密传输，使得数据在传输过程中不易被窃听和窃取。在客户端与服务器之间的通信过程中，服务器生成数字证书和对应的私钥，对数字证书进行签名，并将公钥发给客户端，客户端通过验证数字证书的有效性，使用公钥对数据进行加密，发送给服务器。服务器使用私钥进行解密，获得客户端的数据。

2. 身份认证：HTTPS 能够验证双方身份。服务器提供了数字证书，客户端可以使用这个证书验证服务器是否可信。同时，客户端也可以通过提供数字证书，让服务器验证其身份。

3. 数据完整性：HTTPS 使用了消息摘要算法和数字签名，保证数据的完整性。在通信过程中，发送方使用摘要算法生成消息摘要，并使用私钥进行签名。接收方使用公钥验证签名和消息摘要，确保接收到的数据完整且未被篡改。

综上， HTTPS 通过加密、身份认证和数据完整性保证了信息的安全性，使得数据在传输和通信过程中得到更为安全的保护。

## Http与Rpc的关系 `8`

HTTP和RPC都是常见的网络通信协议，它们都用于不同系统之间的数据交换，但在一些关键方面有所不同。

HTTP是一种客户端-服务器协议，它通过请求和响应方式进行通信，一般用于Web应用程序，通过HTTP协议可以传输HTML页面、JavaScript脚本、CSS样式表、图片、视频等不同的数据类型。HTTP协议对于多种编程语言都提供了支持，Web应用程序可以通过HTTP协议向外提供API接口并实现数据交互。

而RPC（Remote Procedure Call，远程过程调用）也是一种通信协议，它主要用于不同系统之间的数据交换和远程调用。通过RPC协议，客户端可以像调用本地函数一样简单地发起远程调用，获取远程服务的结果。RPC可以使用多种传输协议和数据格式，如TCP、UDP、HTTP和XML等，它使得不同系统之间的交互更加方便和高效。

在技术上看，HTTP和RPC都采用了客户端-服务器模型，其主要区别在于数据传输方式和数据传输格式的不同。HTTP传输的数据一般采用JSON或XML格式进行封装，而RPC数据传输格式则不唯一，可以是二进制、文本或者XML等格式。一些业务系统中，比较常见的应用场景，远程服务器需要对多个客户端（如手机、PC、平板等）提供统一的访问接口，此时通常会采用HTTP协议，或者是服务端渲染的方式向外提供数据，而对于开发语言相同的业务系统，一些高性能、低延迟的RPC协议可能更适合。

## SSL如何加密 `8`


SSL (Secure Sockets Layer) 是一种常用的加密技术，常用于保护网络通讯中的数据安全。SSL 通过使用公钥加密和私钥解密的方式，实现了数据在传输过程中的加密。

以下是简单的 SSL 加密过程介绍：

1. 客户端和服务器进行 SSL 握手，客户端发送请求给服务器。

2. 服务器将自己的 SSL 证书发送给客户端。证书中包含了服务器公钥以及服务器的基本信息。

3. 客户端使用服务器的公钥对证书进行解密，并验证证书有效性。

4. 如果证书有效，客户端生成一个随机数，并使用服务器公钥加密发送给服务器。

5. 服务器使用自己的私钥对加密的随机数进行解密。

6. 客户端和服务器使用交换的随机数临时生成的对称密钥对数据进行加密和解密。

7. SSL 握手结束，客户端和服务器开始使用对称密钥进行通讯。

通过这个流程，在网络传输中，SSL 加密了数据传输的过程，使得第三方无法获取数据的内容，从而可以保证数据的安全性。

## https建立连接的过程 `8`


HTTPS是一种安全的HTTP协议，它在传输数据时使用SSL或TLS加密协议对数据进行加密，在客户端和服务器之间建立一条安全通道，确保通信过程的机密性和完整性。

建立HTTPS连接的过程可以分为以下几个步骤：

1.客户端向服务器发出连接请求
客户端向服务器发出HTTPS连接请求时，会发送一个加密类型、协议版本、主要连接参数等信息，这些信息被称为Client Hello。

2.服务器响应客户端请求
服务器收到客户端的Client Hello后，会返回一个服务端响应，也被称为Server Hello。在响应中，服务器会确定使用的加密套件，生成并发送数字证书，以及发送服务器的公钥等信息。

3.客户端验证服务器的证书
客户端收到服务器的响应后，会使用数字证书中的信息验证服务器的身份。证书中包含了服务器的公钥、服务器的DNS名和有效期等信息。

4.客户端生成并发送随机密钥
一旦客户端验证了服务器的身份，它将生成一个随机密钥，并使用服务器的公钥进行加密。这个密钥将用于在接下来的通信中加密和解密数据。

5.建立安全连接
服务器使用它的私钥解密客户端发来的随机密钥，然后使用该密钥加密和解密通信中的数据。客户端和服务器之间就建立了一条安全的通道，可以进行加密和解密通信中的数据。

通过以上步骤，HTTPS连接已成功建立。客户端和服务器现在可以进行安全通信，并确保传输的数据机密性和完整性。

## Http、Https 性能比较 `8`


HTTP和HTTPS都是用于在Web服务器和客户端之间传输数据的协议，但它们在数据传输过程中有明显的性能差异。

HTTP是一种明文协议，数据在传输过程中不进行加密，因此传输速度较快，但是数据容易被窃听、篡改和伪造，安全性较低。

HTTPS是在HTTP协议的基础上添加了SSL/TLS加密层的协议，可以在传输过程中加密数据，提高安全性。但是由于数据加密和解密需要消耗大量的计算资源，因此传输速度相对较慢。

总体来说，在安全性要求较高的场景下，HTTPS比HTTP更可靠，但是在数据传输速度上会有所降低。对于一般的网站和应用程序，使用HTTP协议可以获得更快的网络速度，但是对于需要保证安全性的交互，使用HTTPS是必须的。

## ajax发生请求的过程 `7`
Ajax（Asynchronous JavaScript and XML）是一种通过JavaScript来实现异步交互的技术，是一种能够实现不刷新网页的情况下与服务器进行数据交互的技术。

Ajax的请求过程可分为以下几个步骤：

1.创建XMLHttpRequest对象

在JavaScript中，创建XMLHttpRequest对象的方法是通过new关键字和XMLHttpRequest()方法进行创建。如下所示：

```
var xmlhttp;
if (window.XMLHttpRequest) {// code for IE7+, Firefox, Chrome, Opera, Safari
  xmlhttp = new XMLHttpRequest();
} else {// code for IE6, IE5
  xmlhttp = new ActiveXObject("Microsoft.XMLHTTP");
}
```

2.建立连接（open方法）

使用XMLHttpRequest对象的open方法建立与服务器的连接。该方法接收三个参数，分别为请求类型（GET或POST）、发送请求的URL，以及是否异步发送请求。如下所示：

```
xmlhttp.open("GET","demo_ajax.php",true);
```

3.发送请求（send方法）

使用XMLHttpRequest对象的send方法向服务器发送请求。对于GET请求，数据会附加在URL之后；对于POST请求，数据则以NameValuePair的形式发送给服务器。如下所示：

```
xmlhttp.send();
```

4.服务器响应

服务器收到请求后，会对请求进行处理，然后将处理结果以响应报文的形式返回给客户端。在JavaScript中，可以通过XMLHttpRequest对象的readyState和status属性获取响应的状态。如果readyState的值为4，即请求已完成，并且响应的状态码为200，则表示请求成功，可以通过responseText或responseXML属性获取响应数据。如下所示：

```
xmlhttp.onreadystatechange=function()
{
  if (xmlhttp.readyState==4 && xmlhttp.status==200)
  {
    document.getElementById("myDiv").innerHTML=xmlhttp.responseText;
  }
}
```

以上就是Ajax发生请求的过程，它的优势在于能够实现异步操作，优化了用户体验。

## Udp使用场景 `7`


UDP是一种无连接的传输层协议，它不提供数据包的可靠性保证，因此常用于一些对数据可靠性要求不高但速度要求较高的场景。

下面是UDP常见的使用场景：

1. 实时音视频传输。在音视频传输过程中，如果发生少量数据丢失，也不会对观看或听取造成太大影响，同时，UDP协议的低延迟特性使得音视频数据能够更快、更及时地传输，因此在实时音视频传输中，UDP协议往往被广泛使用。

2. 游戏场景。在游戏中，每一个数据包都需要快速地传输到服务器或其他玩家，获得低延迟能够提高游戏的流畅度，而UDP在这方面有着很好的应用。

3. DNS域名解析。在DNS中，UDP通常用于域名解析，因为DNS系统需要在很短的时间内响应请求，而UDP可以更快地进行响应。

4. 日志传输。企业日志处理中往往用到UDP协议，UDP的不可靠性在日志传输过程中不构成影响，而速度优势则可以提高日志处理的效率。

总之，UDP协议的快速、低延迟的特性适用于那些对数据可靠性要求不高，但速度要求较高的场景。

## 非对称密钥算法 `7`


非对称密钥算法，也称为公钥密码学，是一种加密和解密信息的方式。它使用了两个不同的密钥，称为公钥和私钥，来加密和解密信息。

公钥是公开的，可以被传递给任何人，用于加密发送的消息。私钥是保密的，只有拥有私钥的人才能解密消息。

非对称密钥算法的一个重要应用是数字签名。数字签名可以用于验证文档的源自于特定的发件人，且在传输过程中没有被篡改。

其他常见的使用场景包括：

1. 通过公钥加密会话密钥，用于保证双方之间的加密通信。

2. 对敏感数据进行加密保护，以防止未经授权的访问。

3. 确保身份验证。

4. 用于数字货币和区块链系统的签名和验证。

总之，非对称密钥算法为信息安全提供了一个强大的工具，可以保护数据的机密性、完整性和真实性，应用广泛且重要。

## http2.0引入多路复用的目的 `7`


HTTP/2.0 引入了多路复用的概念，它允许在一个单独的连接上同时传输多个请求/响应消息。它的目的是提高网络传输效率和性能。

具体来说，它可以在一个连接上同时处理多个请求和响应，而无需为每个请求和响应都建立新的连接。这就避免了建立和关闭多个连接的开销，同时也减少了网络拥塞的风险。此外，多路复用还支持头部压缩技术，可以将 HTTP 请求和响应消息中的头部信息压缩，减少了网络传输中的数据量。

总的来说，多路复用可以提高网站的性能、速度和用户体验，因为它可以更有效地利用网络资源，减少延迟，提高响应速度。

## Socket实现三次握手 `7`


Socket实现TCP连接时，需要进行三次握手。三次握手的目的是建立TCP的连接参数。握手需要经过以下步骤：

1.客户端发送SYN包到服务器端口
2.服务器端收到SYN包，确认启动TCP连接，服务器端回送一个SYN ACK包
3.客户端收到服务器端发来的SYN ACK包，回送一个ACK包，表示连接成功

具体步骤如下：

1.客户端发送SYN包
客户端发送一个SYN包（SYN表示同步信号），其中包含初始序列号（ISN）。SYN包中同时也包含客户端的TCP连接标志和一些其他必要的参数。

2.服务器端回送SYN ACK包
服务器收到客户端的SYN包后，设定一些TCP参数，生成一个随机值并将其称为ISN。然后，服务器端发送一个SYN ACK包（即连接请求确认包），其中包含服务器端的TCP连接标志、ISN和客户端的确认序列号（ACK）。服务器端将ISN+1作为下一个期待收到的序列号（即其期待收到的数据序列号），等待客户端发送一个内容为ACK的包，以便确认其生效。

3.客户端回送ACK包
客户端收到服务器发来的SYN ACK包后，将ISN+1作为下一个期待收到的序列号，并向服务器发回一个ACK包，与服务器确认建立连接。

这样，三次握手完成之后，TCP的连接参数就确定了，数据传输也可正式开始了。

## ajax如何取消请求 `6`
在 HTTP 请求发起之后，有时候需要在请求尚未完成时取消发送的请求，这时候需要使用到 `abort()` 方法，该方法可以在任何时间中止请求，取消请求。

下面是具体的取消请求的方法：

1. 创建XMLHttpRequest对象

```javascript
var xhr = new XMLHttpRequest();
```

2. 发送请求

```javascript
xhr.open('GET', '/get_data', true);
xhr.send();
```

3. 取消请求

```javascript
xhr.abort();
```

当调用 `xhr.abort()` 方法时，无论 AJAX 请求是正在进行中还是已经完成，浏览器都会终止这个请求。

实际上，调用 `xhr.abort()` 方法后，XMLHttpRequest 对象的 `readyState` 值将被置为 `0`，表示 AJAX 请求已经被取消。因此在响应上，`onreadystatechange` 事件将不会被触发，而是直接调用 `onabort` 事件，以表示 AJAX 请求被取消状态。

## TCP为什么要进行拆包？ `6`


TCP是面向字节流的协议，它将发送的数据流分割成一个个的数据包进行传输，而这些数据包在传输过程中可能会被路由器、交换机等网络设备所限制大小影响，从而被拆成多个数据包进行传输，这就是TCP拆包。

TCP拆包主要有两种情况：

1. 网络设备将一个完整的TCP报文段拆成了多个数据包进行传输。

2. 一个TCP数据包中包含了多个TCP报文段。

TCP拆包的原因是为了适应网络环境的变化和不同的应用需求，通过将数据拆成多个小数据包进行传输，可以提高网络传输的效率和可靠性，同时也可以降低网络拥塞和传输失败的风险。

拆包后，接收端的TCP协议需要重新组装数据包，确保接收到的数据与发送端发送的数据一致。如果出现了数据丢失或乱序，TCP会通过重传和流量控制等机制重新传输数据，确保数据传输的完整性和准确性。

## 列举传输层的协议 `6`
传输层是OSI模型中的第四层，它的主要作用是为应用层提供端到端的数据传输服务。传输层的工作包括连接的建立和维护、数据的分段和传输、以及异常处理等。

常见的传输层协议包括：

1. TCP（Transmission Control Protocol）：是面向连接的、可靠的传输协议，主要用于那些需要保证数据可靠传输的应用场景，如HTTP、FTP等。TCP通过三次握手建立连接，并提供流控制和拥塞控制机制，以便在网络拥塞时进行流量控制，从而防止数据包的丢失和重传，保证数据的完整性和可靠性。

2. UDP（User Datagram Protocol）：是面向无连接的、不可靠的传输协议，主要用于那些对数据传输速度要求比较高的应用场景，如视频音频流媒体等。UDP不需要建立连接，也没有流控制和拥塞控制机制，因此传输速度比TCP快，但也会导致数据包的丢失和抖动。

3. SCTP（Stream Control Transmission Protocol）：是一种新兴的面向消息的传输协议，它具有可靠和可定制的传输服务，主要用于一些对数据传输有较高要求的应用场景，如语音通信、IP电话等。SCTP支持多路复用、有序传输和可靠性控制等特性，可以提供更高的传输效率和质量。

总的来说，TCP和UDP是目前最常用的传输层协议，它们各有优缺点，根据具体的应用场景选择合适的协议来实现端到端的数据传输。

## 四次挥手为什么要等待2MSL？ `6`


TCP（传输控制协议）是一种面向连接的协议。它通过双方明确的握手和挥手流程来建立或关闭连接。四次挥手（Four-way handshake）是TCP协议的一部分，用于关闭连接。可以理解为一个信号，使两端都同意关闭连接。

四次挥手的过程如下：

1. 主机A发送一个FIN（表示主机A不再发送数据）给主机B。
2. 主机B确认收到FIN并发送一个ACK（表示主机B已经接收到FIN）给主机A。
3. 主机B发送一个FIN给主机A（表示主机B不再发送数据）。
4. 主机A确认收到FIN并发送一个ACK给主机B（表示主机A已经接收到FIN）。

2MSL指的是两倍的最大报文存活时间（Maximum Segment Lifetime）。也就是说，TCP链接在关闭时需要等待2MSL的时间。

其中，最大报文存活时间指的是一个TCP数据包从发送方到接收方最长的时间，这段时间内，如果数据包丢失，就需要重新发送。因此，一个TCP数据包在网络上的生命周期最长不会超过2倍的最大报文存活时间。这个时间的长度应该是足够的，使网络上的所有数据包都能够完全消失。在这段时间内，主机A或者主机B收到再次发送的相同序号的FIN，可以认为是上一次连接中的延迟数据包，关闭连接仍然可以正确进行。

如果关闭连接后，立即打开新的相同端口号的连接，可能会收到上一个连接的延迟数据包，导致数据的混乱和误解。因此，两次挥手后，主机按照2MSL的时长等待，来确保上一个连接中的所有数据包都已经完全消失，才能重新开启一个新的连接。

## 长连接与短连接的区别 `6`


在计算机网络通信中，客户端（浏览器、应用程序等）与服务器之间进行通信可以采用长连接或短连接两种方式。

短连接：指客户端与服务器建立连接、发送请求、处理响应、断开连接这四个步骤在一个短时间内完成，一般用于客户端对于服务器的请求只涉及一个单独的请求响应过程的场景。

长连接：指在客户端与服务器之间建立一次连接后，可以进行多次请求响应操作，请求响应完成后不会立即断开连接，而是将连接保持在打开状态，等待下一次请求。长连接可以避免频繁地建立、关闭连接，降低通信成本，而且长连接实现起来也比较简单。常用于需要反复请求同一服务器的场景，例如web应用中的AJAX异步请求、IM即时通讯等。

总的来说，短连接在每一个请求中需要重新建立连接，每次连接都需要经过三次握手和四次挥手的过程，处理复杂，同时也消耗更多的资源从而使服务器负担变大；而长连接可以减少连接开销和网络传输数据量，但是长时间占据资源，可能由于connection 超时等导致服务器负荷变大。

## 为什么OSI标准是七层，而实际使用的是五层？ `5`
OSI（Open System Interconnection）标准是一个理论模型，主要用于描述计算机和通信设备之间进行通信时，信息如何在不同层之间传递。该模型将计算机网络分为七层，从下至上依次是：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。

然而，在实际的计算机网络中，我们通常把这个七层模型简化为一个五层模型，这个五层模型也称为TCP/IP协议栈。这五层包括：物理层、数据链路层、网络层、传输层、应用层。其中物理层和数据链路层合并成了网络访问层，会话层和表示层合并成了应用层。

这个简化的五层模型实际使用起来更加方便和实用，因为它更加符合实际的网络通信协议和应用场景。同时，该模型也符合实际应用中的TCP/IP协议，因此被更加广泛地使用。

## 路由器工作原理 `5`


路由器是一种网络设备，它用于将数据包从源地址路由到目标地址。它通过查找路由表和确定最佳路径来决定数据流量的方向，并可通过NAT（网络地址转换）将多个设备连接到Internet上。

以下是路由器的基本工作原理：

1.路由器工作在OSI模型的第三层（网络层）。

2.每个路由器都有一个IP地址，并有多个端口，每个端口将路由器连接到不同的网络。

3.当数据包进入路由器的一个端口时，路由器将检查数据包的目标地址，并使用路由表中的信息来确定路径。

4.路由器使用NAT将多个设备连接到Internet上时，它会将进入路由器的数据包的源地址更改为路由器的地址，并将它们标记，以便在数据包流经网络时，可以返回正确的设备。

5.路由器不会传输故障数据包，它会注意到任何传输错误并返回相应的错误信息。

总之，路由器通过检查目标地址和使用路由表中的信息来确定数据包的路径，并通过NAT将多个设备连接到Internet上。

## ping的过程 `5`


Ping是一种网络工具，用于测试计算机网络的连通性。其原理是发送一个ICMP（Internet控制消息协议）回显请求消息给目标主机，目标主机接收到该请求之后进行回复，通过回复时间和传输丢失率等信息来检测网络性能。

具体来说，Ping的过程如下：

1. 客户端发送一个ICMP回显请求消息给目标主机。
2. 目标主机接收到请求并进行回复。
3. 客户端接收到回复消息并记录下来回复时间和传输丢失率等信息。
4. 客户端计算网络延迟（也就是Ping时间），并根据结果来判断网络连通性和性能状况。

如果网络连通，则Ping测试成功，并输出测试统计信息；如果网络不连通，则Ping测试失败。Ping工具也可以测试局域网内部的主机连通性，甚至可以测试到因特网上的任何IP地址。

需要注意的是，Ping测试的可靠性和精确性受到许多因素的影响，例如网络状况、网络拥堵、主机负载等。因此，Ping测试的结果只能作为参考，不能完全依赖其结果作出判断。

## 服务端time-wait太多，如何解决？ `5`


在计算机网络中，TIME_WAIT是在TCP连接关闭后，为了保证网络数据的完整性和正确性而存在的状态。它是在两个端点之间存在的连接，一般需要一段时间来等待可能丢失的网络包，以及确保它们已经正确地被接收和被确认。在此期间，端口会处于TIME_WAIT状态，直到它被彻底关闭。

服务端TIME_WAIT太多的原因可能是因为网络负载高、TCP连接开启和关闭不规范、连接数量过多等，可以采取以下几种方式来解决：

1. 调整TCP/IP协议参数：Linux系统可以通过更改tcp_fin_timeout（TCP关闭时的超时时间）和tcp_tw_reuse（允许将TIME_WAIT连接的端口重新分配给新的连接，而不会等待到完全结束）等参数来控制。但需要注意的是，这些参数需要根据实际情况进行调整，做好测试后再进行生产环境设置。

2. 加强代码质量：在编写服务器代码时，应当尽可能遵循网络规范，安全地关闭TCP连接，避免异常情况导致TIME_WAIT的产生。同时可以通过定时清理连接池中的无用连接，及时地释放占用的端口资源。

3. 使用负载均衡：使用负载均衡可以分散网络流量，降低单个服务器的连接数量，减轻单个服务器的负担。同时，负载均衡器也可以自动处理TIME_WAIT连接。

4. 添加更多服务器：如果负载均衡不能够解决问题，那么可以尝试添加更多的服务器，分担服务器的负载，进一步降低每台服务器的连接数量。 

综上所述，服务端TIME_WAIT太多的解决方式需要根据实际情况进行调整。如果通过调整TCP/IP协议参数和加强代码质量等方法无法解决问题，可以考虑使用负载均衡或者添加更多服务器。

## TCP超时重传时间与次数 `5`


TCP超时重传时间是指当TCP数据包在传输过程中没有被确认接收，也没有接收到任何重复的应答时，TCP将触发超时重传机制，重新发送该数据包。超时重传时间是指TCP等待确认接收的时间，通常为几秒钟至几十秒钟之间。

TCP超时重传次数是指重传数据包的次数，超过该次数后，TCP会中止传输并进行相应的处理，如关闭连接等。TCP超时重传次数通常在3次左右，如果连续3次没有收到确认响应，则会判定连接异常并进行相应的调整处理。

超时重传机制是为了确保数据的可靠传输，但过于频繁的重传可能会影响网络性能，因此需要根据具体情况进行适当的调整。一般来说，如果网络稳定，可以适当减少超时重传时间和次数；如果网络不稳定，则需要增加超时重传的时间和次数以确保数据的可靠传输。

## TCP协议报文格式 `5`


TCP（Transmission Control Protocol，传输控制协议）是在因特网协议族中非常重要的一种协议，它提供了可靠的、面向连接的数据传输服务。在TCP连接的两端，数据是被抽象化成了数据流并传输的，而在网络层上，TCP协议必须将其分段为独立的报文段以便于网络层的传输。下面是TCP协议报文格式：

![TCP报文格式](https://img-blog.csdn.net/20181129150020284?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2V4Y2hhbmdl/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/q/85)


TCP协议的报文格式如上图所示，包含了如下几个字段：

- 源端口号（16位）：表示发送者的端口号，用于接收方的回传信息。
- 目的端口号（16位）：表示接收者的端口号。
- 序列号（32位）：本报文段所发送的数据的第一个字节的序列号。在三次握手后，序列号即是本端的初始序列号，由它开始编号的字节为发送方已传送过的字节。
- 确认号（32位）：期望收到对方下一个报文段的第一个数据字节的序列号。在三次握手后，用来确认这个序列号之前的字节都已经被对方正确接收。
- 数据偏移（4位）：指TCP头部有多少个32位字，也就是说TCP头部的长度，其最大值为15，代表最多可以有60字节的TCP头，实际上，当前所有的TCP实现都将数据偏移字段设置成了10（也就是40个字节）。
- 保留（6位）：保留为今后使用，目前一般使用全0。
- 6个控制标志：分别为URG、ACK、PSH、RST、SYN、FIN，下面将分别进行介绍。
  - URG（1位）：紧急指针（urgent pointer）有效。
  - ACK（1位）：确认序号有效（标志位为1），大多数情况下都是1，表示确认号有效，这时认为确认号字段有效，可以确信对方已经收到了自己发送的数据。
  - PSH（1位）：接收方应立即将这个报文段交给上层应用程序，而不是等待缓冲区填满再进行传递。
  - RST（1位）：重置TCP连接。
  - SYN（1位）：同步序号用来建立连接。
  - FIN（1位）：释放连接。
- 窗口大小（16位）：这个字段用来告诉对端自己现在的接收窗口大小，也就是还有多少可以接收数据的缓冲区可用，单位是字节。因为TCP采用的是可变大小的窗口，所以在TCP中，窗口这个值是需要交互的，发送方需要知道接收方窗口大小的变化情况。
- 校验和（16位）：对TCP报文段进行校验检查。
- 紧急指针（16位）：当URG为1时，这个字段才有效，它指出紧急数据的字节数位置。

## 分布式session，如何实现？ `5`


分布式Session是指将Session数据存储在多个服务器之间共享，以避免单个服务器或网络故障导致用户会话的丢失。实现分布式Session需要使用一个共享数据存储来存储会话数据，每个服务器在处理用户请求时都可以访问该共享数据存储。

以下是一种可行的实现分布式Session的方案：

1. 使用缓存服务器: 可以使用类似Redis这样的缓存服务器来存储Session数据，每个服务器都可以从缓存服务器中读取和写入Session数据。

2. 使用数据库: 可以将Session数据存储在数据库中，并通过数据库表中的会话ID来跟踪会话状态。每个服务器都可以从数据库中读取和写入Session数据。

3. 使用分布式文件系统: 可以将Session数据存储在分布式文件系统中，如HDFS。每个服务器都可以从HDFS中读取和写入Session数据。

无论选择哪种实现方式，都需要保证每个服务器都可以访问共享数据存储，并且能够在需要时同步数据。另外，确保要对Session数据进行合理的加密和身份验证，防止会话被篡改或窃取。

## Http如何保证安全传输 `5`


HTTP（超文本传输协议）是一种广泛使用的应用层协议，用于在Web浏览器和Web服务器之间传输数据。HTTP通过客户端请求和服务器响应的方式工作，但是HTTP传输的数据在传输过程中可能会被第三方截获，因此需要保证数据的安全性。

HTTP可以通过以下方式保证数据的安全传输：

1. SSL/TLS加密

通过使用SSL（安全套接层）或TLS（传输层安全）协议加密HTTP流量，可以保护数据在传输过程中不被窃听或篡改。在浏览器地址栏中，https://代表使用了SSL/TLS加密，而http://则不使用。

2. 认证与授权机制

通过认证与授权机制，可以控制用户对资源的访问权限。常见的认证与授权机制有基本身份验证（Basic Authentication）、摘要身份验证（Digest Authentication）和 OAuth2.0。

3. 防重放攻击

HTTP在传输过程中容易受到重放攻击，攻击者可以截取HTTP请求并重复发送给服务器，造成一些问题。为了避免这种攻击，可以在请求中加入时间戳或使用一些防止重放攻击的算法。

4. XSS与CSRF攻击防御

XSS（跨站脚本攻击）和CSRF（跨站请求伪造攻击）是Web安全领域的两个非常流行的攻击方式。为了防止这些攻击，需要对输入进行过滤和验证，以确保输入的数据是安全的，同时需要使用安全的cookie标识用户身份。

总体来说，HTTP通过加密、认证、防重放攻击、XSS与CSRF攻击防御等措施来保证数据的安全传输。

## https的证书简述 `5`


HTTPS是一种加密的HTTP协议，用于在Web浏览器和Web服务器之间进行安全、私密的数据传输。HTTPS的证书是用于验证连接的服务器的唯一证明。

HTTPS的证书包含以下重要信息：

1. 证书持有人（即服务器主机的名字）

2. 证书颁发机构（即授权验证该证书的机构）

3. 证书的有效期

4. 证书的公共密钥

当浏览器连接到服务器时，服务器会将其证书发送到浏览器。浏览器将验证证书的有效性和真实性。如果证书可信，则浏览器将使用证书中提供的公钥来加密从浏览器到服务器的所有通信。

如果证书无效或不可信，则浏览器将阻止连接，通常会弹出一个警告框，询问用户是否继续连接。如果用户选择继续连接，则所有传输的数据都可能被窃听或篡改。

因此，HTTPS证书的安全性对于保证Web通信的安全和可靠至关重要。

## 简述什么是HTTP? `5`


HTTP是英文“Hypertext Transfer Protocol”的缩写，即“超文本传输协议”，是一种用于传输超媒体文档（例如HTML）的应用层协议。HTTP是一个基于客户端-服务端（C/S）架构模型的协议。

HTTP的功能是客户端和服务器之间进行通信并传输数据。在交互式的Web应用中，HTTP是无法避免的。它能够在因特网上传输各种文本、图片、音频、视频等资源。

Web浏览器是HTTP客户端，它通过连接到服务器来请求内容，服务器端解析请求，然后向客户端发送请求的文件。HTTP默认使用TCP连接，使用端口号80。

HTTP是一个无状态协议，每个请求都是独立的，没有记忆能力，服务器不保存任何客户端请求的信息。但是，可以利用Cookie技术来保持会话状态。

总的来说，HTTP协议是Web应用程序中最基本的部分之一。它提供了一个标准的通信协议，使得服务器和客户端能够相互通信和交换数据。

## Http状态码301与302的区别 `5`


HTTP状态码301和302都表示重定向，但它们之间有以下区别：

1. 意义不同

301状态码表示永久重定向，即请求的资源已经永久转移到新的URL，搜索引擎会把新URL视为请求的有效资源，同时也会保留旧URL的搜索结果及排名。因此，建议重定向的页面使用301状态码。

302状态码表示暂时重定向，即请求的资源暂时转移到新的URL，搜索引擎会保留原始URL的搜索结果及排名，而不会更新新URL的信息，也不会把新URL视为请求的有效资源。

2. 缓存处理不同

使用301状态码的页面会被浏览器缓存下来，再次请求时会从缓存中读取，不会发送新的请求。而使用302状态码的页面不会被缓存，每次请求都会发送新的请求。

3. 隐私性不同

由于301状态码的特性，搜索引擎会保留原始URL的搜索结果及排名，可能会暴露网站的隐私性。而302状态码可以保护网站的隐私性，因为搜索引擎不会更新新URL的信息，也不会把新URL视为请求的有效资源。

总之，如果你需要重定向某个页面，可以考虑使用301状态码，但如果是暂时的重定向，可以使用302状态码。

## 如何验证CA证书的可靠性 `5`


CA证书是数字证书中最为常用和广泛使用的一种。验证CA证书的可靠性可以通过以下几个步骤：

1. 确认证书颁发机构（CA）的信誉度：要检查CA的信誉度，可以找到CA的官方网站或其他权威机构颁发的信任名录进行查看。如果CA是一家知名的、长期运营的CA机构，比如VeriSign、Comodo、Symantec等，就可以认为其证书的可靠度较高。

2. 确认证书中的相关信息是否正确：验证证书的基本信息包括证书的颁发者、过期时间、域名、公钥等。在进行这一步的时候，需要使用证书颁发机构的公钥进行验证。

3. 确认证书中的证书链：一份证书可能不仅仅是由颁发者颁发的，还可能是由多个颁发者和中间证书颁发机构一步步颁发的。这时需要通过证书链来验证证书的可靠性，证书链包括该证书的发行者、上级颁发者等等。

4. 验证证书的撤销状态：撤销状态表明该证书已被废除。可以通过查找证书颁发机构的证书吊销列表（CRL）、在线证书状态协议（OCSP）等进行验证。

以上是验证CA证书可靠性的主要步骤，需要综合以上四个步骤来确定一个CA证书是否可靠。同时，如果在实际使用过程中发现CA证书存在异常、警告等问题，应该立即停止使用该证书，并联系相关机构核实原因。

## 交换机工作原理 `4`


交换机是一个用于连接多台计算机网络的网络设备，其工作原理是利用MAC地址表来转发数据包。

具体来说，当一台计算机向网络中的另一台计算机发送数据时，交换机收到数据包并检查数据包中的目的MAC地址。交换机会通过自身维护的MAC地址表来判断数据包应该转发到哪个接口，从而实现局域网内的数据包传递。如果交换机在MAC地址表中找不到对应的MAC地址，则会向所有接口广播数据包，以寻找目的计算机。

当交换机未接收到任何数据包时，其MAC地址表将为空。但是，当交换机接收到一个数据包时，它会将源MAC地址和接口信息添加到MAC地址表中。之后，当交换机要向该MAC地址发送数据时，它就可以直接在MAC地址表中查找该地址所对应的接口并转发数据包，而不需要向所有接口进行广播。

交换机可以提高局域网内的传输效率，因为它可以根据MAC地址表将数据包直接转发到正确的目的地。同时，交换机还可以分段局域网，从而减少冲突和数据包的冗余传输，提高网络性能和稳定性。

## ICMP，ARP，IGMP原理 `4`


ICMP:

ICMP（Internet Control Message Protocol）是因特网控制报文协议，用于在网络中传递各种控制和错误消息。ICMP是IP协议的一个扩展，用于提供有关IP正常和异常处理的信息。常用的 ICMP 报文类型有：回显请求和回答、目的不可达、超时、时间戳请求和回答等。

ARP:

ARP（Address Resolution Protocol）地址解析协议，是用于解析IP地址到MAC（Media Access Control）地址的协议。当计算机需要与另外一台计算机通信时，尤其是在本地网络中，需要知道目标计算机的MAC地址，此时ARP就会发挥作用，通过广播的方式查询目标计算机的MAC地址，以便数据包能够正确传输到目标计算机。

IGMP:

IGMP（Internet Group Management Protocol）组管理协议，是用于在IP网络中支持多播通信的协议。它允许主机加入到一个多播组或离开一个多播组，以此实现多播通信。IGMP协议是UDP协议的一个扩展。当一个主机加入到某个多播组时，它会向所有主机发送一个IGMP报文，以通知它们自己已经加入了该多播组。

## ip地址和mac地址的区别 `4`
IP地址和MAC地址是计算机网络中两个重要的地址标识，它们之间有如下区别：

1. IP地址是逻辑地址，MAC地址是物理地址。 IP地址是一个逻辑概念，可以被配置和改变，而MAC地址是一个固定物理地址，唯一标识设备的网卡。

2. IP地址唯一标识网络中的一台设备，MAC地址唯一标识此设备的网卡。 IP地址是在计算机网络中用来标识一台设备的唯一地址，MAC地址是用来标识这台设备上网卡的地址。同一台设备在不同网络环境下拥有不同的IP地址，但是MAC地址是不变的。

3. IP地址与MAC地址使用的协议不同。 IP地址是在网络层使用的协议，它是TCP/IP协议族的一部分。MAC地址是在数据链路层使用的协议，它是局域网通信所使用的协议。

4. IP地址可以被路由器转发，MAC地址只能在同一局域网内通信。当数据包在不同网络之间传输时，会被路由器根据IP地址进行转发，但是MAC地址只能在同一局域网内通信，因为路由器只处理IP地址。

总之，IP地址和MAC地址都是计算机网络中的重要地址标识，但是它们的作用不同，协议不同，使用场景也不同。

## 网络层报文和报头 `4`


网络层是TCP/IP网络模型中的第三层，主要负责在不同网络之间进行数据传输和路径选择。网络层的核心功能是实现数据包的转发和路由选择，同时负责确保数据包正确地从源节点传输到目标节点。

网络层数据包通常被称为IP包，由两部分组成：IP报头和IP数据。IP报头包含了源地址、目的地址等重要信息，这些信息被用来决定数据包的传输路径和目标节点。IP数据则是传输的信息内容，数据包大小不固定，可以根据需要动态调整。

IP报头通常包含以下重要信息：

1. 版本号：指定IP协议的版本，现在广泛使用的是IPv4或IPv6；
2. 头部长度：指定IP报头的长度，通常为20个字节；
3. 区分服务（Differentiated Services, DSCP）：用来指定IP包的优先级；
4. 总长度：指定整个IP包的长度，包括IP报头和IP数据；
5. 标识符：该字段用于唯一标识一个IP数据包，以防止重复传输；
6. 标志位：用于指示是否可以对该IP包进行分片；
7. 分段偏移量：用于指示该IP包在整个数据流中的位置；
8. 时间到生存（Time To Live, TTL）：用于控制IP包在网络中的生命周期；
9. 协议：指定IP数据包携带的上层协议类型，如TCP、UDP等；
10. 校验和：用于检查IP包是否被送错或损坏。

总之，IP报头的作用是提供必要的信息，以确保IP数据包的正确传输和路由选择。

## TCP超时重传时间设置 `4`


TCP超时重传时间设置是指TCP传输控制协议在传输数据时，如果没有及时收到对方确认的数据包，需要重新发送数据包的时间。这个时间默认是由操作系统内核根据网络的状况自动计算得出的，但用户也可以进行手动设置，对网络传输的稳定性和效率有一定的影响。

具体地说，TCP协议通过一个称为RTO（Retransmission Time Out）的计时器来进行超时重传。如果发送方发送了一个数据包但没有收到确认，则开始启动RTO计时器，当计时器时间到达后，发送方会重新发送该数据包。

根据TCP协议标准，RTO的计算公式为：

RTO = SRTT + 4*RTTVAR

其中，SRTT表示平滑往返时间，RTTVAR表示平均往返时间的变化值。在实际使用中，SRTT和RTTVAR是通过对往返时间进行统计计算得出的。一般地，在网络质量稳定的情况下，用户可以将RTO设置为100ms左右；在网络波动较大的情况下，用户可以适当增大RTO值，但不宜过大。

需要注意的是，RTO时间并不可以任意设置，因为设置过小会导致数据包过多重传，浪费网络带宽和资源，而设置过大则会影响数据传输的效率。建议用户在实际应用中根据具体情况进行调整。

## TCP建立连接后传输数据的具体过程 `4`
TCP建立连接后传输数据的具体过程可以分为以下几个步骤：

1. 发送方将数据分成一定大小的数据包，并将每个数据包标记序号。然后将数据包通过TCP协议传送给接收方。

2. 接收方收到数据包后，回发一个确认消息给发送方，告知发送方它已经接收了数据包。同时，接收方会将接收到的数据包缓存起来，等待接收到所有数据包后，再将它们按照序号排序，组装成原始数据。

3. 发送方在接收到确认消息后，会将未确认的数据包重新发送，直到接收方将所有数据包都确认接收。

4. 接收方在接收到所有数据包后，会将它们组装成原始数据。组装完成后，接收方会再次发送一个确认消息给发送方，告知发送方已经成功接收所有数据包。

5. 发送方在接收到确认消息后，就知道数据包已经被成功传输到了接收方。TCP连接正式结束。

总结：TCP传输数据的过程中，发送方会将数据包逐一发送给接收方，并等待接收方给予确认。如果接收方未能确认收到数据包，则发送方会重新发送。接收方会将接收到的数据包缓存起来并排序，最终组装成原始数据。TCP传输数据是一种可靠的通信方式，保证数据的可靠传输。

## 浏览器禁用了Cookie以后还能用Session吗 `4`
在 Web 开发中，使用 Session 和 Cookie 可以为用户提供跨页面持久的状态保存。Session 将数据存储在服务器端，而 Cookie 则将数据通过客户端浏览器存储在本地。如果浏览器禁用了 Cookie，那么就无法在本地存储数据，但是 Session 仍然可以使用，因为 Session 的数据是储存在服务器上的，和浏览器本地 Cookie 无关。

但是需要注意的是，如果禁用了 Cookie，那么仍然需要在每个请求中将唯一的 session id 传递给服务器，以便服务器能够正确地将数据与特定的会话相关联。在没有 Cookie 时，可以通过 URL 重写或者将 session id 作为请求参数的方式来传递 session id。

总的来说，禁用了 Cookie 之后，仍然可以使用 Session，但需要注意一些额外的步骤来维护 session id。

## 简述DDoS的攻击方式与原理 `4`


DDoS（Distributed Denial of Service）是一种针对网络服务器的攻击方式，通常由多台计算机组合而成的攻击网络，短时间内向目标服务器发送大量流量，使其处理不了正常用户的请求，导致服务不可用。攻击者通常使用控制大量的肉鸡（被感染的计算机）进行攻击。下面是DDoS攻击的原理和方式：

原理：

1. 攻击者利用大量肉鸡发送流量：攻击者会通过各种方式控制大量的肉鸡，让它们发送海量的流量到目标服务器上。

2. 流量占满目标服务器带宽：攻击者的流量会超过目标服务器带宽承受范围，导致服务器处理正常用户请求的速度变慢或完全无法处理，从而导致服务不可用。

方式：

1. SYN Flood攻击：攻击者使用大量伪造的TCP连接请求（SYN数据包）占满服务器的连接队列，导致合法的TCP连接请求无法接入服务器，从而拒绝服务。

2. UDP Flood攻击：攻击者向目标服务器发送大量的UDP数据包，占满服务器的带宽，导致正常请求丢失，从而拒绝服务。

3. ICMP Flood攻击：攻击者向目标服务器发送大量的ICMP Echo请求（ping），使服务器的CPU和网络负载激增，导致服务器无法处理正常请求，从而拒绝服务。

4. HTTP Flood攻击：攻击者向目标服务器发送大量的HTTP请求，包括合法的和非法的请求，占满服务器的带宽和资源，导致服务不可用。

总之，DDoS攻击是一种常见的网络攻击方式，攻击者会利用大量的肉鸡、漏洞和技术手段占满目标服务器的网络资源，从而拒绝正常用户的请求，造成损失。

## CSRF的防御措施 `4`


CSRF (Cross-site request forgery)，中文名称跨站请求伪造，是一种常见的Web攻击方式，攻击者通过利用用户已经在浏览器中登录了的身份，伪造一个HTTP请求来操作目标网站，使用户完成一些非法活动。常见的场景是通过诱骗用户点击某个链接、进入恶意的网站，进而实施攻击。

为了防止CSRF攻击，请采取以下措施：

1. 请求验证

这是最常见也是最有效的防御措施之一。利用请求验证（CSRF Token）来防范CSRF攻击。在服务器渲染网页时，后端会生成一段随机字符串（CSRF Token），将其添加到表单中的隐藏域，并在session中保存一份，当用户提交表单时，后端会将其保存的Token值和表单中的Token值进行比较，来判断请求是否合法。

2. Referer验证

Referer是HTTP协议中一个用于标识请求来源的头部字段，使用该方法可以通过比对请求头中的Referer值和当前的域名判断请求是否合法。但是，由于该方法存在被伪造的风险。

3. SameSite属性

SameSite是一个Cookie属性，可以限制浏览器将Cookie发送到第三方网站，使得Cookie只有在同源情况下才会发送。可以使用SameSite属性来禁止CSRF攻击中的Cookie篡改以及Session固定攻击。

4. 防止用户受到攻击

进行用户安全教育和宣传，教育用户不要轻易点击来自未知来源的链接、不要在不可信的网站上输入个人信息等，避免自身成为攻击的对象。

5. HTTPS

在使用HTTPS协议时，浏览器会对每个请求进行加密，即使被攻击者的Cookie被获取了，攻击者也无法看清其中的信息，从而降低了被攻击的风险。

综上所述，以上几点措施是防御CSRF攻击的基本方法，要根据不同的情况综合使用他们。同时也要不断地关注相关的安全技术和最新的攻击手段，及时做出相应的调整和响应。

## Http中的content-type有哪些 `4`


HTTP中的Content-type指示了HTTP消息正文中的媒体类型（MIME Type）。常见的Content-type类型包括但不限于以下几种：

1. text/html：HTML网页

2. text/plain：普通文本

3. text/xml：XML文件

4. application/xhtml+xml：XHTML网页

5. application/xml：XML数据结构

6. application/json：JSON数据结构

7. application/x-www-form-urlencoded：表单数据提交

8. multipart/form-data：文件上传

9. image/jpeg、image/png、image/gif：图片文件

10. audio/mpeg：音频文件

11. video/mp4：视频文件

12. application/pdf：PDF文件

13. application/vnd.ms-excel：Excel文件

14. application/vnd.ms-powerpoint：PowerPoint文件

不同的Content-type类型对应不同的数据格式，服务端需要根据Content-type类型进行相应的消息解析处理，保证数据传输的正确性。

## http断点续传的实现机制 `4`


http断点续传指的是客户端在下载文件时，如果下载过程中中断了，下次继续下载时可以从中断的位置继续下载，不必从新的位置开始下载。

其实，http断点续传就是利用http协议中的range头字段来实现的。在http协议中，range头字段表示客户端需要部分内容。当客户端发起请求时，在http请求头部添加Range字段，Range字段指定需要下载的文件字节范围，服务器在响应头里返回206 Partial Content（部分内容）状态码，并在响应头里添加Content-Range字段，指定响应的文件字节范围。服务器根据Range字段请求范围读取相应部分的数据，然后返回给客户端，客户端接收到数据后继续以同样的方式发送请求，直到下载完整个文件。

在实现http断点续传时，客户端需要在本地维护一个变量记录已经下载的字节数，下次继续下载时，将该变量的值作为Range字段的起始值进行请求。服务端接收到请求后，读取文件中起始位置后的数据并发送给客户端，客户端将接收到的数据追加到已下载的数据之后即可。

要注意的是，目标服务器需要支持http 1.1协议的Range头才能实现http断点续传。同时，客户端和服务端的缓存也需要按照文件的下载范围进行区分，避免数据混乱。

## 简述CA证书 `4`


CA证书（Certificate Authority certificate）是由数字证书认证中心（CA）颁发的一种数字证书，用于证明一个网站或服务器身份的合法性。 

CA证书包含了一些加密的数据，其中包括网站或服务器的公钥、其它标识信息以及证书的签名等等。由于CA是一个已经被广泛信任的第三方机构，当一个网站或服务器的身份被CA证书认证中心所认可时，就可以被其它客户端所信任，从而确保网络通信的安全。

当用户在访问一个被CA证书认证的网站时，SSL证书会加密网站与用户之间的通信，保障传输的安全性，防止数据被窃取或篡改等情况。如果网站没有CA证书，浏览器等客户端就会发出警告，提示用户可能会存在访问非法网站的风险。

一般来说，CA证书具有以下特点：

1. 可靠性：CA数字证书认证机构是一个值得信赖的第三方机构，证书的真实性、准确性和合法性都可以得到保障；

2. 互用性：CA证书是全球通用的，任何国家或地区的用户都可以使用同一份证书；

3. 安全性：CA证书进行了严密的算法加密和数字签名，保证通信的安全性。

希望以上解释说明对您有所帮助。

## 简述HTTP的工作机制 `4`


HTTP（超文本传输协议）是一种应用层协议，它用于在Web浏览器和Web服务器之间传输数据。HTTP是基于客户端-服务器模型，其中，客户端发出一个HTTP请求，然后服务器返回一个HTTP响应。下面是HTTP工作机制的详细步骤：

1. 建立连接：客户端首先需要建立与服务器的TCP连接。一旦连接建立成功，客户端就能够向服务器发送HTTP请求了。

2. 发送请求：在建立连接之后，客户端会通过连接向服务器发送HTTP请求。该请求包含请求行，请求头和请求主体三部分内容。请求行包含请求方法（GET、POST等）和请求的URI（统一资源标识符），请求头包含请求的相关信息，例如请求的 MIME 类型和接受的语言类型等，请求主体包含一些参数和数据。

3. 服务器处理请求：服务器在接收到客户端发送的请求后，会先进行一些处理（例如检查权限、解析请求等），然后根据请求的 URI 执行相应的操作，并将结果返回给客户端。

4. 发送响应：当服务器处理完客户端的请求后，服务器会向客户端发送一个HTTP响应。该响应包含状态码，响应头和响应主体三部分内容。状态码用于指示请求的处理结果，响应头包含响应的相关信息，例如响应的 MIME 类型和字符集等，响应主体包含响应的数据内容。

5. 关闭连接：当客户端完成对服务器的请求后，它可以通过主动关闭连接的方式来结束当前连接。服务器也可以通过响应头来指示客户端在接收完响应后主动关闭连接。

以上就是HTTP的工作机制的基本步骤。HTTP协议是Web应用程序的基础，几乎所有的 Web 应用程序都是使用HTTP来实现客户端-服务器之间的通信的。

## Http建立连接的过程 `4`


HTTP建立连接的过程通常分为三个步骤：建立连接、数据传输、断开连接。

1. 建立连接

a. 客户端向服务端发送请求信息：当浏览器要访问某个 URI 的时候，浏览器就会向服务端发送如下格式的请求信息：

```HTTP
GET /index.html HTTP/1.1 
Host: www.example.com 
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8 
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; AS; rv:11.0) like Gecko 
...
```

其中第一行是“请求行”，标识了请求方式(GET)、URI(/index.html)、HTTP 版本号(HTTP/1.1)；第二行是主机名称；第三行是 Accept，表示客户端希望服务器发送的响应内容类型；第四行是 User-Agent，表示发送请求的客户端代理信息。

b. 服务端响应请求信息：在收到请求信息后，服务端会进行处理，若处理得到相应的资源并可以访问，则会响应如下格式的信息：

```HTTP
HTTP/1.1 200 OK
Content-Type:text/html;charset=utf-8
Content-Length:370
Server:Microsoft-IIS/7.5
...
```

其中第一行是状态行，标识了 HTTP 版本号(HTTP/1.1)、状态码(200)以及原因短语(OK)；第二行是响应头，表示响应数据的 MIME 类型；第三行是响应数据长度；第四行是服务器名称。

c. 确认连接：在完成以上两个步骤后，客户端与服务端成功建立连接。

2. 数据传输

在建立连接后，客户端与服务端可以进行数据的传输。HTTP 的传输协议是基于 TCP/IP 协议的可靠连接，也就是说，客户端与服务端之间的通信是面向连接的，

a. 客户端向服务端发送请求数据：客户端通过在建立连接后向服务端发送请求数据。

b. 服务端向客户端回送响应数据：服务端在接收到请求数据并完成处理后，向客户端回送响应数据。

c. 确认数据传输：当客户端接收到完整的响应数据后，就可以确认数据传输已经完成。

3. 断开连接

a. 客户端向服务端发送关闭连接请求：客户端在完成数据传输后，通过向服务端发送如下信息来提示服务端关闭连接。

```HTTP
Connection: close
```

b. 服务端向客户端回送确认信息：服务端接收到客户端发送的关闭连接请求后，会回送如下信息来确认连接已经关闭。

```HTTP
Connection: close
```

c. 断开连接：当客户端接收到服务端发送的响应信息并完成处理后，会关闭双向连接，结束一次 HTTP 请求响应过程。

## http协议属于哪一层 `4`
HTTP协议属于应用层。在OSI模型中，应用层是最高层，它为用户提供服务，并处理用户请求，同时也是最贴近用户的一层。HTTP协议作为一种应用层协议，它在Web上提供了数据交换的能力，并通过TCP/IP协议来进行数据传输。因此，HTTP协议主要实现了客户端与服务器之间的通信。

## Dubbo远程调用的实现原理 `4`


Dubbo 是一种开源的远程服务框架，它采用了Java高并发、分布式的优秀设计思想，降低了分布式系统的复杂度，提高了分布式系统的可伸缩性、容错性、可靠性。下面是 Dubbo 远程调用实现的原理。

Dubbo 远程调用实现原理中的关键是dubbo 协议，其背后的基本逻辑是客户端通过dubbo 协议向服务器发送请求，并获得响应信息。下面是 Dubbo 远程调用的基本流程：

1. 消费者调用远程接口

消费者通过 RPC 框架调用远程接口，客户端将发起 RPC 调用请求，这个请求包含了服务接口的具体信息（如：接口名称，方法名称，调用参数等）。

2. 通过 JDK 动态代理生成代理类

Dubbo 中使用的是接口代理的方式进行远程调用，使用 JDK 动态代理生成接口的代理类，这个代理类具体实现了请求的发送方式，以及响应的解析。

3. 通过负载均衡选择服务提供者

Dubbo 调用时候根据负载均衡策略，选择服务提供者节点，这个选择过程是通过注册中心进行，会维护当前活跃的服务提供者列表。

4. 调用对应的服务接口

调用对应的服务提供者节点上实现的接口方法。

5. 将返回结果返回给调用端

服务提供者将方法执行结果和服务端信息返回给客户端。

6. 将返回结果进行解码并返回

Dubbo 客户端拿到服务端的响应结果后，进行解码，并将结果返回给业务逻辑处理。

总的来说，Dubbo 远程调用的实现原理是通过 Dubbo 协议，负责将客户端的请求发送给服务端处理，完成服务端的一系列操作后，再将结果通过 Dubbo 协议返回到客户端，最后客户端进行响应结果解码，将结果返回给应用程序。

## 讲一下CORS `3`


CORS（Cross-Origin Resource Sharing）跨域资源共享，是一种浏览器安全机制，用于解决浏览器跨域访问的限制问题。

浏览器的同源策略是一种安全限制措施，它防止了来自不同源网页间的资源共享。同源是指协议、域名、端口相同，只有在同源的网页之间可以共享数据。若请求的资源与当前网页的源不相同，则浏览器会限制访问。

CORS是为了解决这个问题而生的。它允许一个网站的某个网页向另一个网站请求数据，就像请求自己的一样。CORS 通过添加一些特定的 HTTP 头信息，让浏览器知道哪些跨源请求是安全的，哪些是不安全的。

在服务端，通过设置响应头 Access-Control-Allow-Origin，来允许来自指定源的请求访问资源。例如：

```
Access-Control-Allow-Origin: https://www.example.com
```

这意味着只有来自 https://www.example.com 的请求才允许访问该资源。

在客户端，可以通过 XMLHttpRequest 发送跨域请求，浏览器会自动触发 CORS 机制。例如：

```
var xhr = new XMLHttpRequest();
xhr.open('GET', 'https://www.example.com/data.json', true);
xhr.withCredentials = true;
xhr.setRequestHeader('Authorization', 'Bearer ' + token);
xhr.send();
```

上述代码向 https://www.example.com 发送了一个 GET 请求，并携带了身份认证的 token。注意，使用 withCredentials 属性开启跨域请求携带 Cookie，必须同时设置服务端的 Access-Control-Allow-Credentials 响应头，否则请求会失败。

总之，CORS 是一种机制，用于实现浏览器跨域访问资源，通过简单的 HTTP 头信息交互，确保安全可靠。

## 网络模型为什么要分层 `3`


网络模型分层是为了将网络通信过程划分成多个层次，用于实现网络通信的各个功能，使得系统的构建和分析更加简单，同时提高了网络通信的可靠性、灵活性和可扩展性。

常见的网络模型分层有OSI参考模型和TCP/IP协议栈。

以OSI参考模型为例，它将网络通信分为7层，分别是：

1.物理层（Physical Layer）：负责传输比特流，并确保物理链路的可靠性；

2.数据链路层（Data Link Layer）：将比特流划分为帧，进行差错控制、流量控制等操作；

3.网络层（Network Layer）：负责将数据包从源节点传输到目的节点，进行路由选择、拆分和合并数据包等操作；

4.传输层（Transport Layer）：提供传输服务，确保数据完整性、可靠性和顺序性，如TCP和UDP协议；

5.会话层（Session Layer）：在应用程序之间建立和维护会话，负责数据交换时的同步、加密、解密等操作；

6.表示层（Presentation Layer）：将数据转换为应用程序可以理解的形式，如加密解密、数据压缩、数据格式转换等操作；

7.应用层（Application Layer）：为用户提供应用服务，如电子邮件、文件传输等。

通过分层，不同层次的协议和服务可以分别独立地进行设计和实现，不同的网络设备也可以按照需要实现相应的功能，从而使得整个网络系统更加灵活、可靠和高效。同时，分层也使得不同的网络技术可以更容易地进行集成和互联，促进了互联网的发展。

## cdn的原理 `3`
CDN是指内容分发网络，是一种加速网络的技术。CDN技术的原理基于缓存和负载均衡，利用多个节点在地理上分散的服务器来存储和分发网站的静态和动态内容。 

其原理如下：

1. 用户请求访问网站时，先会请求CDN节点，而非直接请求源站点。

2. CDN节点会检查用户请求的内容是否存在于自己的缓存中。

3. 若存在缓存，则直接将数据返回给用户。若不存在，则向源站点服务器请求数据。

4. 源站点服务器将数据返回CDN节点。

5. CDN节点将数据缓存起来，并返回给用户。同时将数据缓存到其他CDN节点，以备下次请求时使用。

6. 当下一个用户访问请求同样的内容时，CDN节点就可以直接从缓存中读取数据并返回，从而加速网站的访问。

总的来说，CDN的原理就是通过多地分布式节点的缓存和负载均衡来分担单个服务器的负载压力，并实现快速、高效、可靠的访问服务。

## NAT实现原理 `3`


NAT（Network Address Translation）即网络地址转换，是一种网络协议，可以将私有IP地址转换为公共IP地址，从而实现内网用户访问外网资源。NAT实现的基本原理是端口映射，即将内网主机发出的请求端口号映射为外网公网IP地址的特定端口号，使得内网主机的请求能够通过NAT设备发往公网。

NAT的实现可以分为以下几个过程：

1. 内网主机发出请求：内网用户向公网IP地址发起请求时，请求会被发送至NAT设备。

2. 源端口的转换： NAT设备会更改该请求的源端口，以保证NAT设备与其他外网主机之间的通讯不会发生冲突。

3. IP地址的转换： NAT设备会将请求中的源IP地址更改为NAT设备的IP地址，这样请求就成为了由NAT设备向外网发送的请求。

4. 目标端口的转换： NAT设备会根据预设的端口映射规则，将请求的目标端口映射为内网主机的对应端口号。

5. 发起请求： 最后，NAT设备向外网资源发起请求，并将其他外网的响应发送回内网主机。

总的来说，NAT实现的原理就是利用设备地址的翻译，实现从一个网络到另一个网络的转换，使得内网主机能够访问外网资源。

## ARP和RARP的区别 `3`


ARP和RARP都是网络通信中常用的协议，它们的主要区别如下：

1. ARP（Address Resolution Protocol）：用于将IP地址解析成对应的MAC地址，也就是在数据链路层和网络层之间进行地址转换，以便在局域网中能够正确地传递数据包。

2. RARP（Reverse Address Resolution Protocol）：与ARP相反，它的作用是将MAC地址解析成对应的IP地址，也就是在网络层和数据链路层之间进行地址转换，以便在通过光盘和硬盘等存储设备安装操作系统时，能够从网络中获取IP地址。

因此，ARP和RARP的作用不同，分别用于在不同的网络层次中进行地址解析。

## 子网掩码的作用 `3`


子网掩码是一个用于标识IP地址网络部分与主机部分的掩码，它同时也是TCP/IP网络协议中的一部分，用于对一个IP地址进行分组。

子网掩码的作用：

1. 用于判断一个IP地址的网络部分和主机部分，将IP地址分为网络ID和主机ID两个部分，方便在网络中进行通信。

2. 子网掩码可以用来判断两个IP地址是否在同一个子网中，可以根据子网掩码的值得出同一子网内的IP地址范围，方便路由器进行分组。

3. 子网掩码还有助于提高网络的安全性。在网络中，不同的主机可以分配不同的IP地址，并且按照网段来进行管理和控制。通过设置不同的子网掩码，可以限制不同用户之间的网络访问。

总之，子网掩码在TCP/IP协议中是非常重要的一部分，可以对网络进行有效的管理和安全控制。

## 列举并简述路由协议 `3`


一、路由协议的概念

路由协议是计算机网络中用于寻找和选择数据包传输路径的一种协议。通常，每个路由器都有一个路由表，路由表告诉路由器如何将数据包从一点传输到另一点。路由协议则帮助路由器更新和维护路由表。

二、路由协议的分类

按照路由协议的工作方式，可将路由协议分为以下两类：

1. 静态路由协议

静态路由协议是指路由表的内容由网络管理员手动配置，而不是由路由协议自动计算出来。静态路由协议通常用于小型网络或者网络拓扑结构稳定、不需要经常变动的网络中，其优点是运行简单，不会因路由协议出错而引起网络故障。缺点则是不够灵活，无法适应动态变化的网络拓扑结构。

常见的静态路由协议有RIP-1（路由信息协议第一个版本）、RIP-2、OSPF等。

2. 动态路由协议

动态路由协议是指路由器之间会自动发送信息和交换数据，从而动态地计算和更新路由表。当网络中的某个路由器状态发生变化时，路由器会自动更新路由表，使得数据包可以通过最优路径传输。动态路由协议的优点是灵活性高，可以适应动态变化的网络拓扑结构。缺点则是复杂度高，可能会消耗网络带宽和路由器处理能力。

常见的动态路由协议有RIP-2、OSPF、BGP等。

三、路由协议的特点

路由协议的特点如下：

1. 路由协议能实现自动路由选择，使数据包在网络中按最优路径传输，提高网络的传输速度和可靠性。

2. 路由协议可以适应网络拓扑结构的变化，保证网络的稳定性和可用性。

3. 路由协议需要占用一定的系统资源，包括带宽、内存和处理能力等。

4. 路由协议的性能和鲁棒性决定了网络的稳定性和性能。

四、结语

路由协议作为计算机网络中的重要组成部分，能够提高网络传输的效率和可靠性。在使用路由协议时，需要根据网络拓扑结构、带宽和系统性能等因素综合考虑，选择合适的路由协议类型和实现方案。

## Mac地址与IP地址的关系 `3`


Mac地址和IP地址是用于在计算机网络中识别设备的两种地址格式。它们之间的关系可以类比成一个地址与一个名称的关系。Mac地址是全球唯一的硬件地址，由设备制造商在生产时写入网络适配器的ROM中，用于唯一标识网络中的设备。IP地址则是由网络管理员在网络中分配的逻辑地址，用于标识在网络中运行的主机、路由器等设备。

在通信过程中，两台设备之间需要进行传输数据的话，需要经过层层的协议处理，其中包括确定目标设备的地址。首先，发送端通过ARP协议（Address Resolution Protocol）查询IP地址所对应的Mac地址，确定目标设备的硬件地址。每台设备都会在本地维护一个ARP缓存表，其中存储了已知的IP地址与对应的Mac地址，如果目标IP地址已经存在于缓存表中，则直接使用缓存中的Mac地址进行通信；如果不存在，则通过ARP广播的方式向本地网络中的所有设备发出ARP请求，请求对应IP地址所对应的Mac地址。当目标设备收到ARP请求，会回复其Mac地址，发送端将目标设备的Mac地址存储在ARP缓存表中，并用它来发送数据包。这样，两台设备就建立了通信连接，可以进行数据的传输。

因此，Mac地址和IP地址是在网络通信中不可或缺的两个关键因素，用于在二层和三层协议中标识设备。而它们之间的关系是，Mac地址用于在本地网络中唯一识别设备的硬件地址，而IP地址则是在全球范围内分配的逻辑地址，用于标识设备在互联网中的位置。

## IPv4地址与IPv6地址的区别 `3`
IPv4和IPv6都是用于标识网络设备的地址，但它们的结构和能够表示的地址空间有所不同。

IPv4地址长度为32位，使用点分十进制的形式表示，例如192.168.1.1。IPv4地址只有大约42亿个，已经不足以支持互联网快速增长的设备数量。

IPv6地址则长度为128位，使用冒号分隔的十六进制表示。例如2001:0db8:85a3:0000:0000:8a2e:0370:7334。IPv6地址的地址空间非常庞大，可提供几乎无限的IP地址。

IPv6与IPv4的另一个区别是在IP地址标识的设备之间通信的方式。IPv6支持更多的选项和功能，例如IPsec，可以提供更安全可靠的数据通信。

总之，IPv4地址和IPv6地址的区别在地址长度和表示形式上有所不同。IPv6地址比IPv4地址有更大的地址空间，以及更多的通信功能和选项。

## 使用udp还想保证数据不丢失如何处理 `3`


UDP是一种面向无连接的传输层协议，因此在发送数据时并不会保证数据不丢失。如果你想使用UDP传输数据并确保数据不丢失，可以采用以下方法：

1. 自己实现数据丢失的检测和重传机制。比如，每次发送数据时，确认对方是否已经接收到数据，如果对方未收到数据，则重新发送数据。但是这种方法需要大量的编程工作，并且在网络不稳定时容易出现问题。

2. 使用可靠的UDP库或框架，如ZeroMQ，Netty等。这些库或框架已经帮你实现了数据的检测和重传机制。你只需要编写简单的代码，就可以实现可靠的UDP传输。

3. 将UDP与其他协议结合使用，如TCP或HTTP。使用UDP传输数据时，可以在应用层对数据进行分段并添加序号，在TCP或HTTP协议上实现数据的重传。

总的来说，UDP是一种不可靠的协议，如果需要保证数据的可靠传输，就需要考虑其他可靠的传输协议。但在某些场景下，如视频直播、实时游戏等，UDP的低延迟和高吞吐量的特点更容易被利用。

## Tcp的慢启动 `3`


TCP的慢启动是一种拥塞控制算法，主要用于控制数据在网络中的传输速率，以防止网络拥塞。它在TCP连接启动时起作用，并在传输开始时探测网络的可用带宽。

具体而言，TCP的慢启动机制通过动态调整发送方的拥塞窗口（cwnd）来实现。在TCP三次握手完成后，发送方将初始的拥塞窗口设置为一个较小的值，一般为MSS（Maximum Segment Size，最大分段大小）的数量。然后，每当发送方接收到一个ACK确认报文，它就将cwnd增加一个MSS的大小，也就是说发送方可以发送多一个MSS大小的数据。

在TCP的慢启动过程中，因为拥塞窗口的增长速率是指数级别的，所以可以快速地探测网络的可用带宽。不过，如果发送方发送的数据太多，就可能导致网络拥塞，因此TCP的慢启动会根据网络的拥塞情况调整拥塞窗口的大小。如果网络出现拥塞，接收方将发送一个重复ACK报文告诉发送方某些数据包丢失了，发送方将减少cwnd的大小，以减缓发送速度。如果网络的拥塞情况得到缓解，则发送方将继续使用慢启动算法来增加拥塞窗口的大小。

总之，TCP的慢启动算法是一个用于控制数据传输速率的拥塞控制算法，可以根据网络的拥塞情况自动调整发送方数据的发送速度，以确保网络的稳定性和高效性。

## 发送方怎么判断丢包？ `3`
发送方可以使用确认机制来判断丢包。确认机制是指接收方在接收到数据包时，必须向发送方发送一个确认消息以告知发送方数据包已经被成功接收。如果发送方在一定时间内没有收到接收方的确认消息，则认为该数据包丢失。

在TCP协议中，发送方会为每个发送的数据包分配一个序列号，接收方在收到数据包后，会发送一个确认消息给发送方，确认消息中包含一个确认号，表示已经成功接收到序列号对应的数据包。如果发送方在规定的超时时间内没有收到确认消息，就认为该数据包丢失了，并且需要重传该数据包。

此外，发送方也会维护一个超时计时器，如果发送方在超时计时器时间内没有接收到确认消息，就会发送该数据包的备份数据包，以保证数据的可靠性。通过确认机制和超时计时器，发送方可以判断数据包是否丢失，并且可以采取相应措施，保证数据传输的稳定和可靠。

## Tcp的选择重传机制 `3`


TCP是一种可靠的传输协议，可以确保数据的完整性、有序性和可靠性。其中一个重要的机制就是选择重传（Selective Repeat）。

选择重传是TCP使用的一种重传机制。在传输数据时，TCP将数据分割成报文段并发送到对方，同时等待对方发送确认消息。如果对方没有及时发送确认消息，TCP就会认为数据丢失并进行重传。选择重传与Go-Back-N重传机制不同，Go-Back-N重传机制只能连续重传丢失的报文段，而选择重传机制可以选择性地重传特定的报文段。

当TCP发现某个报文段没有收到确认消息时，它会开启计时器并重传该报文段。如果在计时器超时之前，TCP接收到了该报文段的确认消息，计时器就会被关闭。如果在计时器超时之后TCP仍然没有收到该报文段的确认消息，就会再次重传该报文段。TCP会维护一个“发送窗口”，它指定了可以同时发送的未确认的报文段的数量。如果发送窗口被占满了，TCP就不能继续发送新的报文段，直到收到确认消息。

选择重传机制的优点在于，它可以避免在网络中出现的乱序和重复数据包。此外，选择重传也减少了网络拥塞的风险，因为它可以选择性地重传数据包，而不是全部重传。

总的来说，选择重传机制是TCP协议实现可靠传输的重要手段之一。

## 列举使用TCP协议的应用/场景 `3`


TCP（Transmission Control Protocol）是一种面向连接的、可靠的、基于流的传输层通信协议。它可以保证数据在传输过程中不会丢失、重复、失序，并且具备拥塞控制机制。无论是基于Web的应用，还是P2P文件共享，TCP协议都扮演了重要的角色。以下是使用TCP协议的应用/场景：

1. 网页浏览：当我们通过Web浏览器请求一个网页时，浏览器会向服务器发送一个TCP连接请求。一旦服务器确认并发送回应，TCP就可以在浏览器和服务器之间建立一条可靠的连接，确保数据传输的正确性。

2. 邮件发送：当我们通过邮件客户端发送一封邮件时，邮件客户端会在使用SMTP协议连接到邮件服务器时使用SMTP协议的TCP/IP协议栈。

3. 文件下载：当我们通过FTP或HTTP协议下载文件时，TCP保证了数据传输的可靠性。当文件传输过程中发生丢包或丢失数据时，TCP可以重发丢失的数据，直到完全传输完成。

4. 远程登录：远程登录也是使用TCP协议的一个重要应用场景。例如，SSH和Telnet协议都是基于TCP协议的，通过这两个协议可以实现在远程计算机上执行命令、编辑文件等操作。

总之，TCP协议是Internet上最常用的协议之一，已经被广泛应用于各个领域，如网络通信、Web浏览、电子邮件、文件传输等。

## 四次挥手出现TimeWait的条件 `3`


在TCP连接的断开过程中会出现四次挥手，它的目的是让通信的两端彼此确认对方已经收到了断开连接的请求。四次挥手的过程中，如果其中一方发送了FIN，但是另一方没有及时回应，就会出现TIME_WAIT状态。

一般来说，出现TIME_WAIT状态需要满足以下几个条件：

1. 当一方发送FIN请求时，对方还有数据需要处理。在这种情况下，如果一方不等对方处理完数据就立即发送最后的ACK确认，就会出现TIME_WAIT状态。

2. 当一方发送FIN请求后，对方发送了一个ACK，但是这个ACK在传输过程中被丢弃了，而对方并不知道ACK丢失了，所以它会再次发送ACK，这个时候就会出现TIME_WAIT状态。

3. 当一方发送FIN请求后，对方收到了这个请求并发送了ACK，但是这个ACK在传输过程中被延迟了。当它最终到达时，发送方可能已经认为连接已经关闭，如果这个时候发送方立即发送最后的ACK确认，就会出现TIME_WAIT状态。

4. 当一方发送FIN请求后，对方收到了这个请求并发送了ACK，但是这个ACK在传输过程中被重复的ACK替代了。最后，发送方在收到数据包后再次发送FIN请求，而另一方通过重复的ACK在之前已经确认了这个FIN请求，这个时候就会出现TIME_WAIT状态。

因此，四次挥手过程中任何一方不遵循正常的TCP协议规则，都有可能导致TIME_WAIT状态的出现。

## 三次握手中出现丢包现象如何处理 `3`


三次握手是TCP协议中建立连接的过程，分为以下三步：

1. 客户端向服务器发送SYN包，请求连接
2. 服务器接收到SYN包后，回复ACK包，表示连接已经建立
3. 客户端接收到ACK包后，再回复ACK包

如果在三次握手的过程中出现了丢包现象，那么就需要根据实际情况进行处理了：

1. 如果客户端发送的SYN包丢失，那么客户端就需要重新发送SYN包，以请求建立连接；
2. 如果服务器接收到客户端的SYN包后，回复的ACK包丢失，那么服务器就需要等待客户端再次发送SYN包，然后再回复ACK包，以建立连接；
3. 如果客户端接收到服务器的ACK包后，因为网络原因没有回复ACK包，那么服务器就需要再次发送ACK包，以确认连接已经建立。

总之，无论是哪一步出现了丢包现象，在发送重复的数据包之前，都需要等待一段时间，以确保数据包已经被接收端正确接收。如果尝试多次之后仍然没有建立连接，则需要检查网络是否正常，或者重新获取服务端的IP地址。

## TCP的报文格式 `3`
TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层协议，在网络通信中广泛使用。TCP使用三次握手建立连接，四次挥手关闭连接，通过序号和确认机制实现可靠数据传输。它的报文格式如下：

![TCP报文格式](https://img-blog.csdn.net/20170624201119831?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvTXlBZG1pbkJveTk=)

TCP协议的报文格式，主要包括以下各个字段：

1. 源端口号（Source Port Number）：2个字节，表示发送端口号，即发送方发送数据时所使用的端口号。
2. 目的端口号（Destination Port Number）：2个字节，表示接收端口号，即接收方接收数据时所使用的端口号。
3. 序号（Sequence Number）：4个字节，表示本数据段的第一个字节的序号，用于接收方确认接收的数据段是否为按序到达的数据段。
4. 确认号（Acknowledgement Number）：4个字节，表示期望收到下一个字节的序号。在确认数据段的同时，也就告诉发送端，从这个序号开始之前的所有数据都已经正确的被接收了。
5. 数据偏移（Data Offset）：4位，指明TCP头部的长度，以4字节为单位，TCP头部最多有15个4字节。
6. 保留（Reserved）：6位，保留备用，没有实际用途。
7. 标志位（Flags）：共6个标志位，分别是URG、ACK、PSH、RST、SYN和FIN，用于控制TCP的连接建立、连接维护和连接释放。
8. 窗口大小（Window Size）：2个字节，表示接收方的接收窗口的大小，用于控制发送方的数据发送速度。
9. 校验和（Checksum）：2个字节，用于校验TCP头部和数据是否都能正常传输。
10. 紧急指针（Urgent Pointer）：2个字节，表示紧急指针的值，用于紧急数据的传输。
11. 选项（Options）：可选字段，长度不定，由长度字段来指定。可用来协商通信中的一些高级功能，如窗口扩大、时间戳、选择确认等。

以上就是TCP协议报文格式的详细解析。

## Http重定向的返回状态码 `3`


Http重定向是一种常见的场景，例如网站网址变更、页面不存在时，就会引起服务器对用户的请求进行重定向。Http重定向常常会伴随着一个状态码，常见的状态码如下：

1. 301 Moved Permanently：表示被请求的资源已经永久移动到新位置，新URL就在响应头部Location中，之后应使用新URL进行访问，搜索引擎在抓取新内容的同时也将旧的网址替换为了重定向之后的新网址。

2. 302 Found：表示被请求的资源已经临时移动到新位置，新URL就在响应头部Location中，之后应使用新URL进行访问，搜索引擎不会更新资源链接，而是继续使用原有地址进行链接跳转。

3. 303 See Other：表示由于请求对应的资源存在另外一个URI，应使用GET方法定向获取请求的资源。在HTTP/1.1中，303状态码被禁止使用。

4. 307 Temporary Redirect：表示请求的资源临时从不同的URI中获取，因此重定向位置可能会发生变化。与302状态码相同，但请求方应该保留原有的HTTP请求方式和数据，而不管新的资源位置是在哪里或者如何变化。

## http1.1 为什么无法做到多路复用 `3`


HTTP/1.1 是顺序处理响应的，也就是说它只能以固定的步骤完成一个请求/响应过程。因此，每次只能处理一个请求，并且必须等待前一个请求的响应返回后才能处理下一个请求。

这也就意味着，如果一个网站中有很多资源需要下载，那么在 HTTP/1.1 下，浏览器必须发起多个 TCP 连接，且每个连接只能下载一个资源。这会导致不必要的延迟和资源浪费。

而多路复用是指在一个连接上同时传输多个请求/响应。也就是说，它可以通过同时发送多个请求和接收响应来提高网络传输效率。例如，在一个多路复用的连接上可以同时下载多张图片，而不必等待前一张图片下载完成。

由于 HTTP/1.1 开始时并没有设计考虑多路复用，因此它不能实现多路复用。直到 HTTP/2 出现后，才开始支持多路复用。HTTP/2 的多路复用是通过帧的方式来实现的，它允许多个请求在同一连接上交错发送。

## 对比分析简单请求与预检请求 `3`


简单请求和预检请求都是跨域数据请求中常见的两种请求方式，在进行跨域数据请求时，浏览器会根据请求的类型进行不同的处理。

简单请求指的是符合以下三个条件的请求：

1. 请求方法是 GET、HEAD 或 POST 中的一种；
2. HTTP请求头信息不超出以下几种字段：Accept、Accept-Language、Content-Language、Content-Type 且 Content-Type的值只有text/plain、multipart/form-data、application/x-www-form-urlencoded、application/json中的一个；
3. 请求没有使用cookie、HTTP认证或者TLS客户端证明。

对于符合上述条件的请求，跨域请求可以直接发送，无需进行预检验。

而预检请求则指的是在发起真正的跨域请求之前，发送一个 `OPTION` 方法的请求。通过这个请求，客户端可以知道是否可以将真正的跨域请求发送到服务器。预检请求会携带额外的请求头，其中包括服务器可以接受的请求方式，以及对于请求所携带的头信息的支持情况。

采用预检请求的的优点是，服务端可以提前告诉客户端是否可以跨域请求，从而放置了安全风险，同时也方便了程序员开发操作。但是也存在一定的缺点，例如需要发出一次额外请求、预检请求的内容与真实请求不完全一致会导致失败等等。

总的来说，需要根据具体情况综合考虑使用哪种请求方式。

## Socket与Channel的区别 `3`


Socket和Channel都是进行网络通信的重要概念，它们的主要区别如下：

1. Socket

Socket是构建网络应用程序的传统API，它基于传输层协议，可用于实现TCP、UDP等协议的通信。Socket在TCP协议下采用面向连接的通信方式，通过建立连接、进行数据传输、断开连接等步骤来完成数据交换。而在UDP协议下，Socket采用无连接的通信方式，只需将数据直接发送给指定目标即可。Socket通常是阻塞的，即进程会一直等待接收数据，直到有数据到来。

2. Channel

Channel是Java NIO中新引入的概念，它采用非阻塞IO模型，能够实现更高效的网络通信。Channel与Socket的关系类似于流(Stream)和Reader/Writer之间的关系，它提供了一种基于Buffer的数据传输方式，不需要像Socket一样阻塞等待数据，而是可以在数据到来时立即进行传输。Channel可以支持多种传输协议，包括TCP、UDP、文件IO等，因此更加灵活。

总的来说，Socket适用于传输数据量、交互频率较低的情况，而Channel则更适合于处理高并发、大量数据传输的场景。

## Socket的系统调用 `3`
Socket是在计算机网络中实现应用程序之间网络通信的基础操作系统的软件接口。它将IP地址和端口号组合成一个套接字（socket），应用程序通过操作套接字来进行网络通信。在操作系统中，使用Socket系统调用来创建、绑定、监听、连接和发送/接收数据。

1. 创建套接字

在使用Socket进行网络通信前，需要先创建一个套接字（socket）。套接字可以通过调用socket()函数来创建，该函数的返回值为一个文件描述符。文件描述符是操作系统内部用来标识打开的文件或设备的整数值，包括套接字。

2. 绑定套接字

创建套接字后，需要将其绑定到一个特定的IP地址和端口号上，以便其他应用程序可以通过该IP地址和端口号与该套接字进行通信。可以通过调用bind()函数来绑定套接字，传递的参数为套接字描述符、sockaddr_in结构体变量（包含IP地址和端口号信息）以及结构体的长度。

3. 监听套接字

当将套接字绑定到IP地址和端口号上后，该套接字处于监听状态，等待其他应用程序的连接请求。可以通过调用listen()函数来开启套接字的监听模式，传递的参数为套接字描述符和已连接队列的最大长度。

4. 接受连接请求

当其他应用程序向该套接字发送连接请求时，需要通过调用accept()函数来接受这些连接请求，返回连接的套接字描述符。accept()函数将阻塞等待连接请求，直到有连接请求到来时才返回。

5. 连接服务器

如果客户端应用程序需要连接到服务器应用程序，可以使用connect()函数与服务器建立连接。connect()函数需要传递服务器的IP地址、端口号以及套接字描述符。

6. 发送和接收数据

连接建立以后，可以使用send()函数向目标主机发送数据，该函数需要传递套接字描述符、要发送的数据以及数据的长度。如果需要接收数据，可以使用recv()函数接收数据，该函数需要传递套接字描述符、接收缓冲区以及缓冲区的长度。

以上就是Socket系统调用的基本流程和常用函数。通过使用这些函数可以实现基于网络通信的应用程序。

## 说说对WebSocket的了解 `3`


WebSocket是一种在单个TCP连接上进行全双工通信的协议。相较于HTTP协议，它具有实时性强、开销小、无需频繁建立连接等优点。WebSocket协议的实现需要客户端和服务器端互相配合，支持普通文本和二进制数据的双向传输。现在，WebSocket已被广泛应用于Web端实时通信和游戏开发等领域。以下是一些常见的问题及其解答：

1. WebSocket的工作原理是什么？

WebSocket协议建立在HTTP协议之上，通过HTTP的握手协议来建立起WebSocket连接。在建立连接之后，WebSocket协议可以在客户端和服务端之间实现双向通信，而无需频繁建立连接。

2. WebSocket的优缺点是什么？

WebSocket的优点包括实时性强，通信开销小，无需频繁建立连接等。但是，WebSocket仅能在支持该协议的浏览器或客户端上使用，对于不支持WebSocket的浏览器或客户端，仍需使用传统的HTTP协议实现双向通信。

3. WebSocket与HTTP的关系是什么？

WebSocket协议建立在HTTP协议之上，通过HTTP的握手协议来建立起WebSocket连接。在建立连接之后，WebSocket可以实现双向通信，而无需频繁建立连接。因此，WebSocket与HTTP协议是互相补充的关系。

4. WebSocket在Web开发中的应用场景有哪些？

WebSocket在Web开发中的应用场景非常广泛，最常见的是实现实时通信、聊天室、游戏开发等。此外，WebRTC技术也基于WebSocket协议实现，用于浏览器之间的音视频通信。

总的来说，WebSocket协议虽然相对较新，但目前已在Web领域中得到了广泛的应用和发展，未来其应用前景也将越来越广泛。

## RPC实现的基本原理 `3`


RPC全称为Remote Procedure Call，即远程过程调用。它的基本原理是允许一个进程通过网络调用另一个进程的函数或方法，实现分布式系统中的进程间通信。

其基本流程如下：

1. 客户端调用本地的stub(代理)函数，传递函数参数。

2. 客户端stub将参数进行打包，并通过网络发送到远程服务端。

3. 服务端stub接收到客户端请求后，将请求请求解包，并调用本地的真正处理函数/方法。

4. 真正的处理函数/方法处理完请求，将结果返回给服务端stub。

5. 服务端stub将结果进行打包，通过网络发送回客户端。

6. 客户端stub接收到响应结果后，进行解包，将结果返回给客户端。

在RPC中，stub是一个代理程序，它存在于客户端和服务端之间，负责将参数打包和解包，同时还可以提供本地的服务发现、路由，包括负载均衡等功能。

此外，RPC还需要具备以下几点：

1. 序列化协议：用于将请求响应等数据打包以及解包。

2. 通信协议：用于通信，例如TCP、HTTP等。

3. 接口定义语言(IDL)：用于定义客户端和服务端之间通信的接口。

4. RPC框架：用于协调和管理整个RPC的调用过程，如Dubbo、gRPC等。

总之，RPC实现的基本原理是通过代理函数将远程服务端的函数调用转换为本地的函数调用，最终实现分布式系统中的进程间通信。

## Nginx的作用与优缺点 `3`
Nginx是一个高性能的开源Web服务器软件，它也可以作为反向代理服务器、负载均衡器和HTTP缓存等多种用途。下面来详细回答Nginx的作用与优缺点。

# 作用：
1. 高性能：Nginx采用事件驱动的异步非阻塞模型，可以处理大规模高并发请求。
2. 动态反向代理：Nginx可以根据请求动态地将请求路由到不同的服务器上，从而实现负载均衡和高可用性。
3. 静态文件服务：Nginx可以高效地提供静态文件服务，减轻后端服务器的负载，同时减少了静态资源请求的带宽消耗。
4. HTTP缓存：Nginx可以缓存动态页面的结果，以提升响应速度。
5. 强大的扩展性：Nginx提供了丰富的模块和API接口，可以方便地进行二次开发和扩展。

# 优点：
1. 高性能：Nginx采用了高效的事件驱动模型和多进程结构，可以处理百万级并发请求。
2. 轻量级、低资源消耗：Nginx是一个轻量级的Web服务器，可以运行在低资源的服务器上，并且非常稳定。
3. 高扩展性：Nginx提供了超过100个第三方模块，可以很方便地进行扩展。
4. 高可靠性：Nginx支持热部署和平滑升级，可以在不影响服务的前提下进行版本更新，从而保证了高可靠性。
5. 灵活的配置：Nginx的配置比较灵活，允许设置Rewrite规则、代理设置等操作。

# 缺点：
1. 不支持动态内容：Nginx不支持处理动态请求，需要结合其他技术（如PHP、NodeJS等）来处理动态请求。
2. 技术门槛高：Nginx需要了解一定的操作系统和网络知识，使用起来可能需要一些技术门槛。
3. 配置复杂：Nginx的配置比较灵活，但是也比较复杂，需要一定的时间和经验来熟悉和掌握。

## 如何配置Ngnix反向代理 `3`


Nginx反向代理配置是一个常见的服务器配置，主要用于将来自客户端的请求转发到后端服务器，如应用程序服务器、数据库服务器等。以下是Nginx反向代理的配置步骤：

1. 安装Nginx服务器；
2. 找到Nginx配置文件nginx.conf（通常位于/etc/nginx/目录下）；
3. 如果需要，可以创建一个新的server block（virtual host）来处理反向代理请求。例如：

```
server {
    listen       80;
    server_name  example.com;

    location / {
        proxy_pass  http://backendserver:port/;
    }
}
```

其中，listen指定监听端口和IP地址，server_name指定主机名或域名。最重要的是location /块，其中proxy_pass指定要代理的目标服务器地址；另外的配置项包括proxy_set_header用于设置代理服务器的请求头信息。

4. 重载Nginx配置：
```
sudo nginx -t
sudo service nginx reload
```

这样Nginx就会启动并开始代理请求到后端服务器。

总结起来，配置Nginx反向代理简单来说，就是创建一个服务器块（virtual host），并在其中使用location /指明代理请求的目标服务器地址。

## Dubbo与SpringCloud的差异 `2`
Dubbo和Spring Cloud都是微服务框架，用于构建分布式系统，但是它们的架构设计和技术选型有很多不同点。

Dubbo是阿里巴巴内部开源的RPC框架，主要特点是高性能、多语言支持。它采用了SOA（面向服务架构）的风格，支持多种协议和注册中心。Dubbo还提供了服务治理、可视化管理等丰富的扩展支持，并自带限流、容错、负载均衡等功能，能够满足高并发、高可用的服务调用场景。

而Spring Cloud则是Spring Boot生态的一部分，是一个集成了多种分布式系统开发工具的框架。它提供了基于RESTful编程风格的微服务架构，并使用Eureka、Zookeeper等注册中心实现服务发现和负载均衡。Spring Cloud还提供了API网关、配置中心、断路器、分布式跟踪等组件，涵盖了微服务开发的常见需求。相对于Dubbo，Spring Cloud的优势在于更加灵活的部署方式，更加丰富的组件支持，而且用于Java语言开发。

总体来说，Dubbo更适合用于环境稳定、性能要求高的系统，而Spring Cloud则更适合于快速迭代、高灵活性、易于部署和维护的分布式系统。

## cors的返回头、cors预请求，什么时候会出发预请求 `2`


CORS（Cross-Origin Resource Sharing）是一种用于在浏览器和服务器之间进行跨域资源访问控制的机制。在进行跨域资源访问时，浏览器会发送一个预请求（Preflight Request）以检查服务器是否支持该跨域请求。当服务器收到预请求时，需要在响应头中添加特定的CORS返回头，否则浏览器会阻止跨域资源的访问。

常见的CORS返回头包括以下几个：

- Access-Control-Allow-Origin：指定允许跨域访问的来源地址或通配符（*）表示允许来自所有地址的跨域请求。
- Access-Control-Allow-Credentials：表示是否允许前端向后端发送认证信息（如Cookie和Authorization Header）。
- Access-Control-Allow-Headers：指定允许跨域请求发送的自定义请求头。
- Access-Control-Allow-Methods：指定允许跨域请求发送的请求方法。

当浏览器发起跨域请求时，会根据请求头中的Origin字段先发送一个预请求（OPTIONS请求），以询问服务器是否支持该跨域请求，并验证该请求是否允许发送到目标服务器。浏览器会检查该请求的Method、Headers、Credentials等信息，并通过Access-Control-Request-Method、Access-Control-Request-Headers等请求头告诉服务器需要哪些CORS返回头。

只有当服务器正确响应了预请求中的信息，并返回特定的CORS返回头后，浏览器才会发送真实的跨域请求。因此，预请求是在跨域请求之前发送的，用于检查服务器是否允许该跨域请求发送，以保证浏览器的安全性。对于一些复杂的跨域请求（如使用了自定义请求头和请求方法的跨域请求），浏览器会先发送预请求进行验证。

## 如何预防XSS攻击 `2`
XSS（Cross-Site Scripting，跨站脚本攻击）是指攻击者在目标网站上注入恶意脚本，使用户在访问该网站时执行该恶意脚本，从而获取用户的敏感信息或者进行其他攻击。

预防XSS攻击需要从以下几个方面入手：

1.输入过滤：对于用户提交的数据进行过滤，删除或者转义掉特殊字符，例如<、>、&、"、'等符号。可以使用现成的安全框架或者自己编写过滤函数。

2.编码转换：将所有用户输入的数据转换为HTML实体编码，例如将">" 转换为 &gt;，这样就可以防止浏览器将输入的内容解释为HTML标签。

3.对Cookie设置HttpOnly属性：HttpOnly属性可以防止JavaScript读取和修改Cookie，避免了Cookie被劫持。通过在Cookie中设置HttpOnly属性，可以将Cookie保护起来，使得只有在HTTP/S请求时才可以访问。

4.CSP（Content-Security-Policy）：CSP是一种安全策略，可以指定哪些外部资源可以加载到网页中，例如脚本、图片、样式表等，可以有效防止XSS攻击。当浏览器遇到外部资源的请求时，会根据CSP中的策略判断是否允许加载该资源。开发者可以通过设置CSP来限制网页中JavaScript的运行环境，从而降低XSS攻击的风险。

5.使用HTTPS：HTTPS可以通过SSL/TLS协议加密与服务器之间的通信，避免中间人攻击和窃听。这样可以有效保护用户的数据不被劫持和泄漏。

6.对Cookie进行签名和加密：对Cookie进行签名和加密可以有效防止Cookie的篡改和窃取。对于敏感信息的Cookie，可以使用类似JWT（JSON Web Token）的方式进行数据签名和加密。

通过以上几种措施，可以有效地预防XSS攻击。同时，开发人员也需要时刻关注新的漏洞和攻击手段，适时更新安全策略和防范措施。

## 数据链路层有哪些协议 `2`


数据链路层（Data Link Layer）是 OSI 参考模型中第二层，负责将底层物理层提供的比特流划分为数据帧，并管理帧的流控制和错误检测等任务。以下是数据链路层中常用的协议：

1. 以太网协议（Ethernet protocol）：是一种局域网（LAN）协议，传输速度快，广泛应用于互联网。

2. WiFi协议（Wireless Fidelity protocol）：是一种无线局域网（WLAN）协议，能够实现近距离无线通信。

3. 令牌环协议（Token Ring protocol）：是一种基于环形拓扑结构的局域网协议，使用令牌机制实现数据的发送和接收。

4. PPP协议（Point-to-Point Protocol）：是一种点对点协议，用于串行通信，主要应用于拨号网络和广域网接入。

5. HDLC协议（High-level Data Link Control protocol）：是一种广泛应用于通信行业的数据链路层协议，具有流量控制、差错校验和可靠性控制等功能。

6. SLIP协议（Serial Line Internet Protocol）：是一种简单的串行线路协议，用于连接一台计算机与因特网。

7. CSLIP协议（Compressed Serial Line Internet Protocol）：是一种压缩版的SLIP协议，用于提高串行连接速度。

8. PLIP协议（Parallel Line Internet Protocol）：是一种基于并行通信线路的协议，用于连接一台计算机与因特网。

9. ARP协议（Address Resolution Protocol）：是一种将网际协议（IP）地址映射到物理地址的协议。

10. RARP协议（Reverse Address Resolution Protocol）：是一种将物理地址映射到IP地址的协议。

## IP协议是否可靠并说明原因 `2`


IP协议是一种不可靠协议，其主要原因包括以下两个方面：

1. IP协议不保证数据包的可靠性
当一个数据包通过IP协议发送时，它只包含了最基本的信息，包括源IP地址和目标IP地址，并不会校验数据包的完整性和正确性。在传输过程中，如果数据包出现了错误或者丢失，IP协议并不会进行重传或者纠错，而是将其丢失。因此，IP协议并不保证数据包的可靠性。

2. IP协议不保证数据包的顺序
当多个数据包通过IP协议发送到同一个目标地址时，它们可能会沿着不同的路径到达目标地址，这会导致数据包的到达顺序和发送顺序不一致。因此，IP协议并不保证数据包的顺序。

虽然IP协议本身不可靠，但是它和其他传输协议（如TCP）一起使用可以提供可靠性的数据传输。在TCP协议层面，它会使用IP协议传输数据包，并进行校验和重传等机制，确保数据的可靠传输。

## 二层交换机和三层交换机的区别 `2`


二层交换机和三层交换机都是局域网交换设备，但是它们的功能和应用场景有所不同。

二层交换机是根据MAC地址来转发数据包的交换机，它可以学习网络中各个设备的MAC地址，并根据MAC地址来选择正确的接口将数据包转发到目标设备。二层交换机仅仅工作在OSI模型中的第二层（数据链路层），因此只能进行二层的转发，无法进行IP地址的路由。二层交换机的主要作用是加速局域网内部的数据传输，通常应用于环境单一、规模不大的网络，例如企业的部门内部网络、宿舍楼等。 

三层交换机是在二层交换机的基础上增加了路由功能的交换机，可以根据IP地址，通过具体的路由表信息或者动态路由协议，将数据包高效地转发到目标设备。所以，三层交换机不仅可以进行二层的转发，还可以进行IP地址的路由，属于综合性能更强的交换机。三层交换机主要应用于规模较大、网络结构复杂的企业网络中，例如酒店、医院等。

因此，二层交换机和三层交换机的区别在于功能和应用场景：二层交换机主要用于加速局域网内部的数据传输，而三层交换机不仅能加速局域网内部的数据传输，还能进行IP地址的路由，并应用于规模较大、网络结构复杂的企业网络中。

## 分析说明IP层协议 `2`


IP层是互联网协议栈中的网络层协议。它负责在不同计算机之间传送数据包，将数据通过不同网络节点路由到目的地。以下是IP层协议的分析说明：

1. IP地址：IP地址是一个32位的二进制数字，通常表示为4个十进制数，每个数的范围是0到255，例如192.168.0.1。IP地址分为公网IP和私有IP，私有IP地址只能在局域网内部使用，而公网IP地址可以在互联网上使用。

2. IP协议头：每个IP数据包都包含有一个IP协议头，它包含源IP地址、目的IP地址、协议版本、服务类型、包长度、标识符、片偏移、TTL、协议类型、校验和等信息。这些信息帮助路由器将数据包传递给正确的目标计算机。

3. IP协议类型：IP协议头中的协议类型指定了上层协议的类型，例如TCP、UDP、ICMP等。这些协议共享一个IP地址，因此路由器需要检查数据包的协议类型，以便将数据包传递给正确的上层协议。

4. 路由选择：在互联网中，IP数据包需要通过多个路由器进行转发才能到达目标计算机。IP层的路由选择算法可以选择最佳路径，以确保数据包能够快速且可靠地到达目的地。

总之，IP层协议是互联网通信中的基础，它为其他协议提供了一种可靠的基础通信结构。它使计算机能够通过互联网相互通信，实现数据交换和资源共享。

## UDP为什么快？ `2`


UDP（User Datagram Protocol）是一种面向无连接的传输层协议，相比于TCP（Transmission Control Protocol），它有如下特点：

1. 数据包大小限制较小：UDP数据包的最大长度为64KB，而TCP数据包的最大长度为1KB（实际以太网限制为1500字节）。这个限制使得UDP协议的传输效率高，因为数据包短小，可以更快地传输和处理。

2. 不需要建立连接：在TCP协议中，传输前需要先建立连接，传输结束后需要断开连接，这里涉及到三次握手和四次挥手，这些过程会增加网络延迟。而UDP协议不需要建立连接，只需简单的发送和接收数据包。

3. 没有数据校验、重传机制：UDP协议对数据的完整性和可靠性不做严格的检查和保证，因此没有TCP那样的数据校验和流量控制机制。这也使得UDP协议在网络传输中更为快速。

总之，UDP协议没有TCP那么复杂，它在需要快速传输而可靠性较低的应用场景下表现得更为出色。但是，需要注意的是UDP无法保证数据的完整性和顺序性，因此适用于一些不要求数据可靠性和顺序性的应用，比如视频和音频的流媒体传输。

## 第三次挥手，如果客户端挂了，
服务端拿不到客户端响应，如何应对？ `2`


在TCP中，建立连接时是三次握手，断开连接时是四次挥手，其中第三次挥手是客户端通知服务端客户端不再发送数据的消息。在正常情况下，服务端发送完ACK之后，就关闭了连接，等待客户端发送FIN；客户端接收到ACK后，一定时间内如果没有接收到服务端的关闭连接消息，就会发送FIN来关闭连接。

但是，如果客户端挂了，服务端就拿不到客户端的响应，会导致服务端一直等待客户端发送FIN，这就进入了TCP的“半关闭”状态。为了避免这种情况，服务端可以采用TCP的超时重传机制来判断是否需要关闭连接，即如果一段时间内一直没有收到客户端的响应，就自动关闭连接，释放资源。

另外，在一些需要保证可靠性的场景下，服务端可以要求客户端发送心跳包，以确保客户端仍然存活。如果客户端长时间没有发送心跳包，服务端就断开连接，释放资源。这种机制可以有效地防止由于客户端故障导致的连接阻塞等问题。

## 如何验证传输报文是否完整？ `2`


在计算机网络中，验证传输报文是否完整通常使用校验和和CRC校验两种机制：

1. 校验和：在发送数据时，通过对数据的每一位进行简单的加和，将结果一起发送出去。接收方在收到数据后，也进行相同的操作并将结果与发送方发送的校验和进行比较。如果两者一致，则说明数据传输过程中没有出现数据损坏。

2. CRC校验：CRC是循环冗余校验，它的检错能力比校验和强。CRC校验在计算校验和时不仅考虑了数据值，还考虑了幂次的大小。它通常使用多项式计算出一个校验值，发送方将该值附加到数据末尾发送出去，接收方在接收数据后也通过相同的多项式计算出校验值，对比校验值是否一致，以此来验证数据传输是否完整。

以上，希望对你有所帮助。

## 如果第一次握手后，服务端宕机会怎样？ `2`


TCP协议进行通信时，TCP连接的建立需要三次握手。握手过程中，客户端和服务端会交换数据包，以确认数据包能够发送到对方并被接收到。具体握手过程分为以下三步：

1. 客户端向服务端发送SYN数据包，请求建立连接。

2. 服务端接收到客户端的SYN请求后，向客户端发送SYN/ACK数据包，确认请求，并请求建立连接。

3. 客户端接收到服务端的SYN/ACK请求后，向服务端发送ACK数据包，确认建立连接。

如果第一次握手后，服务端宕机了，那么客户端会一直等待服务端发回的SYN/ACK数据包，因为这个数据包不会到达客户端。在等待了一段时间后，客户端会发送一个RST数据包，通知网络连接已经失效，然后结束这个连接。也就是说，TCP连接无法建立并被中止。

## 滑动窗口的大小是如何确定的？ `2`


滑动窗口是一种常用的算法，用于解决一些需要基于连续、非重叠窗口数据进行分析和处理的问题。其原理是将需要处理的数据分成固定长度的窗口，然后计算每个窗口的结果，再进行汇总分析。而滑动窗口的大小一般是根据具体问题和需求来确定的。

在实际应用中，滑动窗口的大小往往受到以下因素的影响：

1. 数据量大小：如果需要处理的数据量很大，那么窗口的大小可以适当增大，以减少数据的读取和处理次数，提高计算效率。

2. 数据粒度：如果需要分析粒度更细的数据，则可以选择更小的窗口大小。

3. 分析目的：不同的分析目的需要对数据进行不同的切割和处理，因此需要根据具体的分析目的来确定滑动窗口的大小。

总之，滑动窗口的大小并没有一个固定的标准，需要根据具体问题和需求来灵活选择。

## 什么是连接半打开状态 `2`


连接半打开状态（half-open connection）是一个网络连接过程的状态，指的是TCP/IP协议中的一个特定状态。TCP协议允许设备之间建立可靠的网络连接，其中包括三个阶段：建立连接、数据传输和连接断开。在“建立连接”阶段中，客户端和服务器之间通过一个简短的握手来协商通信参数，并且在发送和接收数据之前建立连接。

当客户端向服务器请求连接时，它会发送SYN数据包。服务器收到请求后，将返回一个SYN-ACK数据包表明自己已经准备好接收连接，并等待客户端返回一个ACK数据包以确认连接已经建立。连接半打开状态就是在此时，连接建立过程中的中间状态。在连接被完全建立之前，如果网络异常或者其他原因导致客户端和服务器之间的数据包无法成功传递，则连接将会处于半打开状态，并且要么尝试重新建立连接，要么关闭连接。

在半打开状态下，客户端会等待服务器发送回一个SYN-ACK数据包，以便确认连接已经被接受。如果客户端没有收到SYN-ACK数据包，则客户端将关闭连接并尝试重新发送SYN数据包以及重新建立连接。如果服务器没有收到ACK数据包，则服务器将关闭连接并返回一个重置（RST）数据包以标记连接已经被断开。

总之，连接半打开状态是网络连接协议TCP协议中的一种状态，它发生在建立连接的过程中，并且可能会出现网络异常导致的连接断开。对于网络管理员来说，了解半打开连接状态，以及如何处理半打开连接状态的技能是很重要的。

## A、B间有TCP连接，如果B拔网线，TCP连接会怎样 `2`
TCP连接是一种可靠的连接，它包含了数据包的序列号、确认号、校验和等机制，以确保数据的可靠传输。当B拔掉网线，TCP连接会按照以下步骤终止：

1. B会发送一个RST（重置）包给A，通知A连接已经终止了。
2. A收到RST包后，会认为连接已经异常终止，关闭TCP连接。

在TCP连接中，如果一方异常终止连接，另一方会通过重传机制尝试重新建立连接。但是，当B拔掉网线后，A无法收到B发送过来的ACK（确认包），所以A会在一段时间内尝试重传数据包，但最终会放弃重传，认为连接已经异常终止。

需要注意的是，当B拔掉网线时，TCP连接的另一端并不能马上感知到连接已经断开，因为TCP连接有一个保活机制，会定期发送保活包检测连接是否还存活。如果长时间没有收到保活包，则认为连接已经断开。

## Tcp如何判断连接超时？ `2`


TCP连接超时是指在进行TCP连接建立的过程中，由于某种原因导致连接建立失败，超过了一定的时间阈值后，TCP连接自动关闭。TCP连接超时的原因可能是网络故障、连接请求队列满等问题。

TCP连接的超时时间是由TCP协议栈内部的计时器控制的。在TCP连接的建立过程中，会经过三次握手，其中第二次握手发送的 SYN 包经过网络传输的时间就是一个参考时间。在这个时间的基础上，TCP协议栈内部的计时器会开始计时，如果在超时时间内没有收到对方的 ACK 包，则连接建立失败，计时器超时，TCP连接自动关闭。

需要注意的是，TCP连接超时时间的设定需要考虑网络质量、网络拥塞、应用程序负载等多方面因素。一般来说，TCP连接超时时间应设置在30~60秒左右，以保证连接的可靠性和网络性能。如果超时设置得太短，则会频繁地发生连接失败或重传等现象，降低网络性能；而如果超时设置得太长，则会造成资源浪费和网络拥塞。

## 快重传与快恢复的区别 `2`


快重传和快恢复都是TCP协议中的一种流量控制机制，它们的主要作用是在传输数据时，防止网络发生拥塞，提高数据传输的稳定性和效率。但是，它们的实现方式有所不同。

快重传：指的是当源主机发送数据给目的主机时，如果接收方主机没有接收到所有数据，则会向源主机发送重传请求。在快重传机制中，发送方会保存发送过的数据，禁止发送新的数据直到接收方再次成功接收到完整的数据包。这种机制保证了数据的完整性，但也会降低传输的效率。

快恢复：与快重传不同，它在接收方发送重传请求后，并不会立即停止发送数据，而是继续根据窗口大小发送新的数据包。只有在成功接收到重传数据包之后，接收方才会开始接收新的数据。这种机制可以在尽可能快地传输数据的同时，保证数据的完整性。

因此，快重传和快恢复可以看做是TCP协议中流量控制的两种策略，其中快重传更为保守，能够确保数据的完整性，但可能会影响传输效率；而快恢复相对开放，在保证数据完整的前提下，尽可能提升传输效率。

## TCP协议的简要介绍 `2`
TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层协议，其作用是提供可靠的数据传输和流控制。

TCP协议采用三次握手和四次挥手来建立与关闭连接。在三次握手时，客户端发送一个SYN包给服务端，服务端收到SYN包后，回复一个SYN ACK包，客户端收到SYN ACK包后，回复一个ACK包，三次握手完成，连接建立。在四次挥手时，客户端发送一个FIN包给服务端，服务端回复一个ACK包，进入CLOSE_WAIT状态，然后服务端发送一个FIN包，客户端回复一个ACK包，进入TIME_WAIT状态，四次挥手完成，连接关闭。

TCP协议还具有拥塞控制、流量控制等特性，可以控制数据传输的速度和可靠性，保证数据的正确性和完整性。同时，TCP协议还提供了窗口机制，可以进行流量控制和拥塞控制，优化数据传输的效率。

总之，TCP协议是一种可靠的和稳定的传输协议，被广泛用于互联网应用中，如Web、Email、FTP等。

## 服务器存在大量的close-wait状态如何处理 `2`


在计算机网络中，TCP协议实现了可靠的传输以及流控制功能。在TCP连接的关闭过程中，主动关闭的一方进入FIN_WAIT1状态，等待对方的确认，对方关闭后需要再等待一段时间，将连接状态变为CLOSE_WAIT状态，并等待数据全部被接收完毕。如果此时服务器存在大量的CLOSE_WAIT状态，那么很可能会导致服务器的性能下降，甚至出现进程/线程数耗尽的情况，以至于无法为新请求提供服务。针对此类问题，可以采取以下一些方法：

1. 调整TCP的参数，比如增大TIME_WAIT超时时间，减少CLOSE_WAIT超时时间，修改连接的缓冲区大小等。

2. 使用“短连接”，即在进行一些短暂的网络通信后就立即关闭TCP连接，而不是一直保持连接状态。

3. 对于长连接，可以采用心跳保活机制，即定期向对方发送心跳包以检查连接是否有效，若无响应，则在合理的时间后即可关闭连接。

4. 在代码中正确地关闭TCP连接，及时释放文件描述符和资源，可以避免CLOSE_WAIT状态的产生，从而减少服务器的负担。

5. 如果以上方法无效，可以考虑使用SO_REUSEADDR选项，以重用本地地址，防止过多的TIME_WAIT状态。仅在TCP连接的端点使用SO_REUSEADDR选项即可，同时将SO_LINGER选项设为0，调用close()时则立即返回。

总的来说，处理服务器存在大量的CLOSE_WAIT状态需要根据具体情况采取不同的解决方案，避免对服务器的性能造成影响。

## TCP的连接状态有哪些 `2`


TCP连接状态主要有以下几个：

1. CLOSED：表示TCP连接处于关闭状态，未建立或已经关闭。

2. LISTEN：表示TCP服务端正在等待客户端的连接请求。

3. SYN-SENT：表示TCP客户端已经发送了连接请求，等待对方确认。

4. SYN-RECEIVED：表示TCP服务端已经收到了客户端的连接请求，并发送了确认，等待客户端发送确认。

5. ESTABLISHED：表示TCP连接已经建立，数据可以互相传输。

6. FIN-WAIT-1：表示TCP连接即将关闭，已经发送了关闭请求，正在等待对方确认。

7. FIN-WAIT-2：表示TCP连接已经关闭，但是还可以接收数据，等待对方发送关闭请求。

8. CLOSE-WAIT：表示TCP连接已经收到关闭请求，正在等待对方发送最后的数据。

9. CLOSING：表示TCP连接正在进行最后的关闭阶段，等待双方发送最后的数据。

10. TIME-WAIT：表示TCP连接已经关闭，但是还可以接收最后的数据。在此状态下，连接不再使用，等待一段时间后会自动释放。

这些状态经常会在网络中出现，了解它们可以帮助我们更好地排查网络故障和调优网络性能。

## TCP中有哪些定时器 `2`


在TCP协议中，常用的定时器有以下几种：

1. 连接建立超时定时器（SYN重传定时器）

在TCP协议中，发送SYN包进行连接请求时，如果收不到对方的确认响应，就需要重传SYN包。如果重传的次数超过了一定的阈值，还是没有收到响应，就会认为连接建立失败，关闭连接。这个重传SYN包的定时器就是连接建立超时定时器。

2. 重传定时器

在TCP协议中，用来保证数据可靠传输的重传机制。发送方发送数据时，会设置一个定时器。如果在定时器到期之前，没有收到对方的确认响应，就会触发重传机制，重新发送数据。

3. 心跳定时器

心跳定时器是为了检测连接是否还能正常通信而设置的。TCP协议中，双方通信时会互相发送心跳包，以保证连接的正常性。发送方发送心跳包之后，设定一个定时器，如果在规定的时间之内没有收到对方的响应，就会认为连接已经断开。

4. FIN_WAIT2定时器

当一方发送FIN包后，如果收到了对方的ACK响应，进入FIN_WAIT2状态。此时需要设置一个定时器，如果在规定时间之内没有收到对方的FIN包，就会关闭连接。

总之，在TCP协议上，定时器扮演着相当重要的角色，确保TCP连接的可靠性和稳定性，保证数据的可靠传输。

## 如何快速回收TCP资源 `2`


TCP资源回收主要是指在网络通信过程中如何及时、有效地关闭和释放TCP连接，避免占用过多的系统资源和导致网络拥堵。以下是常见的快速回收TCP资源的方法：

1. SO_REUSEADDR：在TCP连接关闭后，通常需要等待一段时间（称为TIME_WAIT状态）以确保对方接收到FIN包并状态稳定。但是，如果新的TCP连接使用了之前连接的IP地址和端口，则可以通过设置SO_REUSEADDR套接字选项来快速释放资源，允许新的连接使用同样的地址和端口。

2. tcp_tw_reuse：针对Linux操作系统，可以通过sysctl参数tcp_tw_reuse来打开资源快速回收，该参数允许TIME_WAIT状态的端口被立即重用。但是需要注意，如果两个相同的连接使用相同的端口，则无法保证完全正确的重用。

3. TCP_QUICKACK：TCP协议具有一种延迟确认机制，即接收方通常会等待一段时间（通常是200毫秒）才发送ACK确认数据包。可以通过设置TCP_QUICKACK套接字选项来启用快速确认机制，从而减少连接保持的时间。

4. TCP_NODELAY：TCP协议的标准实现将数据缓存到一定大小后再发送，通过设置TCP_NODELAY套接字选项可以禁用Nagle算法，减少数据传输的延迟。

需要注意的是，快速回收TCP资源可能会对网络连接的可靠性和安全性造成影响，因此应该根据实际情况谨慎采用。

## TCP的长连接与短连接区别 `2`


TCP长连接和短连接的区别在于连接的建立和释放方式不同。

1. 长连接

长连接也称为持久连接，是指一次TCP连接可以被多次传输使用，客户端与服务端在一定时间内保持连接状态，不需要每次请求都重新建立连接。这样可以减少连接建立和断开时的开销，提高网络通讯效率。

2. 短连接

短连接是指每次请求和响应结束后，都会关闭TCP连接。下一次请求需要重新建立连接，这会给网络通讯带来额外的开销，特别是在高并发情况下，会极大地降低通讯效率。

那么，如何选择长连接和短连接呢？主要基于以下几个方面考虑：

- 服务器的容量：如果服务器容易过载，建议采用短连接，因为长连接在维护状态时会占用服务器的资源。
- 数据库连接的数量：如果连接数量比较多，可以考虑使用连接池管理连接，缓解连接的建立和释放带来的压力。
- 业务需求：根据业务需求考虑，如果需要频繁地进行操作，建议使用长连接，否则使用短连接。

总之，选择长连接和短连接需要根据实际情况进行合理的优化和处理，解决网络通讯效率和系统稳定性的问题。

## TCP如何最大化利用现有的网络带宽 `2`


TCP是一种传输控制协议，它可以最大限度地利用网络带宽。以下是一些方法：

1. 增加窗口大小：TCP使用窗口控制流，这意味着它会等待确认，以确定它发送的数据是否成功到达接收方。通过增加窗口大小，TCP可以同时发送更多数据，从而增加其吞吐量。

2. 使用拥塞控制算法：拥塞控制算法是TCP中最重要的功能之一。它可以检测网络拥塞，并调整发送速率，以确保网络中的流量不会过载，从而最大化利用可用带宽。

3. 压缩数据：TCP可以将数据分成更小的块，然后将它们压缩，从而减少传输数据的总量，提高数据传输的速度。

4. 使用TCP加速器：TCP加速器可以优化传输的数据流，利用缓存和数据压缩等技术，从而提高TCP的性能，进一步最大化利用网络带宽。

总而言之，TCP能够最大化利用现有的网络带宽，是通过使其发送的数据量最大化、检测并减少拥塞、以及使用优化技术如压缩和加速等。

## 域名相同，协议不同，cookie是否可以传递？ `2`


在同一个域名下，不同协议（比如http和https）之间是可以共享cookie的。这是因为cookie是在浏览器端被管理的，它是由服务器在HTTP响应头中通过Set-Cookie字段设置的，然后保存在客户端浏览器的内存或硬盘上，当浏览器发起同域名的请求时，会将cookie带上发给服务器。

在使用不同协议（比如http和https）时，浏览器会判断请求是否来自同一站点，而不仅仅是比较域名，因此可以传递cookie。只要在一个域名下，无论是什么协议，都是可以设置和获取该域名下的cookie的。

需要注意的是，虽然同域名下不同协议之间可以共享cookie，但是浏览器在处理安全问题时，会将http和https视为两个不同的站点，因此在涉及到用户安全信息（比如用户登录信息）的处理时，应该尽量避免在http和https之间传递cookie，建议将网站全面升级到https协议。

## Cookie中包含哪些内容 `2`
在Web中，Cookie是一种存储在用户计算机中的小文本文件，用于在用户和服务器之间持久化存储数据。

Cookie中包含以下信息：

1. Name：Cookie的名称。

2. Value：Cookie存储的值。

3. Domain：Cookie所属的域，可以控制哪些网站可以访问Cookie。

4. Path：Cookie所属的路径，可以控制哪些页面可以访问Cookie。

5. Expires/Max-Age：Cookie的过期时间或存活时间，有两种设置方式。

6. Secure：一个布尔值，表示是否仅在 HTTPS 连接中发送该 Cookie。

7. HttpOnly：一个布尔值，表示是否通过JavaScript脚本修改该 Cookie。

Cookie可以通过response对象设置，也可以通过request对象获取。常用的场景包括实现用户登录状态的记忆，购物车、广告追踪等。需要注意的是，Cookie中储存的信息是可以被解析的，因此需要对敏感信息进行加密或编码。

## DNS使用TCP协议还是UDP协议 `2`


DNS（Domain Name System）既可以使用TCP协议，也可以使用UDP协议。

关于DNS的协议选用，通常取决于所进行的请求的类型和响应的大小。DNS协议定义了两种传输协议：UDP（用户数据报协议）和TCP（传输控制协议）。大多情况下，DNS使用UDP协议，因为UDP是一个无连接的协议，它比TCP轻量级得多，并且通常比TCP更快。但是，由于UDP没有可靠性保障，因此UDP不适用于传输过程长、数据量大的DNS数据。在这种情况下，TCP协议是更好的选择，因为TCP有序、可靠、保障消息及时性等优点，可以确保数据包的完整性，防止丢包，确保数据的安全传输。

需要注意的是，当DNS报文超过单个 UDP 数据报大小时（512字节），DNS 使用 TCP 来传输。所以通常情况下，DNS 使用的是UDP协议，在需要使用TCP传输的数据时才会采用TCP协议。

## DNS劫持是什么意思 `2`
DNS劫持是指攻击者通过篡改域名系统（DNS，Domain Name System）的解析方式，将用户正常的请求转向到其他的错误或恶意网站上，从而实现欺骗用户、窃取信息、挟持流量等目的的一种攻击方式。DNS劫持在实施时具有隐蔽性和迅速性，使得用户难以察觉，而攻击者却可以非常轻易地掌握用户的网络使用情况。

DNS劫持的原理是：攻击者通过篡改DNS服务器的地址解析表或通过伪造DNS请求来获得DNS服务器的控制权。然后将指向特定目标的正确地址转发到攻击者想要的钓鱼网站或恶意网站上进行欺骗或窃取信息。通过改变用户输入的网址指向恶意网站，攻击者可以获取用户的账号密码等敏感信息，或者让用户误入陷阱而导致资产损失等。

为防止DNS劫持，用户可以使用正规的网址，不要轻信不熟悉的链接；企业可以建立安全的DNS服务器，定期更新DNS地址解析表和密码，使用加密连接。

## Http可以长连接，但为何还是无状态？ `2`


HTTP是一种无状态协议，是指在HTTP请求和响应之间不会保留请求和响应的任何状态信息，即每个请求都是独立的，与之前的请求和后续的请求无关，不会记忆之前发生的任何事情。

虽然HTTP协议支持长连接，但是这只是为了提高传输效率而采取的一种技术手段。在长连接中，客户端和服务器之间的TCP连接保持打开状态，可以同时传输多个请求和响应，避免了多次建立和关闭TCP连接所带来的额外开销。

然而，无状态特性是HTTP协议的基本原则，这正是使得HTTP协议具有高度灵活性和可扩展性的原因。无状态的HTTP协议可以处理大量的请求和响应，可以部署在不同的系统和环境中，并且可以方便地与其他应用程序进行集成，因为它们不需要了解其状态或上下文信息。

## Http与Https的端口号 `2`


HTTP协议的默认端口号为80，HTTPS协议的默认端口号为443。

当我们在浏览器中输入一个网站的地址时，如果是HTTP协议，浏览器会自动在后面加上“:80”，如果是HTTPS协议，浏览器会自动在后面加上“:443”。

HTTP协议基于传输层协议TCP，HTTPS协议则是在HTTP协议上添加了SSL/TLS加密层，使得数据传输更加安全可靠。因此，访问HTTP网站时需要使用80端口，访问HTTPS网站时需要使用443端口。

## Https加密算法用在哪个步骤？ `2`


HTTPS加密算法主要用于安全传输HTTP协议所传输的数据，HTTP协议是明文传输的，HTTPS的加密算法则是在HTTP和TCP之间加一层SSL/TLS协议。因此，HTTPS加密算法主要用于以下步骤：

1. SSL/TLS协议的握手过程：当客户端发起HTTPS请求时，首先要与服务器进行安全通信协议的协商（这个协商过程称为SSL/TLS协议的握手过程），在这个过程中，包括对称加密算法、非对称加密算法、密钥交换算法等参数的协商都需要使用HTTPS加密算法。

2. 通信数据加密：一旦握手协议完成，双方将通过对称加密算法共享的密钥来加密/解密通信过程中传输的数据，保证数据传输的机密性和完整性。

3. 数字证书验证：数字证书是SSL/TLS协议的重要组成部分，它包含了证书颁发机构的信息以及服务器的公钥等内容，通过HTTPS加密算法来校验数字证书的有效性，确保通信双方的身份。

因此，HTTPS加密算法主要用于SSL/TLS协议的握手过程、通信数据加密和数字证书验证等多个步骤。

## keep-alive在http和tcp/ip中的区别 `2`


在HTTP和TCP/IP两个协议中，keep-alive的作用是一样的，都是为了减少每次连接的开销以提高网络性能。但是在具体实现方式上，两者略有不同。

在HTTP协议中，keep-alive是一种HTTP持久连接技术，即在一次TCP连接上可以发送多个HTTP请求和响应，而不是每次请求都建立一次新的TCP连接。通过使用keep-alive技术，HTTP客户端可以在一个TCP连接上发送多个请求，从而减少每次连接的TCP握手和挥手过程，提高网络性能和资源利用率。

在TCP/IP协议中，keep-alive是一种TCP选项协议，可以使TCP连接在空闲时定期交换数据包，以防止连接因为长时间没有数据交换而被中断。它能够检测到连接的两端是否还在通信，并在一定时间内没有数据交换时，发送一个小的探测报文来确认另一端是否还在运行。如果探测失败，则视为连接断开。

因此，可以看出HTTP中的keep-alive是建立在TCP/IP协议之上的，是一种实现技术，在HTTP请求和响应之间进行复用TCP连接；而TCP/IP中的keep-alive则是属于TCP协议的一项功能，能够保持TCP连接的状态，并对空闲连接进行检测。

## Http2.0 二进制分帧改进 `2`


HTTP/2.0 是 HTTP 协议的新版本，它在网络传输上进行了一些最新的优化，其中最重要的就是二进制分帧。在 HTTP/1.x 协议中，数据是通过文本格式传输，但在 HTTP/2.0 协议中，所有的数据都被分解为二进制格式，分成更小的帧进行传输。

二进制分帧可以使数据包更加简洁、可靠且高效。在 HTTP/2.0 协议中，服务器可以将一个大的资源拆分成多个二进制帧，在客户端接收端再组装成一个整体。这种方式可以提高数据的加载速度，因为不需要等待整个资源传输完毕。

除了二进制分帧，HTTP/2.0 还有一些其他的优化，比如多路复用、头部压缩、服务器推送等。这些优化都旨在减少网络通信的延迟和提高网络传输的效率。

## Http是基于Tcp还是Udp? `2`
Http是基于Tcp协议的。TCP协议是一种面向连接的，可靠的传输层协议，它提供了面向连接的服务，也就是说，在传输数据时，发送方和接收方需要先建立连接，然后才能进行通信。与TCP不同的是，UDP是一个非面向连接的协议，它不保证数据包的可靠性，也不提供数据包的重发机制。因此，在需要可靠传输的场景下，通常选择TCP协议来实现。

HTTP（Hyper Text Transfer Protocol）是一种基于TCP协议的应用层协议，它是一种请求-响应协议，客户端向服务器发送一个请求，服务器会返回一个响应。HTTP协议是Web应用使用最为广泛的协议之一，它基于TCP协议的可靠性和连接管理机制，为Web应用程序提供了良好的传输基础。因此，HTTP协议必须建立在TCP协议的基础之上，保证数据的可靠传输和连接管理。

## 立足于http协议解释，为何第二次从网页上下载图片会变快 `2`


HTTP协议是一个应用层协议，主要用于传输万维网上的超文本（HTML、XML、图片、音频、视频等）资源。在HTTP协议中，客户端通过HTTP请求来请求服务器上的资源，而服务器则通过HTTP响应来响应客户端请求。HTTP/1.1版本中，客户端可以通过在请求头中添加 "If-Modified-Since" 来询问服务器，该资源是否有更新，服务器在响应头中添加 "Last-Modified" 字段告诉客户端该资源最后一次更新的时间。

当客户端第一次请求一个资源时，服务器会返回整个资源的内容。而当客户端第二次请求相同的资源时，如果该资源没有更新，服务器会返回一个状态码为304(Not Modified)的响应，并在响应头中添加 "Content-Length" 来表示该资源已经被下载完成，无需重新下载。因此，第二次从网页上下载图片会变快。

## Http的无状态具体指的是什么 `2`
HTTP是一种客户端-服务器协议，客户端向服务器发送请求，服务器返回响应。HTTP协议是无状态的，这意味着服务器不会在请求之间维护任何状态。当客户端向服务器发送请求时，服务器只会处理该请求，而不会考虑以前的请求。每一次请求与响应是独立的。 

具体来说，当客户端向服务器发送请求时，服务器会根据请求中的信息来处理请求，并返回一个响应。但是，服务器不会保存任何之前请求的信息，例如该客户端之前是否曾经与该服务器交互过、之前的请求都是什么等等。服务器只是在客户端的每个新请求中逐一进行处理。

因此，在HTTP协议的无状态模式下，每个HTTP请求都是相互独立的，服务器不会保持与客户端之间的任何会话状态，每个请求的处理方式是一样的。如果需要保存状态，那么必须使用其他机制，例如Cookie或Session，来实现状态的跟踪和管理。

## ssl协议属于哪一层 `2`


SSL（Secure Sockets Layer），现在已经被替代为TLS（Transport Layer Security），属于传输层协议。在传输层协议中，SSL/TLS主要负责安全通信。它位于应用层协议（如HTTP、SMTP和FTP）和传输层协议（如TCP和UDP）之间，使用了一系列加密算法来保证可靠的数据传输。这些加密算法包括对称密钥加密算法和非对称密钥加密算法，从而保证通信数据的机密性、完整性和可验证性。

## Http缓存定义与原理 `2`


HTTP缓存是指浏览器在请求服务器资源时，对这些资源进行缓存，以便之后再次请求该资源时，可以直接从本地缓存中获取资源，而不必重新从服务器上下载。这样可以节省带宽，提高访问速度，减轻服务器负担，提升用户体验。

HTTP缓存的原理是通过在HTTP响应头中设置一些缓存相关的字段来控制缓存。常见的有以下响应头字段：

1. Expires：缓存过期时间，表示缓存数据的有效期限。浏览器在请求该资源时，如果发现该资源已经过期，则会重新向服务器发送请求。如果未过期，则直接从本地缓存中获取。

2. Cache-Control：缓存控制字段，可以设置多个指令来控制缓存行为。常见指令有：

- Public：表示该资源可以被任何缓存代理缓存，包括客户端浏览器和中间代理服务器。

- Private：表示该资源只能被客户端浏览器缓存，中间代理服务器不能缓存。

- Max-Age：缓存的最大有效时间，单位为秒。例如：Cache-Control: max-age=3600，表示该资源在客户端缓存一小时。

3. ETag：实体标签，是Web服务器用于判断资源是否有更新的一种机制。服务器将一个唯一的字符串作为资源的标识，发送给客户端。客户端再次请求该资源时，将该字符串通过If-None-Match字段发送给服务器，如果和服务器上的标识相同，则表示资源未更新，可以直接从本地缓存获取。

4. Last-Modified：最后修改时间，表示该资源最后一次修改的时间戳。服务器在响应头中发送该字段，客户端在下次请求该资源时，会发送If-Modified-Since字段，如果该时间晚于该资源的最后修改时间，则服务器返回304 Not Modified状态码，表示该资源未更新。否则，服务器返回新的资源数据。

## 为什么https要采用混合加密算法 `2`


HTTPS（Hypertext Transfer Protocol Secure）是基于HTTP协议的安全通信协议，它通过使用SSL（Secure Socket Layer）和TLS（Transport Layer Security）协议来对数据进行加密和认证，保障网络通信安全性。

混合加密算法是https协议中使用的一种加密方式，它结合了对称加密和非对称加密两种加密方式的优点。对称加密的优点是加密解密速度快，但是密钥的安全性比较弱，容易被破解；非对称加密的优点是密钥的安全性比较高，但是加密解密速度很慢。

混合加密算法的基本过程是：先使用非对称加密方式进行公钥交换，然后使用对称加密方式进行数据加密传输，最后再使用非对称加密方式进行数字签名认证。

混合加密算法的优点在于可以同时兼顾对称加密和非对称加密的优点，更加安全可靠，在网络通信中得到广泛应用。

## no-cache 和 no-store 的区别 `2`
no-cache 和 no-store 是 HTTP 响应头中的两个缓存控制指令。

no-cache 的作用是告诉浏览器不要直接从缓存中获取资源，每次请求都必须发送到服务器进行验证。服务器通过验证后，如果资源没有修改，可以返回 304 Not Modified，让浏览器从缓存中获取资源，如果资源已修改，则返回最新的资源。所以 no-cache 会使用缓存，但在每次使用之前都会将缓存与服务器上的最新版本进行比较，以确保获取的资源是最新的。

而 no-store 比 no-cache 更严格，它的作用是禁止浏览器缓存任何版本的资源。每次用户请求一个资源，都必须从服务器重新获取，而不管缓存中是否存在该资源的副本。这样可以有效避免敏感数据被缓存到用户的本地设备中，提高安全性。

综上所述，no-cache 和 no-store 的区别在于前者会使用缓存，但在每次使用之前都会将缓存与服务器上的最新版本进行比较，以确保获取的资源是最新的；而后者则完全禁止缓存。

## expires和cache-conchol的区别 `2`


expires和cache-control都是HTTP响应头中用于控制缓存的字段，但是它们有着不同的作用和优先级。下面具体解释一下：

1. expires

expires是HTTP1.0版本定义的头信息，它的作用是指定当前文档的过期时间。

如果在响应头里设置了expires的值，那么浏览器在本地缓存了这个资源后，就会在过期时间到达后再向服务器进行请求。如果在客户端系统的时间被修改了，则会导致缓存失效。

2. cache-control

cache-control是HTTP1.1版本定义的新特性，它的作用是用来控制每个请求和响应是否要被缓存，以及如何被缓存。

cache-control的常见属性值包括：

- public：响应可以被任何对象（包括：发送请求的客户端，代理服务器等）缓存。
- private：响应只能被单个用户（例如，浏览器）缓存，其他客户端不能缓存。
- no-cache：客户端缓存响应，但是在使用之前必须和服务器确认是否仍然有效（通过发送一个条件请求If-Modified-Since或If-None-Match请求头到服务器）。
- max-age：指定缓存的最大有效时间，单位是秒。

同时，cache-control的优先级比expires高。如果两者同时出现在响应头中，cache-control会覆盖expires的作用。

总之，expires已经被cache-control所取代，因为cache-control更加灵活，可以更好的控制缓存机制，因此在实际开发中，推荐使用cache-control来控制缓存。

## Socket通信与Tcp通信的比较 `2`


Socket通信是一种通用的网络编程接口，它可以使用多种协议，如TCP、UDP、ICMP等。而TCP通信是一种基于传输控制协议（Transmission Control Protocol）的网络通信协议。下面是它们之间的比较：

1.工作原理：Socket通信是一个应用程序接口（API），而TCP通信是一个协议。Socket通信可以实现TCP通信，也可以实现其他协议的通信。

2.连接：Socket通信可以是连接的或无连接的，而TCP通信是连接的。这意味着在Socket通信中，你可以选择建立连接或不建立连接，而在TCP通信中，建立连接是必须的。

3.可靠性：TCP通信提供可靠的数据传输服务，可以保证数据的正确传输。而Socket通信没有提供可靠性，在传输过程中数据可能会丢失或损坏。

4.延迟：由于TCP通信提供可靠性，因此它的传输延迟可能会比Socket通信高。在Socket通信中，因为没有建立连接和数据确认的过程，因此传输延迟较低。

5.效率：由于TCP通信提供可靠性和顺序传输保证，因此占用了更多的网络带宽，效率较低。而Socket通信的效率较高，因为它没有提供可靠性、顺序传输保证，占用的网络带宽较少。

6.应用场景：Socket通信通常用于小数据传输、实时性要求较高的场景，如在线聊天、视频直播等；而TCP通信通常用于需要保证数据可靠传输、数据量较大的场景，如文件传输、视频下载等。

总体来说，Socket通信更灵活、效率高、适应场景广泛，而TCP通信则更可靠、数据整合性更好。选择哪种通信方式需要根据具体的应用场景和需求来决定。

## 下载文件时下载速度为什么会先上升再平滑？ `2`


下载速度先上升再平滑可能与网络带宽、文件大小、以及文件服务器性能等因素有关。

网络带宽：当我们开始下载一个文件时，下载速度可能会先快速上升，直到达到我们的网络带宽限制。然后，下载速度就会逐渐稳定在最大带宽值。这是因为在开始时，网络传输会尝试充分利用可用的带宽，但是一旦传输达到带宽上限，下载速度就会平稳。

文件大小：如果下载的文件小，那么它可以更快地传输并在短时间内完成，因此下载速度的上升和平稳可能是快速的，因为文件更小，频道的利用率更高。

文件服务器性能：如果下载的文件存储在一个网站的服务器上，那么文件服务器的性能也会影响下载速度的上升和稳定。如果服务器是高性能的，那么下载速度可以很快地达到峰值，然后平稳。但是，如果文件服务器性能较差，那么下载速度的上升可能会较慢，而且当下载速度逐渐达到最大带宽限制时，导致服务器性能下降，并在下载后期导致下载速度变慢。 

综上所述，下载速度上升和平稳的时间和过程因上述因素而异。

## 如何定义一个RPC服务 `2`


RPC（Remote Procedure Call，远程过程调用）是一种通信协议，它允许一个进程在不同的计算机上请求另一个进程的服务，就像调用本地的函数一样，而不需要了解底层的网络细节。

定义一个RPC服务步骤如下：

1.定义消息格式：制定服务所使用的数据格式，例如使用JSON格式。

2.制定接口：定义需要暴露的RPC方法和接口参数，包括输入参数和输出参数，以及方法的返回值。

3.实现服务端：实现RPC服务端代码，主要包括处理客户端请求、解析请求参数、执行相关操作并返回数据等。

4.实现客户端：实现RPC客户端代码，包括通过网络发送请求，接收响应等。

5.部署并测试：将服务端部署到服务器上，并测试服务端的性能和稳定性，同时测试客户端能否正确连接到服务端，并成功请求服务。

总之，定义一个RPC服务需要定义消息格式、制定接口、实现服务端和客户端，并最终进行部署和测试。

## RPC如何实现服务注册与发现 `2`


RPC （Remote Procedure Call）远程过程调用，可以使不同的进程或者计算机之间的程序调用就像调用本地程序一样简单方便，实现高效的跨服务器远程通信。

在 RPC 中，服务注册（Service Registration）与发现（Service Discovery）是非常重要的。服务注册是指向注册中心注册自己的服务信息，发现则是从注册中心中查找已注册服务信息的过程。这样可以充分利用微服务架构的优势，让每个服务之间松耦合、互相独立。

下面是一种较为通用的实现服务注册和发现的流程：

1. 服务端启动后向注册中心注册自己的服务信息，包括服务名称、服务地址、端口号等。

2. 客户端启动后向注册中心查找服务。可以通过提供的 API，根据服务名称查询对应的服务地址和端口号。

3. 客户端对服务进行调用。

4. 在服务调用的过程中，需要将请求发送到服务地址和端口。为了保持通信的高效性，通常会使用一些高效的网络通信协议，比如 Protobuf、Thrift 等。

值得一提的是，服务注册与发现是一个非常复杂的系统，并且在实际应用中通常还需要考虑到负载均衡、故障转移、熔断降级等问题。因此，我们通常会采用一些已有的开源框架来简化这个过程，比如 ZooKeeper、Eureka、Consul 等。这些开源框架提供了完整的服务注册与发现功能，并且支持多种编程语言和协议。

## 限流和熔断分别适用于哪些场景 `2`


限流和熔断都是常用的微服务治理手段，用于保护系统的稳定性和可靠性。虽然两者都是用来控制服务的流量，但是应用场景略有不同。

限流适用于流量控制场景，用于限制某个接口或服务的并发访问量或请求速率，避免突发的流量冲击引起系统崩溃。当服务发现并发量超过配置的限制时，可以从以下几个维度考虑进行限流：

1. 按时间窗口限流： 在一定时间内，控制请求的次数或速率。
2. 按用户id/IP/业务等进行限流：为每个用户或业务分别设置请求频次上限。
3. 按特定URL或API接口进行限流：限制特定的URL或API的请求次数或速率。

而熔断适用于服务降级与快速恢复场景。当依赖服务出现故障或延迟时，为避免线程池被耗尽、请求阻塞等问题，我们通常采用熔断器进行处理。熔断器通过设置一个阈值，在一段时间内检测到达该阈值的请求将直接熔断，并触发失败快速响应（Fall Back）逻辑，从而保护主服务的可用性和稳定性。当调用链中某一个服务出现故障时，如果不断路，可能会造成请求堆积、超时等连锁反应。综合来讲，熔断器主要用于以下几个方面：

1. 避免依赖服务的耗时请求对主服务的影响。
2. 避免请求堆积和线程池耗尽导致的故障。
3. 帮助诊断和分析服务故障原因。

## Nginx负载均衡的实现原理 `2`


Nginx是一款高性能的Web服务器，同时也是一款反向代理服务器和负载均衡器，它可以将请求均匀地分配到多个服务器，从而提高网站的可用性、可靠性和性能。Nginx负载均衡的实现原理主要包括以下几个方面：

1. 负载均衡算法：Nginx提供了四种负载均衡算法，包括Round Robin、IP Hash、Least Connections和Generic Hash。Round Robin是默认的算法，它按照顺序将请求分配给每个服务器。IP Hash算法根据请求的IP地址散列值将请求分配给对应的服务器。Least Connections算法会将请求分配给当前连接数最少的服务器。Generic Hash算法需要自定义负载均衡规则。

2. 后端服务器配置：在Nginx配置文件中必须定义后端服务器的地址、权重、最大连接数等信息。

3. 健康检查机制：Nginx通过定期检查后端服务器的健康状况来确认服务器是否可用，如果服务器无法响应请求，则会从负载均衡列表中删除该服务器，避免请求被分配到已经宕机的服务器。

4. 会话保持机制：为了保证用户的会话不被中断，Nginx可以使用Cookie或IP Sticky等机制，将同一个用户的请求分配给同一个服务器处理，避免请求被重定向到不同的服务器。

总的来说，Nginx通过以上机制来实现负载均衡，将请求分配到多个服务器，从而提高网站的可用性、可靠性和性能。

## Dubbo如何实现超时处理、通信协议与序列化 `2`


Dubbo的超时处理：
Dubbo提供的超时处理是通过heartbeat机制来实现的。heartbeat机制是在consumer和provider之间建立线程，这些线程每个心跳时间都发送心跳包到另外一端的服务，如果一段时间内没有回复会认为对端失联，根据预先设置的重试次数决定是重试还是抛出异常。

通信协议：
 Dubbo通信采用的是自定义RPC协议，能有效降低网络传输的开销，提高RPC性能。Dubbo支持的协议包括：dubbo(默认协议)，hessian，http，rmi。

序列化：
 Dubbo默认采用了Java原生的序列化机制，优点是简单易用，缺点是性能和跨语言支持不如其他序列化方案。同时Dubbo也支持了其他的序列化机制，包括Kryo、FST、Hessian、Protobuf等等，Dubbo的扩展支持为使用者提供了更多序列化的可能性。Dubbo序列化的扩展机制可以用SPI进行扩展，使用者只需要在classpath下加入对应的序列化扩展jar包即可，Dubbo自动将其加载到容器中。

## Dubbo的数据结构 `2`


Dubbo是一款分布式服务框架，它支持各种数据结构来保证系统的可靠性、性能和可扩展性。以下是Dubbo中常用的数据结构：

1. URL：Dubbo中用URL来描述服务的地址，格式为 host:port/path?key=value。URL里可以包含协议、主机地址、端口号、路径以及查询参数等信息。

2. Invoker：Invoker是Dubbo中用于执行远程服务调用的核心接口。服务消费者通过Invokers对象来获得服务提供者的远程服务调用代理。

3. Invocation：Invocation是Dubbo中用于封装方法调用信息的接口。它包含调用方法名、方法参数以及调用属性等信息。

4. Result：Result是Dubbo中用于封装方法调用结果的接口。它包含方法返回值、异常信息以及调用属性等信息。

5. ServiceConfig：ServiceConfig是Dubbo中用于暴露服务的接口，通过它可以将服务注册到注册中心。ServiceConfig包含服务接口、服务实现、服务注册地址以及服务版本等属性。

6. ReferenceConfig：ReferenceConfig是Dubbo中用于引用远程服务的接口，它可以通过接口泛化、代理或者本地存根等方式调用远程服务。

7. Registry：Dubbo中用于注册服务的组件，它可以将服务信息注册到注册中心，也可以从注册中心中查找服务信息。

以上就是Dubbo中常用的数据结构，通过这些数据结构，Dubbo可以实现分布式系统的各种功能。

## 如何解决Dubbo连接数爆满的问题 `1`


Dubbo连接数爆满的问题通常是由于Dubbo的连接池没有正确配置造成的，主要有以下几种解决方案：

1. 调整连接池大小

通过调整每个服务提供者和消费者连接池大小来防止连接数爆满。服务提供者可以使用 `server` 的 `Threads` 参数调整线程池大小；消费者可以使用 `consumer` 的 `Connections` 参数指定连接池大小。

例如，在 Dubbo Spring 配置文件中，可以像下面这样配置：

```xml
<!-- 提供者配置 -->
<dubbo:service interface="com.xxx.XxxService" 
               ref="xxxServiceImpl"
               protocol="dubbo"
               server="netty"
               threads="100" />

<!-- 消费者配置 -->
<dubbo:reference interface="com.xxx.XxxService"
                  id="xxxService"
                  url="dubbo://localhost:12345/com.xxx.XxxService"
                  connections="50" />
```

2. 使用权重路由

Dubbo 提供了 dubbo weight 路由策略，可以根据每个服务的权重来调整请求的分发比例，进而限制某些服务的请求数量。

例如，在 Dubbo Spring 配置文件中，可以像下面这样配置：

```xml
<!-- 提供者配置 -->
<dubbo:service interface="com.xxx.XxxService" 
               ref="xxxServiceImpl"
               protocol="dubbo"
               server="netty"
               weight="100" />

<!-- 消费者配置 -->
<dubbo:reference interface="com.xxx.XxxService"
                  id="xxxService"
                  url="dubbo://localhost:12345/com.xxx.XxxService"
                  loadbalance="weight" />
```

3. 使用负载均衡器

Dubbo 支持客户端和服务端的负载均衡器，可以有效分配请求和资源。负载均衡器可以在服务治理和分布式系统中发挥重要作用。

例如，可以在 Dubbo Spring 配置文件中配置服务提供者的负载均衡器：

```xml
<!-- 提供者配置 -->
<dubbo:service interface="com.xxx.XxxService"
               ref="xxxServiceImpl"
               protocol="dubbo"
               server="netty"
               loadbalance="roundrobin" />

<!-- 消费者配置 -->
<dubbo:reference interface="com.xxx.XxxService"
                  id="xxxService"
                  url="dubbo://localhost:12345/com.xxx.XxxService"
                  loadbalance="roundrobin" />
``` 

总之，根据实际业务需要和 Dubbo 版本，可以采用不同的方案进行调整。

## 网络请求到达服务器，可能经过哪些中间件？ `1`


经典的Web应用程序生命周期经常包括HTTP请求到达服务器并到达应用程序代码。在此过程中可能涉及到多个中间件（middleware），这些中间件可以拦截，修改或者丰富这个请求/响应流。其中比较典型的中间件包括：

1. Web服务器（如Nginx、Apache），用于接收并路由来自客户端的HTTP请求；

2. CDN（内容分发网络），用于缓存以及加速响应速度，可以代理网络请求并将响应优化后返回；

3. 防火墙（如WAF），用来防止请求中的安全问题，如SQL注入、XSS攻击等；

4. 负载均衡器，用来分发请求到多个后端服务器，实现集群的高可用性和负载均衡；

5. 应用服务器（如Tomcat、IIS、Apache HTTP）用来处理HTTP请求，一些框架也可以作为中间件，如Django、Express等；

6. 缓存服务器（如Redis），用来缓存常用数据，加速读取和处理请求的效率。

上述中间件通常会将一些与请求相关的信息传递给下一个中间件或者应用程序，并将处理后的响应返回到上一个中间件或者客户端。这些中间件可以提供各种各样的功能，如能够缓存响应、日志记录、认证等，都可以为Web应用程序提供更好的性能和安全性。

## Rpc丢包如何处理 `1`


RPC（远程过程调用）丢包是指在网络传输过程中，由于网络问题或系统故障，部分或全部请求或响应消息丢失的情况。对于RPC系统来说，丢包是一种非常常见的问题。因此，需要相应的处理方式来确保RPC的顺畅运行。

为了解决RPC丢包问题，一般采用以下几个方法：

1. 超时重试

一般情况下，当一个RPC请求发出后，应该在一定时间内收到响应，否则就认为请求消息丢失了。这个时间间隔称为超时时间，可以根据具体系统性能和网络状况来设置。当超时时间到达后，可以对请求消息进行重试，以确保它最终能够被正确处理。

2. 序列号

针对RPC丢包问题，我们可以为每个请求和响应消息分配一组唯一序列号，序列号是递增的。当一条消息丢失时，我们可以通过序列号判断该消息是否收到。如果接收方发现丢失了某条消息，可以请求发送方重新发送该消息，以确保RPC的顺畅运行。

3. 快速失败

当一个RPC请求过于庞大或者超过了系统的处理能力时，会影响整个系统的性能。为了防止这种情况的出现，我们可以采用快速失败的策略。当系统发现RPC请求过于庞大或者超过了系统的处理能力时，可以直接返回错误信息，不再进行处理。

总的来说，针对RPC丢包问题，我们需要采用一系列的方法来应对不同的情况。对于不同的RPC系统，需要根据具体情况来选择最适合的处理方式。

## RPC如何解决请求超时问题 `1`


RPC（远程过程调用）是一种一般性的技术，用于在不同的计算机进程之间调用函数。在分布式应用程序中，RPC可以在不同的计算机之间交换信息并协调工作。但是，由于分布式系统中的网络延迟和故障等因素，如果 RPC 请求不存在超时处理机制，可能会导致请求长时间阻塞或失败。因此，RPC框架通常会采用一些手段来解决超时问题。

下面是RPC如何解决请求超时问题的步骤：

1. 首先，客户端向服务器发送请求，但是不会等待服务器的响应。

2. 客户端会启动一个定时器来检测请求的超时时间是否已经到达。

3. 如果超时时间已经到达，客户端会将请求标记为失败，并且发送一个错误的响应给服务器。

4. 如果服务器在超时时间内没有响应客户端的请求，客户端会认为请求已经失败。此时，客户端会立即向其它可用的服务器发送相同的请求。

5. 如果服务器在合理的时间内响应客户端的请求，则客户端会取消定时器，响应请求结果。

通过这些方法，RPC能够解决请求超时问题，从而使分布式应用程序更加高效和可靠。

## Netty解决粘包的方式 `1`


Netty是一个高性能、异步事件驱动的网络编程框架，解决了很多网络编程中的常见问题，其中之一就是粘包问题。

粘包问题是指在传输过程中，两个独立的消息会被合并成一个，或者一个消息被拆成多个包传输。造成这个问题的原因是因为底层的TCP协议是基于流的，没有消息边界。

Netty解决粘包问题的方式有以下几种：

1.按消息长度分割：开发者可以自定义消息的长度，然后在处理器中去判断是否满足读取一个完整的消息，如果不满足，则等待接收下一个消息。

2.分隔符分割：使用一定的分隔符来区分不同的消息。在处理器中可以设置一个特定的分隔符，然后接收数据时按照分隔符来切分消息，处理完一个消息后再处理下一个。

3.固定长度分割：设定一定长度的消息来解决粘包问题，在处理器中每次读取固定长度的数据，如果不足则等待下次数据的到来。

4.更改底层协议：如果以上方法难以满足应用需求，也可以通过更换底层协议来解决粘包问题，比如使用UDP协议。

以上是Netty解决粘包问题的几种常见方法，具体选择哪种方法取决于应用需求和具体场景。

## nginx的负载均衡策略 `1`


Nginx是一款开源且高性能的Web服务器，它也可以用作反向代理和负载均衡器。Nginx的负载均衡策略主要有以下几种：

1. 轮询（Round Robin）：Nginx会按顺序将请求分配给多个服务器，每个服务器都会逐一处理请求。当所有服务器都处理完一轮后，它会回到第一个服务器继续处理，周而复始。

2. IP Hash：Nginx会根据客户端IP地址计算一个哈希值，并将其映射到一台服务器。这种策略可以确保同一IP地址的请求总是被分配给同一台服务器处理，适用于需要保持会话（Session）状态的应用，如在线游戏等。

3. Least Connections：Nginx会将请求分配给当前处理连接最少的服务器。这种策略可以确保每台服务器都能够处理大约相同数量的连接，避免了服务器负载不均的问题。

4. Generic Hash：这种哈希策略不同于IP Hash，它可以根据自定义参数计算哈希值，并将请求分配给相应的服务器。

5. Weighted Round Robin：这种策略会给每台服务器分配一个权重值，权重值越大的服务器会被分配更多的请求。这种策略可以用于解决服务器性能不均衡的问题。

以上是Nginx的几种常用的负载均衡策略，不同的策略适用于不同的场景，需要根据实际情况进行选择。

## 你了解的web安全漏洞 `1`


Web安全漏洞指的是在Web应用程序中出现的安全相关的弱点。以下是一些常见的Web安全漏洞：

1. SQL注入：攻击者通过在Web应用程序中注入SQL语句来执行未授权的数据库操作。此漏洞非常危险，可能会导致数据库的整个破坏以及信息泄漏。

2. 跨站点脚本攻击（XSS）：攻击者在Web页面中注入恶意代码，使用户的浏览器执行这些代码，可能会窃取用户的敏感信息，如密码和cookie。

3. CSRF：攻击者通过伪造用户的认证信息来完成非法操作。

4. 文件包含漏洞：攻击者利用Web应用程序的文件包含功能来执行恶意代码，从而破坏整个系统。

5. 认证漏洞：攻击者通过暴力破解、社会工程学等手段获取用户的认证信息，从而进一步破坏系统。

6. 命令注入漏洞：攻击者通过在Web应用程序中注入命令，来执行未授权的系统操作。

以上是一些常见的Web安全漏洞，Web开发者需要在开发过程中严格遵守安全编码规范，提高自身安全意识和技术水平，以有效防范这些安全漏洞的发生。

## 代理服务器和服务器之间存在跨域问题吗？ `1`


代理服务器是一种中间层服务器，它充当客户端和目标服务器之间的一个媒介，可以隐藏客户端的真实IP地址，同时提供负载均衡和缓存等功能，以提高请求响应速度。而服务器是指直接提供服务给客户端的主机。

当代理服务器和目标服务器之间存在跨域问题时，可能会导致请求被拒绝或者无法正常返回数据。跨域是指在web安全模型下，浏览器禁止向不同的域名发送ajax请求。因此，如果代理服务器和目标服务器的域名不相同，就会出现跨域问题。

对于这个问题，可以采用以下方法进行解决：

1.使用jsonp方式。jsonp本质上是一种ajax请求，不同的地方在于服务端返回一个JSONP格式的数据，而不是JSON格式的数据。这种方式需要服务端的支持，客户端代码也需要做相应的改动。

2.使用CORS方式。CORS是一种跨域资源共享策略，通过在服务端设置响应头信息，允许客户端跨域访问资源。这种方式相对较为灵活，需要在服务端进行相应的配置。

3.在代理服务器上使用反向代理方式。通过在代理服务器上配置反向代理，将客户端请求转发至目标服务器，以此来解决跨域问题。这种方式需要在代理服务器上进行配置，不需要对客户端和目标服务器进行修改。

总的来说，代理服务器和服务器之间存在跨域问题，需要采取相应的措施来解决，在实际应用中可以根据具体的情况选择合适的解决方案。

## 为什么代理之后就不存在跨域问题了？ `1`


跨域问题是由浏览器同源策略产生的安全限制。同源策略要求不同域名、不同端口、不同协议之间的网页不能相互访问。如果一个网页的 JavaScript 脚本试图访问另一个网页，就会产生跨域访问的问题。

代理服务器是介于客户端和目标服务器之间的一台服务器。当客户端需要访问目标服务器时，客户端会向代理服务器发送请求，代理服务器会将这个请求转发给目标服务器，并将目标服务器的响应返回给客户端。在这个过程中，代理服务器完全可以屏蔽掉不同源策略所产生的限制。

具体来说，当一个网页需要通过 Ajax 请求获取跨域数据时，可以首先将这个请求发送给代理服务器，让代理服务器去获取目标服务器的数据，再将数据返回给网页。由于代理服务器与目标服务器之间不存在跨域限制，因此所有的数据都可以正常获取，且跨域问题也就不存在了。

需要注意的是，代理服务器只是解决了跨域问题，但并不能解决所有的网络问题。如果代理服务器出现故障或者性能较差，就可能会导致网页加载变慢或者无法正常访问。

## 把allow-origin设置为*会有什么问题？ `1`
让allow-origin设置为*可以导致一些安全问题，因为它允许来自任何来源的请求访问你的资源。这意味着，如果服务端配置不当，攻击者就可以通过从恶意网站向你的服务端发送请求，来窃取敏感信息、修改数据或进行其他危险性操作。此外，由于安全性被削弱，攻击者也更容易发起跨站脚本（XSS）攻击。

为了解决这些安全问题，建议使用适当的CORS配置，指定允许访问你的资源的来源。这样可以最小化安全性问题，提高网络安全性。

## cors要设置哪些参数 `1`


CORS（跨来源资源共享）是一种机制，它允许服务器向不同域名下的客户端发送跨域请求并接受响应。为了确保安全性，并且防止潜在的跨站点请求伪造攻击，CORS要对跨域请求进行限制。下面是一些关于CORS要设置的参数：

1. Access-Control-Allow-Origin - 这个头部是必须设置的，它指定了哪些域名可以访问资源。如果请求的Origin与指定的值匹配，则允许请求。如果这个参数没有设置或者设置为*，那么所有域名都可以访问资源。

2. Access-Control-Allow-Methods - 这是一个选填的头部，它指定了哪些HTTP方法是允许的。如果不设置，那么默认情况下只允许 GET、HEAD、POST 这三种方法。

3. Access-Control-Allow-Headers - 这也是一个选填的头部，它指定了哪些自定义的头部可以带入请求。如果没有设置，那么默认情况下只允许以下头部：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。

4. Access-Control-Allow-Credentials - 这是一个布尔类型的值，表示是否允许发送 cookie 等凭证信息。如果需要发送凭证信息，就需要设置为true。否则设置为false。

5. Access-Control-Max-Age - 这也是一个选填的头部，它指定了请求结果的有效期（单位是秒）。在有效期内，可以不用发送预检请求，直接使用缓存的响应结果。

这些是CORS必须设置的参数，但实际使用中可能还有其他头部需要设置。

## 什么请求会触发cors的预检，为什么会有预检，预检增加了请求次数，这有什么好处？ `1`


CORS（跨域资源共享）是一种浏览器机制，用于允许运行在一个源站点下的Web应用程序，访问不属于该源站点的选择性资源。CORS支持大多数现代浏览器。

当浏览器向一个跨域资源共享的url发起请求的时候，会发生CORS预检。请求发起时，浏览器先以OPTIONS形式发起一个CORS预检请求，来判断实际请求是否安全，是否需要发送跨域请求。

CORS预检请求中包含了请求头（Request Headers）信息，以及 Origin字段，用于表明实际请求的来源。服务器根据这些信息来判断是否允许响应资源请求，是否允许跨域访问。预检也可以传输额外的Header，具有HTTP方法和Content-Type。 预检请求成功后，服务端返回一个HTTP响应，浏览器才能够进行CORS跨域请求。

预检虽然增加了一次请求，但是可以避免非法跨域请求，确保请求的安全性。CORS预检还可以帮助指定请求的额外参数，例如Cookies、HTTP头和验证等，以此使跨域请求完全与同源请求相同。这样，开发人员就可以控制跨域请求、保护客户端和服务器不被非法攻击等。

## 两个页面如何通信（跨浏览器通信，不是同源政策的跨域通信） `1`


因为同源策略的原因，不同页面之间的直接通信是不被允许的。但是在某些情况下，我们仍然需要实现页面间的通信，比如页面嵌入在 iframe 中；或者我们需要从一个页面向另一个页面传递数据等等。

在这种情况下，可以使用以下方法来实现跨浏览器的通信：

1. 使用postMessage() API：这个API可以允许在不同窗口和iframe之间安全地传递字符串数据和嵌套JavaScript对象。在这种方法中，一个窗口调用 postMessage() 函数来发送信息，而另一个窗口则监听 message 事件来接收信息。

2. 使用WebSocket：WebSocket 是一种在网络上进行全双工通信的协议。通过WebSocket，两个页面可以使用相同的主机名在不同的端口上建立一个 TCP 连接，然后发送和接收数据。

3. 使用WebRTC（Web实时通信）：WebRTC 是一种可以实现浏览器之间点对点通信的开放性标准。两个页面可以通过WebRTC建立一个点对点连接，通过这个连接在浏览器之间交换信息。

需要注意的是，这些跨浏览器的通信方法需要进行一定的安全防范措施，以确保只有预期的页面能够接收到信息。此外，这些方法的实现也需要确保在各种浏览器和设备上都能正常工作。

## 客户端与服务端建立连接后是否会保持？何时释放？ `1`


客户端与服务端建立的连接是可靠的，并且在连接建立之后会一直保持，直到其中一方显式地断开连接或者因为网络中断等异常情况导致连接被断开。

具体来说，客户端与服务端建立连接的过程通常包括三个阶段：建立连接、数据传输和释放连接。其中，建立连接主要是通过握手协议完成的，也就是通过发送一些特定数据交换双方的身份信息、协议版本等进行握手，再协商一些连接参数，最终建立连接；数据传输则是通过已经建立好的连接进行数据交互的过程，双方可以交换各种类型的数据，包括文本、二进制文件、图片、视频等；释放连接则是在交换完数据后，双方一方或者双方都显式地发送请求断开连接，或者因为网络中断等异常情况导致连接被断开。

在实际应用中，客户端与服务端的连接通常由长连接和短连接两种方式实现。长连接是指连接建立后一直保持连接状态，可以实现实时通信、推送等功能，但会占用系统资源，需要定期进行心跳维护，同时可能会受到网络环境等因素的影响；短连接则是指客户端与服务端仅建立短暂的连接，完成一次数据传输后立即释放连接，可以节省系统资源，但需要频繁进行连接建立和断开操作，对于实时通信等功能不太适用。

## 服务端如何记录客户端登陆状态？ `1`


服务器端如何记录客户端登录状态，这可以基于多种不同的技术实现，下面我们介绍其中两种实现方式：

1. session会话机制

Session会话机制是一种常见的记录用户登录状态的方式。具体实现是，当用户在客户端登录时，服务器端会创建一个session并将session ID 返回给客户端，客户端存储在本地。之后，客户端每次请求服务端时，都会将这个session ID 发送给服务端表示自己的身份。服务端从自己的session存储中查找这个session ID对应的session，判断用户是否登录，如果是登录状态，则返回用户请求的数据，否则返回登录页面或者提示用户需要登录。

2. Token机制

Token机制也是一种常见的记录用户登录状态的方式。它实现的方式是：用户在客户端登录时，服务端生成一个Token，并将这个Token返回给客户端，客户端将其存储在本地。之后，每次客户端发送请求时，都会带上这个Token，服务端通过验证这个Token的有效性来判断用户的登录状态，并返回响应结果。

无论采用哪种方式，服务端记录用户登录状态都需要进行数据持久化，以便在服务宕机或其他情况下能够保留已登录用户的状态。基于这个需求，我们可以选择使用Session存储数据，也可以使用Redis等缓存来记录登录状态。

## 如果你使用无线局域网，访问网址很慢如何排查？ `1`


问题分析：

在使用无线局域网时，访问网址很慢可能有多种原因，例如WIFI质量差，信号干扰，路由器配置不当等。

排查步骤：

1.检查WIFI信号质量：检查电脑或手机的WIFI信号强度和连接速度，如果信号质量差、连通速度慢，就要考虑增加WIFI的发射器，调整电脑或手机的位置，去除信号干扰等。

2.检查路由器设置：检查路由器的设置，例如是否开启QoS（服务质量）功能、是否设置优先级、是否限制带宽等，如果路由器配置不当，也会导致WIFI访问网站变慢。

3.排查DNS服务器：DNS服务器的故障或被劫持也会导致网络访问缓慢。可以尝试手动设置DNS，比如使用8.8.8.8或114.114.114.114作为DNS解析服务器，看是否能够解决问题。

4.检查浏览器设置：有些时候，浏览器的设置也会导致访问网站变慢。比如可以检查是否开启了代理服务，是否开启了无痕浏览模式，是否安装了广告过滤插件等。

5.检查系统安全软件：有些安全软件可能会对网络访问产生影响，使用杀毒软件、防火墙的用户需要确认网络相关功能是否开启，是否发生冲突等。

总结：

以上是排查WIFI访问网站变慢的常见步骤，用户可以通过逐步排除来确认问题产生的原因，再进行相应的优化与调整。

## BS与CS的区别 `1`


BS和CS是两种软件架构模式，分别表示Browser/Server和Client/Server。

- BS（Browser/Server）架构模式：它的特点是浏览器是客户端，服务器端负责业务逻辑和数据存储等。具体来说，我们在浏览器中输入网址或者点击链接时，浏览器会向服务器发送请求，服务器接收并处理请求，最终将结果发送给浏览器，浏览器展示给用户。

- CS（Client/Server）架构模式： 它的特点是客户端主动发送请求，服务端负责响应请求并提供服务。通常情况下，客户端与服务端采用Socket方式进行通信。

两种架构模式的区别：

- BS架构中的浏览器只负责呈现数据，不需要安装软件，便于维护和升级。而CS架构需要在客户端安装软件。

- BS架构中客户端是浏览器，而CS架构中客户端是安装在本地的软件，因此BS架构是跨平台和跨设备的。

- BS架构可以减轻客户端的硬件需求，因为它不需要软件在客户端本地运行，而是通过浏览器在服务器上运行，而CS架构需要在本地运行完整的软件。

- BS架构的数据安全性比CS架构高，因为可以将业务逻辑和数据存储在服务器端，而不需要将数据存储在客户端。

## 网络数据转发的全流程（交换机/路由器报文传输具体流程） `1`


网络数据转发的全流程包括以下几个步骤：

1. 发送数据

网络数据的发送者将数据发送到发送端主机的网卡，这个过程可以通过数据链路层的协议（如Ethernet）来实现。

2. 寻址

发送端的操作系统会根据目标IP地址和本机的网络配置信息，确定要送到哪个网络接口上，将这个信息添加到数据包的头部，称为MAC地址。

3. 局域网传输

发送端的交换机或路由器将数据包传输到接收端的交换机或路由器。如果接收端和发送端在同一个子网内，交换机会进行局域网内部的转发，直接发送数据包给接收端。如果接收端与发送端不在同一个子网内，路由器会进行网关转发，把数据包发送给下一个路由器或者最终的接收端。

4. 再次寻址

当数据包到达接收端所在的局域网后，接收端的操作系统会通过数据包中的目标MAC地址识别出数据包是发给自己的，然后进行解包，得到数据信息。

5. 数据处理

接收端获得数据包后会进行解析并进行相应的处理，例如在应用层处理HTTP请求，发送响应。

这些步骤通常是通过硬件和软件设备的协调作用来完成，包括交换机、路由器、协议转换等组成的系统，构成了数据中心、企业网络和互联网等网络结构。

## 网络中信息传递的顺序（同网段、不同网段） `1`


在网络中，信息传递的顺序是有一定规则的，主要包括同网段和不同网段两种情况：

1. 同网段传递：在同一网段中，计算机之间通过MAC（Media Access Control，媒体访问控制）地址来进行通信。当一台计算机需要向同一网段中的其他计算机发送数据时，首先会查询目标计算机的MAC地址，然后将数据封装成帧的形式，通过交换机等网络设备直接传输到目标计算机上。

2. 不同网段传递：在不同网段中，计算机之间通过IP（Internet Protocol，网络协议）地址来进行通信。当一台计算机需要向不同网段中的其他计算机发送数据时，首先需要将数据封装为IP数据包，并加上目标计算机的IP地址作为目的地址。然后通过路由器等网络设备将数据包发送到目标计算机所在的子网中，最终再通过同网段传递的方式传递到目标计算机。

需要注意的是，在同一网段内的计算机通过MAC地址直接通信时，数据包不需要经过路由器等设备，因此传输速度比跨越不同网段的数据传输速度快得多。在网络设计时，应尽可能减少跨越不同网段的数据传输，以提高网络传输效率。

## MySQL建立连接的过程 `1`
MySQL建立连接的过程可以分为以下几个步骤：

1. 客户端向服务端发起连接请求。客户端使用自己的IP地址和端口号向MySQL服务端的IP地址和端口号发起连接请求。

2. 服务端收到连接请求后，根据TCP/IP协议分配一个新的socket。服务端的socket用于和客户端通信。

3. 服务端向客户端返回连接成功的响应消息，建立TCP连接。

4. 客户端向服务端发送认证信息。客户端需要提供用户名和密码进行认证，服务端验证通过后才可以进行操作。

5. 服务端收到认证信息后进行验证，验证通过后，客户端和服务端完成连接的建立，可以进行数据交换。

在MySQL建立连接的过程中，需要注意以下几点：

1. MySQL服务端通过监听TCP端口实现连接请求的接收。

2. 客户端连接请求需要经过网络传输，响应消息同样需要经过网络传输。因此，网络延迟和带宽等因素会影响连接的建立时间。

3. 客户端和服务端建立连接后，需要进行认证。在MySQL中，认证方式是可定制化的，通常使用用户名和密码进行验证。

4. MySQL支持并发连接，可以同时处理多个连接请求。在连接数较大的情况下，需要注意MySQL服务端的性能和资源利用率。

## 为什么要动静分离 `1`


动静分离是指将网站中的静态文件（如html，css，js，图片等）存放到静态服务器上，将动态内容（如数据库读取的内容）存放到动态服务器上，从而分散网站的访问流量，减轻服务器负担，提高网站的访问速度和稳定性。

为什么要动静分离呢？原因如下：

1. 减轻服务器负担：当静态文件与动态文件存储在同一台服务器上时，访问量大时会导致服务器负担过大，导致网站访问速度变慢或者崩溃。而动静分离后，静态文件由专门的服务器处理，动态文件由其他服务器处理，减轻服务器负担，提高网站的稳定性。

2. 提高访问速度：因为静态文件不需要数据库查询，所以静态服务器可以更快的响应用户请求，同时也可以利用缓存机制，提高用户访问速度。

3. 方便管理：动静分离后，静态文件由专门的服务器管理，可以更加方便的管理、预览和替换。

4. 易于扩展：动静分离后，如果网站需要扩展，则只需增加静态或动态服务器即可，而无需修改已存在的服务器。

综上，动静分离有助于提高网站的访问速度、稳定性和易于管理，是现代网站架构的常用实践。

## 静态资源与动态资源的区别 `1`


静态资源和动态资源是Web开发中常用的两种资源类型。静态资源是指服务器端不需要进行处理和解析的文件，例如HTML、CSS、JavaScript、图片、视频和音频等。这类资源在传输时会直接被客户端请求，并返回给客户端。

相反，动态资源是需要在服务器端进行处理和解析的文件，例如PHP、ASP.NET、JSP等。这些资源不是直接返回给客户端的，而是在服务器端被处理解析后生成HTML等静态资源，最终返回给客户端。

静态资源和动态资源的区别主要体现在以下三个方面：

1. 资源获取方式：静态资源可以直接被客户端请求，而动态资源需要在服务器端进行处理解析。

2. 资源内容：静态资源的内容通常是固定的，而动态资源的内容可以根据不同的用户请求进行动态生成。

3. 资源缓存：静态资源可以在客户端进行缓存，有效减少服务器响应时间，而动态资源的缓存需要在服务器端进行控制。

总的来说，静态资源提供页面的基础结构和展示内容，而动态资源则是提供页面的交互和数据处理等功能。在Web开发中，静态资源和动态资源的结合使用，可以为用户提供更加丰富和优秀的使用体验。

## 静态资源如何加速 `1`


静态资源加速一般通过以下几种方式来实现：

1. CDN加速：CDN是指内容分发网络，通过在全球各地建立节点服务器，将静态资源缓存在较近的节点上，减小了资源的传输时间和距离，提高了访问速度。

2. 压缩：可以对静态资源进行压缩，比如对JavaScript、CSS、图片等文件进行压缩，减小文件体积，提高文件下载速度。

3. 浏览器缓存：将静态资源缓存在浏览器本地，下一次请求同一资源时直接从缓存中获取，避免了重复请求和下载。

4. 图片延迟加载：当页面中的图片过多或较大时，可以先加载最重要的部分，而将其它内容的图片延迟加载，即当用户滚动到该图片时再去加载，减轻了页面的加载压力。

5. 合并文件：在合理的情况下，可以将多个小文件合并成一个大文件，减少请求次数，提高速度。

6. 减少请求次数：不同的文件需要不同的请求，减少请求次数可以提高速度，比如将多个CSS文件合并为一个文件，用CSS Sprites技术减少图片请求次数等。

7. 网页缓存：主要是利用浏览器缓存和代理服务器缓存，在一定时间内将一些数据缓存下来，下次请求时如果数据没有发生改变，则可以直接使用缓存，减少请求次数。

通过以上方式，可以有效的优化静态资源的加载速度，提高网站的访问速度和用户体验。

## QQ能登录但浏览器不能访问网页，分析原因（开放题） `1`


该问题可能有多个原因，以下列出几种可能性：

1. DNS解析问题：浏览器无法找到如何解析特定网站的域名服务器。这可能是由于DNS缓存中的错误条目，DNS服务器故障或本地网络配置错误等原因造成的。对此可以尝试清空DNS缓存（在cmd命令行中输入ipconfig /flushdns），或者改变DNS服务器设置等。

2. 代理服务器问题：如果计算机上有代理服务器配置，可能存在代理服务器故障、代理服务器设置错误、代理服务器访问被限制等因素。我们可以尝试取消代理服务器设置，或者检查设置是否正确等。

3. 防火墙策略问题：防火墙设置可能会阻挡浏览器访问某些特定网站。可以尝试关闭防火墙或者添加网站到白名单中。

4. 浏览器设置问题：可能是由于浏览器设置问题，如浏览器缓存或cookie存储问题，或浏览器插件或扩展程序干扰等原因引起。可以尝试清空浏览器缓存或cookie，或者在浏览器设置中禁用或删除扩展程序或插件。

总之，需要根据具体情况及时分析并处理可能的问题，以恢复浏览器访问网页的正常情况。

## 如何实现实验室不能访问bilibil(开放题) `1`


针对实验室不能访问Bilibili这个问题，我们可以采取如下几种方案：

1.路由器屏蔽Bilibili的IP地址

可以在实验室所使用的路由器上配置黑名单，屏蔽Bilibili的IP地址，从而实现禁止实验室访问Bilibili的目的。但是，这种方法需要了解Bilibili的全部IP地址，因为Bilibili会不定期更换IP。

2.修改hosts文件

在实验室的所有计算机上修改hosts文件，将Bilibili的域名映射到本地IP地址，实现对Bilibili的阻止访问。但是，这种方法也需要不断更新hosts文件，对于大型网络环境可能不太可行。

3.使用防火墙

可以在实验室网络环境中部署一台防火墙，设置防火墙规则，禁止实验室内的计算机访问Bilibili。如果要访问Bilibili，必须先通过防火墙进行认证和授权。

4.使用DNS过滤

可以在实验室的DNS服务器上进行过滤设置，将Bilibili的域名解析到一个错误的IP地址，从而实现对Bilibili的阻止。但是，这种方法只能防止直接访问Bilibili的情况，如果使用代理或者VPN等方式访问Bilibili，仍然可以成功访问。

综上所述，一般来说，采用防火墙或者DNS过滤的方法比较实用。但是，也需要结合实际情况进行选择，因为每种方法都有其优缺点和适用性。

## 整体介绍互联网体系架构 `1`


互联网体系架构是指互联网上的各种硬件、软件和协议的组合。这个体系架构涉及多项技术，包括网络协议、分布式系统、数据库管理、云计算等等。

一般来说，互联网体系架构可以分成四层：用户层、应用层、服务层和基础设施层。

用户层是指互联网的终端用户和设备，这个层面涉及到各种客户端软件和硬件设备，如移动设备、PC、智能家居等。应用层是指各种具体的应用服务，如电子商务系统、社交媒体、医疗系统等。服务层是指各种中间件和协议，如SOAP、RESTful等，是用于应用服务之间进行通讯的桥梁。基础设施层则是指各种物理设备和软件，如负载均衡器、集群系统、分布式数据库等，以支持整个互联网系统。

在互联网体系架构中，还有一些重要的技术，如云计算、大数据、物联网等。这些新技术正在改变整个互联网架构的面貌。

总的来说，互联网体系架构是一个复杂的系统，由各种不同层面的技术和细节组成。理解这些技术和他们之间的关系，才能为互联网的开发和应用提供更好的支持。

## 交换机和路由器的区别 `1`


交换机和路由器是常见的网络设备。虽然它们的作用都是连接多台设备，但是它们的工作方式有所不同。

交换机可以理解为一个多端口的网络设备，可以有效地连接多个计算机，打造局域网。交换机会学习网络中各个设备的MAC地址，根据MAC地址进行数据包的转发，可以有效地避免网络中出现冲突，提高网络的传输效率。

相比较而言，路由器则是连接不同网络的设备，可以将来自不同网络的数据包进行转发。比如我们家里的路由器就可以连接我们家里的电脑、手机等设备和外部的互联网。路由器会根据网络地址和路由表，进行数据包的选择和传输。

因此，交换机和路由器主要的区别在于它们的工作范围不同，交换机连接的是同一局域网内的多个设备，路由器连接的是不同网络。同时，交换机基于MAC地址，路由器基于IP地址进行数据包转发。

## 路由器在OSI模型的哪层 `1`
路由器在OSI模型中处于网络层（第三层）。 

在OSI模型中，路由器主要负责网络层的数据传输和路由选择。它负责将来自不同网络并且使用不同协议的数据包进行转发，以帮助它们达到目的地址。路由器有一个IP地址，用于识别它所在的子网。当一个数据包在路由器上进行转发时，路由器会根据数据包头部的目的IP地址，查找路由表来决定该数据包应该往哪个方向传输，以达到目的地。

可以发现，路由器在OSI模型中处于网络层，它上面还有数据链路层和物理层。同时，它下面也可能有其他路由器或者主机，如交换机和集线器等，它们处于数据链路层和物理层。这些设备共同协作，为网络的正常运行提供了基础支撑。

## 列举熟悉的网络协议 `1`
网络协议是计算机系统中进行通信的一套规范，通过网络协议可以实现不同计算机或设备之间的信息交换和数据传输。以下是一些常见的网络协议：

1. TCP/IP协议：是互联网常用的一种协议，包含了TCP协议和IP协议两部分，用于实现计算机之间的数据传输和通信。

2. HTTP协议：是Web应用程序的基础协议，用于在客户端和服务器之间传输超文本数据。

3. FTP协议：是一种用于文件上传和下载的协议，支持多种操作，如创建、删除、移动、下载、上传等。

4. SMTP协议：是一种用于电子邮件发送的协议，用于将电子邮件从发送方传输到接收方。

5. POP3协议：是一种用于接收电子邮件的协议，用于从邮件服务器中下载电子邮件内容。

6. DNS协议：是一个能够将域名映射为IP地址的分布式数据库系统，用于实现互联网中域名与IP地址的相互映射。

7. SSH协议：是一种安全的远程登录协议，可以加密所有传输的数据，包括用户登录信息、命令和输出等。

8. MQTT协议：是一种消息传递协议，用于在物联网设备之间传递和交换数据和信息。

9. SNMP协议：是一种简单网络管理协议，用于管理和监控网络设备和系统，如路由器、交换机等。

10. UDP协议：是一种无连接的传输协议，用于快速传输大块数据，如音频、视频等。

## OSI 和 TCP/IP 模型之间的区别 `1`


OSI（开放式系统互联）和TCP/IP（传输控制协议/因特网协议）都是网络协议栈的设计模型。OSI模型是一个理论上的概念，而TCP/IP是一个实际使用的协议栈。

OSI模型分为七层，从低到高分别是：物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。每一层都有其特定的功能，例如在网络层寻找最佳的路由，传输层负责可靠地传输数据。

而TCP/IP模型只有四层：网络接口层（物理/数据链路层的组合），网际协议层（网络层），传输控制协议层（传输层）和应用层。TCP/IP模型将会话层、表示层和应用层合并成一个层。

OSI模型是一个理论参考模型，TCP/IP模型是实际使用的协议栈。TCP/IP是基于OSI模型的，但它将层次结构减少到四个，并为互联网设计了一些特定的功能。所以可以说，OSI模型是一种逻辑模型，而TCP/IP模型是一种实际的，经过验证的协议栈。

## 用户使用App扫描网站二维码登录的过程 `1`


当用户使用App扫描网站二维码登录时，会依次经历以下几个过程：

1. 扫描二维码

用户打开App后，使用App内置的扫码功能扫描网站二维码。二维码通常包含了网站身份标识信息，例如网站的URL、访问令牌等。

2. 发送请求

扫描二维码后，App会向网站发送请求。请求通常包含了用户的身份标识信息，例如用户的登录凭证（如用户名密码、第三方登录授权等）。

3. 验证身份

网站接收到请求后，会验证用户的身份。这个过程通常包括了一系列的安全检查，例如防止攻击、判断请求来源、验证用户凭证等。

4. 验证成功

如果用户身份验证成功，网站会在后台生成一个令牌（token），并将该令牌返回给App。通常情况下，令牌会包含用户身份标识信息和有效期等信息。

5. 登录成功

App收到令牌后，会将令牌进行保存。之后，用户就可以通过App在网站上完成相应的操作，例如查看个人资料、提交订单等。此时用户已经成功登录了网站。

需要注意的是，网站应当采取一系列的安全措施来保护用户的隐私和安全。例如，在传输过程中使用HTTPS协议来加密通信，采用一些反欺诈手段来防止恶意操作等。

## 数据链路层的报头和报文 `1`
数据链路层是OSI模型中的第二层，主要负责将物理层提供的比特流进行封装和组帧，使之成为有意义的数据包，以便网络中的各设备能够识别和处理。

在数据链路层中，每个数据帧由两部分组成：报头和报文。下面是它们的具体解释：

1. 报头（Header）：报头是数据帧中的一部分，它通常由若干个字段组成，用于指示帧的起始和结束，以及帧中不同部分的类型、长度等信息。报头通常包含以下几个字段：

- 帧起始标记（Start Frame Delimiter, SFD）：指示帧的开始位置。
- 目的地址（Destination Address）：指示接收此数据帧的设备地址。
- 源地址（Source Address）：指示发送此数据帧的设备地址。
- 类型/长度（Type/Length）：指示数据帧中的信息类型或长度。

2. 报文（Payload）：报文是数据帧中的另一部分，它包含实际的数据信息，可以是网络层的IP数据包、传输层的TCP/UDP数据段或应用层的应用数据等。

总体来说，数据链路层的报头和报文是数据帧的两个核心组成部分，报头用于标识帧的各个字段，并指示帧的起始和结束位置，而报文则是实际传输的数据信息。在传输数据时，不同OSI模型层次中的组成部分负责不同的功能，数据链路层的主要责任就是提供一个可靠的物理层传输接口。

## 什么是网段？ `1`


网段（也称为子网）是指在一个更大的网络中，将其划分成多个具有相同的地址前缀的子网络。一个地址前缀指的是一个32位IP地址中的前若干位，用于标识网络地址。通过将整个网络划分成多个子网，可以更好地管理、组织和控制网络中的设备和流量。

例如，一个IP地址为192.168.1.100，如果将其子网掩码设置为255.255.255.0，则其前三个地址段（192.168.1）就表示网络地址，而最后一个地址段（100）就表示该网络中的某个设备地址。这样，就可以将整个网络划分成多个子网，每个子网有自己的地址段。

划分网段可以提高网络的安全性、可管理性和效率，同时也可以方便不同子网之间的通信和数据交换。

## 私网如何访问到百度？ `1`


私网指的是内网，也就是局域网。访问外网（例如百度）需要通过路由器连接到Internet，而内网中的电脑是无法直接连接到Internet的，因此需要使用网关来实现访问。

具体实现方式如下：

1. 在内网中设置网关，将网关设置为连接内网和Internet的设备（例如路由器）的IP地址。

2. 将内网中的电脑的默认网关设置为上一步中设置的网关。

3. 在路由器中设置NAT（Network Address Translation）功能。NAT可以将内网中的IP地址转换为外网中的IP地址。

4. 确保路由器中已经设置了正确的IP地址和DNS服务器地址。例如，DNS服务器地址应该设置为ISP提供的公共DNS服务器地址。

这样，内网中的电脑就可以访问到外网了，包括百度等网站。

## 公网和私网如何区分？ `1`


公网和私网通常是根据其IP地址的范围来进行区分的。

在IPv4中，有三类IP地址范围被保留为私有地址：

- 10.0.0.0/8（10.0.0.0 - 10.255.255.255）
- 172.16.0.0/12（172.16.0.0 - 172.31.255.255）
- 192.168.0.0/16（192.168.0.0 - 192.168.255.255）

这些IP地址范围被保留在公司、机构或家庭网络中使用。使用私有IP地址的设备可以通过路由器或防火墙与公共互联网通信，但是它们的IP地址不会被路由交换网络（Internet）所承认，也无法通过Internet直接访问。

而公网IP地址则是指Internet上全球唯一的公共IP地址，它们可以被路由器和互联网设备所识别，用于实现跨公共网络的通信和数据交换。

因此，如果一个设备的IP地址属于10.0.0.0/8，172.16.0.0/12或192.168.0.0/16，那么这个设备就属于私网；如果设备的IP地址不属于以上这些私有IP地址范围，那么这个设备就属于公网。

## 电脑多网卡，IP数据包如何选择网卡发送 `1`


在一台电脑上，如果有多块网卡，每个网卡都有一个唯一的IP地址。当电脑需要发送IP数据包时，需要根据目标IP地址及本机IP地址和子网掩码计算出目标IP地址是否在同一个子网中，如果在同一子网中，则直接发送数据包，如果不在同一子网中，则需要根据路由表查找下一跳路由器的IP地址。

当找到下一跳路由器IP地址后，就需要选择发送数据包的网卡了。这时电脑会按照以下步骤选择网卡：

1. 判断目标IP地址是否在本机的路由表中，如果存在，则根据路由表选择发送数据包的网卡；

2. 如果目标IP地址不在本机的路由表中，则根据本机的默认路由表选择发送数据包的网卡；

3. 如果本机默认路由表中也没有指定要发送数据包的网卡，则采用ARP（Address Resolution Protocol）协议来获取下一跳路由器的MAC地址，在获取MAC地址的过程中，网卡会随机选择一个进行ARP请求，获取MAC地址后再发送数据包。

在这个过程中，操作系统会根据网络接口的优先级来选择网卡发送数据包，一般情况下，优先级高的网卡会被优先选择。如果存在多个网卡有相同的优先级，则操作系统会采用轮询或者随机的方式来选择网卡发送数据包。

## A能ping通B，B不能ping用A，如何排查问题 `1`


这个问题一般有以下几个可能的原因：

1. 防火墙的问题

可能是A主机上的防火墙限制了B主机到A主机的流量，可以在A主机上关闭防火墙或者开放相应的端口，以解决该问题。

2. 路由器的问题

如果A主机和B主机在同一局域网内，可能是路由器的问题导致的。可以检查路由器的配置，确认是否存在相应的路由规则阻止了B主机到A主机的流量。

3. 网络配置的问题

可能是A主机和B主机的网络配置不匹配，可以检查两台主机的IP地址、子网掩码、网关等配置是否正确，以及是否存在其他网络配置的问题，如DNS配置等。

4. 软件配置的问题

可能是A主机上的软件配置问题导致B主机无法与其通信。可以检查A主机上的软件配置是否正确，相关服务是否开放，是否存在防止外来连接的配置等。

在排查问题时，可以使用以下命令和工具：

1. ping命令：可以使用ping命令探测主机之间的连通性。

2. traceroute命令：可以使用traceroute命令追踪数据包在网络中的路径，查找两台主机之间的路由问题。

3. tcpdump工具：可以使用tcpdump工具捕获网络数据包，并分析网络通信流程。

4. telnet工具：可以使用telnet工具测试主机之间的连接是否畅通。

通过以上命令和工具的组合使用，可以定位问题的根本原因，调整相应的配置并解决问题。

## 如何实现软路由 `1`


软路由是一种基于软件技术构建的路由器。可以将个人计算机或嵌入式设备转化为功能强大的路由器或网关，其中软件是用以替代硬件路由器中常常使用的专门用于路由功能的ASIC芯片。

实现软路由主要有以下几个步骤：

1. 选择合适的软件：常用的软路由软件包括pfSense、OpenWrt、DD-WRT等。用户可以根据自己的需求和硬件资源选择适合自己的软件。

2. 安装软件：根据软件提供的安装指南，在计算机或嵌入式设备上安装软路由软件。

3. 配置网络：在软路由软件中配置网络参数和功能。具体操作可以根据软件提供的使用手册进行配置。

4. 连接互联网：将软路由设备与互联网连接，可以通过以下几种方式：
   - 直接通过ADSL或光纤等物理连接接入互联网。
   - 使用4G网络等无线网络方式连接互联网。
   - 联网共享：通过连接家庭无线路由器实现联网共享。

5. 添加防火墙和策略路由：可以根据需要添加防火墙规则和策略路由规则。

总之，实现软路由需要选择合适的软件、正确配置网络参数和功能、连接互联网，根据需要添加防火墙规则和策略路由规则。

## 列举网络拓扑结构 `1`


网络拓扑结构是指网络中节点之间连接的方式和规律。以下是常见的五种网络拓扑结构：

1. 星型拓扑：所有节点都连接到中心节点上，中心节点作为信息传输的控制中心。该结构易于维护和管理，但若中心节点故障，整个网络将瘫痪。

2. 总线拓扑： 所有节点都连接到一条主干电缆上，在电缆两端设置终端，终端之间可以直接通讯。该结构成本低，但当主干线路损坏时，所有节点都将无法通讯。

3. 环形拓扑：节点相互连接形成一个环，节点通过通讯进行信息交换。该结构运行稳定，但是增加和删除节点比较困难。

4. 树形拓扑：将总线式拓扑和星形拓扑结合起来，以多个星型拓扑通过一个控制节点用总线相连。该结构的成本和配置较为复杂，但有良好的可扩展性和可靠性。

5. 网状拓扑：节点之间多个连接，通常应用于大型复杂网络的规划。该结构数量庞大，成本高，但具备高度可靠性和容错性。

这五种网络拓扑结构各有优缺点，需要根据实际应用场景选取。

## 简要介绍OSPF协议 `1`


OSPF是一种以开放标准为基础的链路状态路由协议，它可以动态计算网络上最优的路由。正如其名称所示，该协议是基于开放的标准，即任何厂商都可以根据此协议开发所有层次的设备。

OSPF协议通过在网络中进行链路状态广播，收集所有路由器能够连接到的邻居信息、链路状态和路由器运营状况等数据，并使用这些信息为网络建立一个拓扑结构。OSPF将整个网络划分为若干个区域，并为每个区域分配一个32位的标识符。 网络管理员可以对这些区域进行逐个设置，从而使得OSPF的运作更为灵活和高效。

OSPF协议运作的基本原则和性能要求如下：

1. 可靠性：OSPF协议是一种可靠的链路状态路由协议。
2. 快速收敛：OSPF协议采用Dijkstra算法计算最短路径，从而快速收敛路由。
3. 可扩展性：OSPF协议采取分层设计，支持多区域域间路由。

在现代网络中，OSPF已成为广泛使用的标准路由协议之一，广泛应用于企业级和ISP级网络。

## 简要介绍RIP协议 `1`


RIP（Routing Information Protocol）是一种常用的距离向量路由协议，主要用于TCP/IP网络。RIP将整个网络看做一个路由器，利用路由器之间交换信息，以确定每个路由器到其他网络的距离和最优路径，使数据能够在网络中高效传输。

RIP协议的特点：

1. RIP基于距离向量的原理，它采用距离（即跳数）作为衡量路径优劣的标准；

2. RIP使用UDP协议发送和接收路由信息；

3. RIP支持最多15个跳的网络；

4. RIP使用split horizon、hold down和poison reverse等技术来避免路由环路和降低网络路由波动引起的问题。

RIP协议的工作流程：

1. 各个路由器之间可以改变自己的路由表信息，然后向相邻路由器传播信息；

2. 转发接收到的路由器信息，并更新自己的路由表，同时向相邻路由器通知自己的路由信息；

3. 当路由表发生改变时，会向所有相邻路由器发送路由更新信息，其它路由器收到该信息后，也会更新自己的路由表，以达到整个网络中各个路由器的路由表信息同步。

总体来说，RIP协议是一种简单易用的路由协议，并且具有灵活性和适应性强的优点。

## 一个MTU最大多少字节，最多可包含多少数据 `1`


MTU是指链路层传输单位的最大传输单元。它指示了能够在各种类型的网络中发送的最大数据包的大小。MTU通常是以字节为单位表示的。

以太网是一种常见的网络类型，它的MTU通常为1500字节。这意味着，在以太网中，一个数据包的最大大小为1500字节。

然而，需要注意的是，实际可包含的数据量可能少于MTU值，因为在数据包的头和尾部分别添加了各种协议和控制信息。例如，在TCP / IP网络中，一个IP数据包通常会附加20个字节的IP头和20个字节的TCP头，这意味着在一个1500字节的以太网数据包中，实际可用于传输数据的大小为1460字节。

因此，MTU给出了网络传输的理论最大值，而实际可发送的数据量取决于各种因素，如网络协议、网络设备、操作系统等。

## 路由转发方式 `1`


路由转发方式是互联网中广泛使用的网络通信方式，它是把数据包从源地址传输到目的地址的过程。路由器可以执行路由转发，它通过查看数据包的目的地址，并使用内部路由表中预先定义的路由选择最佳的出口接口，从而把数据包转发至下一个路由器或目的主机。路由转发方式有以下两种：

1. 静态路由转发

静态路由转发是人工配置给定网络中的计算机流量规则，使得来自这些计算机的数据包按照规则被路由器传输。静态路由转发需要手动输入路由规则，如果网络拓扑结构变化，路由规则需要重新配置。这种方式适用于小型网络，并且可以减少网络拓扑结构变化的概率。

2. 动态路由转发

动态路由转发是通过路由协议使路由器自动适应网络拓扑结构的变化来实现路由转发。例如，OSPF 和 BGP 路由协议会周期性地把路由表更新发给相邻路由器，以便它们可以在网络出现变化时快速更新路由信息。动态路由转发可以根据网络中的拓扑结构和流量状况，动态地选择最佳的路由路径，提高路由的准确性和效率，因此被广泛应用于大型企业级网络中。

无论是静态路由转发还是动态路由转发，路由器在转发数据包时都会遵循一定的规则，例如最短路径、最优路径等。同时，路由器还会根据网络拓扑结构、流量状况等因素对路由表进行调整，以保持网络的连通性和性能。

## 描述通过IP地址路由到主机的全过程 `1`


IP地址路由到主机的过程包括以下步骤：

1. 发送端根据目标主机的IP地址和自己的IP地址以及子网掩码等信息，判断目标主机是否在同一子网内。
2. 如果目标主机不在同一子网内，发送端将IP数据包发送给本地路由器，选择一个最佳路径将数据包发往目标主机。
3. 路由器根据路由表中的信息选择一条比较优秀的路径，将数据包转发给下一个路由器。
4. 数据包在多个路由器之间传输，直到达到目标主机所在的路由器。
5. 目标主机所在的路由器将数据包发送给目标主机。

路由表是路由器存储路由信息的地方，它包含了目的网络地址、下一跳地址、路由距离和接口等信息。路由算法是确定路由表中路由的过程，其中有几种常见算法如下：

1. 静态路由算法：手动配置路由表的每条路由，适用于网络较小的情况。
2. RIP协议：使用距离向量算法，将整个网络看作一个大的路由表进行计算，适用于小型网络。
3. OSPF协议：使用链路状态算法，将网络划分为多个区域，每个区域有一个最优路径，适用于大型企业网络。
4. BGP协议：用于不同自治系统之间的路由，根据系统之间的政策选择最优路径。

## 已经有流量控制为什么还要拥塞控制？ `1`
流量控制和拥塞控制都是网络传输中的两种机制，它们的目的不同。

流量控制是指发送方和接收方之间，在数据传输时控制数据流量，以避免接收方被发送方淹没。流量控制主要通过滑动窗口协议来实现，发送方发送的数据量不超过接收方的接收缓冲区大小。

而拥塞控制是指在网络中控制数据包的流动，防止过多的数据包进入网络造成网络拥堵。拥塞控制是为了和流量控制协同工作而存在的，防止数据的积压和过度拥塞在整个传输链路中，避免网络资源的浪费和传输效率的降低。

因此，流量控制和拥塞控制两者虽有相似之处，但是它们是不同的原理和机制，各有其独特的作用和意义。在网络传输中，流量控制和拥塞控制共同协作，互相配合，才能够保证网络传输的质量和效率。

## 大文件传输用UDP还是TCP `1`


大文件传输，一般建议使用TCP协议进行传输，而不是UDP。

TCP协议具有以下优点：

1. 可靠性高：TCP协议提供可靠的数据传输，能够保证数据的准确性和完整性。

2. 流控制和拥塞控制：TCP协议通过窗口控制和拥塞控制技术可以有效地控制数据传输速率，防止网络拥塞。

3. 顺序性：TCP协议能够保证数据传输的有序性，即数据包的顺序可以被保持，不会出现乱序的情况。

而UDP协议则不能提供上述功能，因此不适合进行大文件传输。UDP协议的优点在于传输速度快、延时低、无需建立连接等特点，适合于对实时性要求较高的应用场景。

但是，如果网络质量较差，TCP协议对于大文件传输有时可能会导致传输速度较慢，甚至出现拥塞现象。这时候，可以考虑使用UDP协议加上自定义的可靠性机制进行大文件传输，以提高传输效率和速度。不过需要注意的是，这样会增加额外的开发和维护成本，需要根据具体应用场景进行权衡。

## UDP报文格式 `1`


UDP（User Datagram Protocol）是一种无连接的协议，在数据传输层中运行，它可以帮助应用程序在互联网上进行高效的数据传输。UDP报文是UDP协议交换的数据单元，它的格式如下：

```
 0                15 16               31
+-----------------+-----------------+
|   源端口 (16位)   |   目的端口 (16位)  |
+-----------------+-----------------+
|        长度 (16位)         |       校验和 (16位)       | 
+-----------------+-----------------+
|                                      负载（数据）                           |
+-----------------+-----------------+
```

其中：

- 源端口：源端口是16位的数字，用于标识UDP报文的发送端。
- 目的端口：目的端口也是16位的数字，用于标识UDP报文的接收端。
- 长度：表示UDP报文的长度，包括UDP头部和负载数据，长度的单位是字节。
- 校验和：UDP校验和是一个可选字段，可以用于检验UDP报文是否被篡改。
- 负载：负载是报文的实际数据内容，长度可以为零。

需要注意的是，UDP协议是一种无连接的协议，因此UDP报文并没有序列号或者确认号等标识，也没有重传机制，所以UDP是一种不可靠的传输协议。

## TCP 有哪几种关闭的情况？ `1`


TCP连接的关闭可以根据关闭时状态的不同分为主动关闭和被动关闭。在主动关闭时，连接的一方发送FIN报文，告诉对方自己已经没有数据要发送了，请求对方发送ACK，以便告知连接彻底关闭。在被动关闭时，连接的一方收到对方发送的FIN报文，返回给对方一个ACK报文，表示已经同意关闭，并且自己也不会再发送数据。

根据关闭的细节可以将TCP的关闭分为下面几种情况：

1. 完全关闭：既包括主动关闭和被动关闭两种情况，是指两端都经过了四次握手完成连接的关闭，即彼此都知道对方已经完成断开动作。

2. 半关闭：一方关闭连接，但是另一方仍需发送数据的情况，这时候只有一方的发送已经关闭，而接收并没有关闭，可以继续接收数据，知道数据发送完毕再关闭。半关闭包括主动半关闭和被动半关闭两种情况。

3. 超时关闭：当关闭连接时发送的FIN报文在一段时间内未能得到想应的ACK报文确认，通常会触发一个超时计时器，处理超时关闭的原则是在一段时间内不断重传FIN报文，直到得到对端的ACK报文或达到最大重传次数。

4. 大量连接关闭：对于服务器来说，可能有大量的客户端连接需要关闭，如果采用常规的四次握手关闭，关闭连接需要发送大量的FIN报文，这时候可能会引发网络拥塞等问题。这时候可以采取TCP的连接池等技术，优化大量连接的关闭。

## Linux 内核如何实现 TCP ？ `1`


TCP协议在Linux操作系统中是作为内核模块被实现的。内核模块负责实现TCP的所有功能，如连接管理，数据传输等。

Linux TCP协议栈实现过程如下：

1. TCP协议在内核中通过一个名为 `inet_create` 的函数注册。

2. 客户端进程通过`socket`系统调用创建一个TCP套接字，并调用`connect`函数向服务器发起连接请求，此时操作系统开始建立TCP连接。

3. 操作系统创建一个TCP报文段，其中包含SYN标志，发送给服务器。

4. 服务器端接收到TCP报文并回复一个带有SYN和ACK标志的TCP报文段，表示在同意与客户端进行TCP连接。

5. 客户端接收到服务器回复的TCP报文段，回复一个带有ACK标志的TCP报文段。

6. 至此，TCP连接建立成功，客户端和服务器可以进行数据传输。

7. 当数据传输完成后，客户端和服务器都会发送一个FIN报文段，用于关闭TCP连接。

8. 操作系统在接收到FIN报文段后，发送一个ACK报文段以确认收到关闭请求，并在等待一段时间后关闭TCP连接，释放资源。

总体来说，Linux内核实现TCP协议的过程是通过监听和传输TCP报文来实现的，其中包括连接的建立、数据的传输和连接的关闭等。而TCP协议的具体实现则涉及到一系列底层算法和技术，如拥塞控制、流量控制等。

## TCP 里的 RTT 和 RTO 怎么测量的？ `1`


TCP （Transmission Control Protocol）是一种可靠传输协议，为了保证数据的可靠传输，TCP 中引入了分组确认和重传机制。在这个过程中，TCP 中的 RTT（Round Trip Time）和 RTO（Retransmission TimeOut）是两个重要的指标。

RTT 指的是数据包从发送方发送出去到接收方返回 ACK（确认）的时间，通俗点说就是发送方发送数据时，在接收到 ACK 前所需等待的时间。而 RTO 则是指 TCP 分组超时时间，当 TCP 发送方发送数据包后，在 RTO 时间内没有收到接收方对应的 ACK，则发送方就会进行重传数据包操作。

那么，如何测量 RTT 和 RTO 呢？

对于 RTT，我们一般会采用“四次握手”来测量。发送方发送数据包后，接收方收到后立即回复 ACK，发送方收到 ACK 后再发出第四次数据包以完成“四次握手”，此时 RTT 就是从开始发送第一次数据包到接收到 ACK 的时间差。

对于 RTO，通常根据不同系统的实现方式有不同的测量方法。常见的是通过采集数据包的往返时间，计算出平均值和标准差，然后乘以一定的倍数作为超时时间。另外，还有一些实现方式，例如 Jacobson-Karels 算法、Karn-Patridge 算法等。

总之，测量 TCP 中的 RTT 和 RTO 是保证 TCP 可靠传输的重要一环，在实际应用中也需要根据情况采用不同的方法进行测量。

## last ack状态作用 `1`
"last_ack"是TCP（传输控制协议）连接状态的一种，指示发送方已经发送了FIN包（即结束包），等待收到最后一个ACK确认回复。 这种状态是在TCP连接结束时由发送端的最后一个分组引起的。 当发送方发送FIN包时，它处于FIN_WAIT_1状态，此时等待接收到另一端的确认（即ACK）。在接收到另一端的确认后，发送方就进入了FIN_WAIT_2状态。在接收到另一端发送的最后一个ACK确认包后，发送方会进入"last_ack"状态。 如果在"last_ack"状态下再次收到ACK，连接将被关闭且发送方将被解除绑定。

因此，"last_ack"状态的作用是为发送方提供一个机会来确认连接中最后一个数据包的正常传输，以确保连接可以安全地关闭。

## 数据接收方还会有滑动窗口吗 `1`


是的，数据接收方可能会使用滑动窗口。

滑动窗口是一种用于流控制的技术，用于管理传输过程中的数据流量，并确保数据的可靠性。数据接收方通过设置一个滑动窗口来控制发送方的数据发送速率。

在滑动窗口中，接收方不仅要确认已经接收到的数据包，而且还会通知发送方可以继续发送多少数据包。滑动窗口的大小随着数据包的发送和接收而不断变化。如果接收方已经准备好接收更多数据包，则窗口就会向前滑动，允许更多的数据包通过。如果窗口已经满了，则发送方必须等待接收方确认已接收的数据包。

滑动窗口可以确保数据在传输过程中不会丢失，并且可以提高网络性能和吞吐量。因此，即使在现代网络和通信技术中，滑动窗口仍然被广泛使用。

## UDP是否会进行数据校验 `1`
UDP协议提供了传输层的基本数据传输功能，但是与TCP协议不同，UDP协议不会对数据进行可靠性和顺序传输的保障，因此UDP协议被设计为一种无连接的、不可靠的协议。

UDP协议仅提供了最基本的错误检测功能，即包含了一个简单的校验和，用于检测接收端收到的数据是否具有完整性。在发送端，UDP将要传输的数据进行校验和计算，并将结果添加到UDP协议头部信息中。在接收端，UDP接收到数据后同样会重新计算校验和，并根据计算结果判断数据包是否完整，如果数据包未被篡改，则将数据包交给上层应用程序处理。

需要注意的是，UDP协议的校验和方式是一种非常简单的算法，只能检测出一部分的数据传输错误，例如比特翻转、错误的校验和计算等数据传输错误，但它不能检测出更复杂的错误，例如数据包的重复、丢失、乱序等错误。因此，UDP协议被认为是不可靠的数据传输协议，适用于实时数据传输，例如视频和音频流传输等场景。

## TCP是长连接还是短链接 `1`


TCP 协议本身没有规定连接是长连接还是短连接，它仅仅定义了如何在网络中传输数据。因此，TCP 连接的长短取决于应用程序的设计以及底层的网络架构。

一般来说，TCP 连接有两种方式：短连接和长连接。短连接是在客户端向服务器发送一次请求后，客户端和服务器立即断开连接。长连接是在客户端向服务器发送一次请求后，客户端和服务器之间会一直保持连接状态，直到连接被断开或者超时。

具体来说，短连接和长连接的选择需根据具体应用场景进行判断。短连接适用于服务器端响应时间短、连接频繁建立和释放、网络环境变化频繁等场景。长连接适用于服务器端响应时间长、连接建立和释放不频繁、网络环境比较稳定等场景。

总的来说，TCP 连接的长短与具体的业务场景有关，需要结合具体情况进行考虑。

## UDP包大于1472字节能够发送成功吗？ `1`


UDP (User Datagram Protocol) 是一种无连接的协议，也就意味着 UDP 并不提供错误检查或重传机制。相比之下，TCP (Transmission Control Protocol) 是一种面向连接的协议，需要在传输数据前先建立可靠的连接，并负责确保数据在传输过程中不发生丢失或损坏。因此，UDP 在传输数据时，需要考虑各种因素，如 MTU (Maximum Transmission Unit) 长度等。

MTU 的长度是指通过网络传输的最大数据包大小。MTU 可以因路由器、接入点和操作系统不同而有所不同。在以太网上，MTU 大小通常为 1500 字节，其中包括 20 字节的 IP 头和 8 字节的 UDP 头，因此 UDP 数据包的最大大小为 1472 字节（1500-20-8）。

如果 UDP 数据包的大小超过了 MTU，就需要进行分片，将大的数据包分解成多个小的数据包进行传输。然而，UDP 不提供重传机制，因此如果发生了分片丢失或丢失一个数据包，那么整个数据包都会丢失，这会导致数据的丢失。因此，在实际应用中，建议将 UDP 数据包控制在 MTU 的长度内。如果需要传输大量的数据，可以考虑分块、分段传输，以确保数据的顺利传输。

所以，如果 UDP 包大于 1472 字节，它不能保证数据的完整性传输，也很有可能会丢失数据。

## 如何搭建TCP高并发服务器 `1`


TCP高并发服务器可以通过以下几个步骤来搭建：

1. 选择合适的框架：可以选择像Netty、Mina等优秀的网络框架，这些框架提供高性能、异步IO、事件驱动等特性，非常适合构建高并发服务器。

2. 服务器架构设计：可以采用多线程或者多进程的方式来提高并发处理能力，也可以采用事件驱动的方式来实现高并发。

3. 负载均衡设计：可以采用LVS、nginx、F5等软硬件负载均衡方案，将请求分发到不同的服务器上。

4. 高效存储设计：可以采用Redis等内存型数据库，或者采用分布式存储方案，保证高效的数据存储和读取。

5. 多机房架构设计：可以将服务器部署在不同的机房，通过网络互联的方式构建多机房集群，提高可靠性和可扩展性。

在具体实现时，需要考虑以下几个关键点：

1. 网络通信：采用NIO或者AIO方式实现非阻塞网络IO，避免传统阻塞IO模式下的线程阻塞和上下文切换。

2. 多线程/多进程设计：可以采用线程池、进程池等方式来提高并发处理能力，注意线程/进程间的通信和协调问题。

3. 事件驱动设计：可以采用Reactor模式或者Proactor模式等方式，通过事件触发的方式来处理客户请求，避免阻塞和上下文切换问题。

4. 数据存储设计：采用Redis等内存型数据库和高速缓存，或分布式数据库系统，保证高效的数据存储和读取。

最后，在实现过程中还需要考虑高可用、监控报警、安全等方面的问题，才能搭建一个完备的高并发服务器系统。

## UDP能携带的数据最大长度是多少？ `1`


UDP协议中数据报的长度是有限制的，因为UDP是一种无连接的协议，不像TCP协议有流量控制机制，数据报大小超过MTU时就直接被分割成多份，每份都被TCP/IP协议包装成不同的IP包，这会增加一定的网络开销和延迟。因此，UDP能传输数据的最大长度由网络的MTU大小限制。

MTU指的是Maximum Transmission Unit，即最大传输单元，是指在一个特定的通信协议中一次能够传送的最大数据包大小。在UDP协议中，IPv4的MTU通常是1500字节，而IPv6的MTU则更大，通常为1280字节。

因此，如果需要在UDP中传输大量的数据，可以考虑将数据分成多个小包进行传输，避免UDP数据包过大产生的问题。另外，由于UDP本身不保证可靠性，在传输过程中可能会出现数据丢失或乱序等问题，因此需要在应用层自行处理数据的可靠性和顺序。

## TCP的特点 `1`

TCP（传输控制协议）是一种面向连接的传输协议，用于在计算机之间可靠地传输数据。它有以下几个特点：

1. 面向连接：在使用 TCP 进行数据传输之前，需要先建立一个连接，数据的传输是在连接的基础上进行的。连接建立后，数据传输完成后还需要断开连接。这种特点使得 TCP 数据传输的可靠性更高。

2. 可靠性：TCP 通过一些机制来保证数据传输的可靠性，如校验和、确认应答机制、流量控制、拥塞控制等。这些机制可以有效避免数据的丢失、错误和重复传输等问题，提高了数据传输的可靠性。

3. 面向字节流：TCP 把数据看作是一个连续的字节流，在传输数据的过程中，数据并不像数据报一样被分割成一个个的数据段，而是一次性发送整个数据流。这种特点使得 TCP 更适合于传输大量数据。

4. 全双工通信：TCP 可以实现全双工通信，即在数据传输过程中，两端都可以同时发送和接收数据。

5. 慢启动和拥塞控制：TCP 在数据传输过程中会根据网络状况自适应地调整数据发送量，随着网络状况的好转，数据发送量也会逐渐增加，以达到更高的传输效率。同时，当网络拥塞时，TCP 会自动减少数据发送量，以避免网络拥塞的加剧。

总之，TCP 是一种可靠性、稳定性较高的传输协议，适合于数据传输要求高可靠性的场景。

## TCP和socket的区别 `1`


TCP（Transmission Control Protocol）和socket之间有一些区别，我们来看一下：

1. TCP是一种协议，而socket是一种编程接口。
TCP协议是指计算机网络通信协议中的一种，它提供了可靠的、面向连接的数据传输服务，而socket则是一种面向TCP/IP协议族的编程接口，用于实现网络应用程序与网络之间的数据传输。

2. TCP属于传输层协议，socket属于应用层协议。
TCP协议位于OSI网络模型中的传输层，而socket则处于应用层。即TCP负责网络数据的传输，而socket则是应用程序通过TCP协议进行数据传输的工具。

3. TCP提供不同级别的服务，与不同的应用层协议结合使用。而socket则是通过应用程序编写的接口来使用TCP协议的。

4. TCP可以同时连接多个应用程序，以不同的端口号标识不同的应用程序。而socket则是通过不同的套接字实现数据的传输。每个套接字都有自己独立的端口号，用于标识不同的进程。

总的来说，TCP和socket在实际应用中是相辅相成的。TCP提供了可靠的数据传输服务，而socket则使得我们能够更加方便地使用TCP协议进行网络编程。

## TCP的延迟主要在哪 `1`


TCP的延迟主要集中在以下几个方面：

1. 应用层阻塞：TCP协议是基于应用层的，如果应用层的处理时间过长，就会导致数据包的等待时间增加，从而增加延迟。

2. 拥塞控制：为保证网络的可靠性，在网络拥塞时，TCP会通过降低传输速率来避免数据包的丢失，从而增加了延迟。

3. 重传机制：TCP协议使用重传机制来保证数据传输的可靠性，当一个数据包没有响应或丢失时，TCP会重新发送该数据包。这也会增加延迟时间。

4. 丢包重传：当数据包被丢失或损坏时，TCP协议会要求重新发送数据包，这也会增加延迟。

5. 延迟确认：TCP协议使用延迟确认机制来确认接收到的数据包。这个过程需要等待一定的时间，也会增加延迟。

综上所述，TCP的延迟主要与应用层、拥塞控制、重传机制、丢包重传和延迟确认等方面有关。在实际应用中，可以针对这些方面来优化TCP协议，提高网络的传输效率和速度。

## TCP如何控制建立连接与断开连接 `1`


TCP（Transmission Control Protocol，传输控制协议）是一种常用的传输协议，它可以保证数据的可靠传输。TCP实现了连接导向、可靠性高和流控制等特点。

在TCP中，建立连接和断开连接需要通过握手过程来实现。下面是建立连接和断开连接的具体流程：

1. 建立连接

当主动发起连接的一方（通常是客户端）向被动接收连接的一方（通常是服务器）发起连接时，TCP首先通过发送一个SYN（Synchronize，同步）报文来请求建立连接。在发送SYN报文时，TCP使用一个随机生成的序列号来标识自己的起始序列号，并指定对方的的序列号为其下一个序列号。

当被动接收连接的一方收到SYN报文后，它将其放入一个半连接队列（SYN_RECV队列）中，并回复一个SYN+ACK（Synchronize Acknowledgment，同步确认）报文给客户端。同时，被动接收连接的一方也会指定一个随机生成的序列号作为自己的起始序列号，并在ACK字段中指定客户端期望接收到的下一个数据报的序号。

最后，客户端收到服务器的SYN+ACK报文后，将其放入一个已连接队列（Established队列）中，并回复一个ACK（Acknowledgment，确认）报文给服务器，表明双方建立了连接。在ACK报文中，客户端指定客户端期望发送的下一个数据报序号。

2. 断开连接

当连接双方中有一方需要断开连接时，TCP会通过一个四次握手（Four-Way Handshake）的过程来关闭连接。其具体流程如下：

第一步：当需要断开连接的一方（例如Client）向另一方（例如Server）发送一个FIN（Finish，结束）报文，表明自己已经不再发送数据。此时该连接状态进入FIN_WAIT_1状态。

第二步：收到FIN报文的一方（例如Server）会回复一个ACK报文，表示收到了FIN报文。此时该连接状态进入CLOSE_WAIT状态。

第三步：当该另一方（例如Server）自己也准备好断开连接时，就向发起方（例如Client）发送一个FIN报文，此时该连接状态进入LAST_ACK状态。

第四步：最后发起方（例如Client）收到FIN报文后，回复一个ACK报文，此时该连接进入TIME_WAIT状态。在TIME_WAIT状态下，该连接会在一个固定的时间后自动关闭，释放掉资源。

以上就是TCP建立连接和断开连接的具体流程。为了保证数据的可靠传输，TCP采用了定时器、滑动窗口等措施，经过不断的协商和调节来实现数据传输的效率和可靠性。

## TCP建立连接需要的系统调用 `1`


TCP建立连接需要三个重要的系统调用：

1. socket() - 创建套接字

在TCP连接建立之前，必须先创建一个套接字。套接字是一种与网络通信的端点，它包含一个IP地址和一个端口号。socket()系统调用创建一个TCP套接字，并返回一个文件描述符，以便进行读写操作。

2. bind() - 绑定端口号

在创建套接字之后，必须将该套接字与一个端口号绑定。这可以通过bind()系统调用来完成。如果端口号已被其他程序占用，该系统调用将失败。

3. connect() - 建立连接

在绑定端口号之后，可以使用connect()系统调用来建立TCP连接。该系统调用需要提供对方的IP地址和端口号。此时，TCP协议会进行三次握手，以确保连接的正常性和稳定性。

以上三个系统调用的顺序为：socket() -> bind() -> connect()。其中，bind()并不是必须的，如果不绑定端口号，系统会随机分配一个可用的端口号。

## TCP报文中的端口号是如何获取的 `1`


TCP报文中的端口号是通过源端口和目的端口字段来获取的。

源端口是发送方所使用的端口，目的端口是接收方所使用的端口。当一台主机向另一台主机发送TCP报文时，它随机选择一个未被占用的端口号作为源端口，以便接收方可以发送回响应信息。同样地，接收方也会使用一个随机的未被占用的端口号作为目的端口，以便发送方可以确定响应消息的目标。

在TCP协议中，端口号是一个16位的无符号整数，取值范围是0~65535。其中由0~1023的端口号是保留端口，用于一些系统服务，应用程序不能使用。端口号由1024~65535的范围则是开放的端口，应用程序可随意使用。

总结来说，TCP报文中的端口号是由发送方和接收方在通信建立时各自随机选择的未被占用的端口号。

## 当服务器与客户端建立连接后，服务器端突然断电，客户端会怎样？ `1`


当服务器与客户端建立连接后，如果服务器端突然断电，客户端会因为网络连接中断而失去与服务器端的连接。在这种情况下，客户端应该会立即发出网络异常或连接断开的错误信息，并根据实际情况进行相应的处理。

一般来说，客户端会通过捕获相关的错误码来判断服务器是否断开连接，并进行相应的处理，如重新连接等操作。对于需要保证数据传输安全的业务场景，客户端会对断开连接进行重试，并进行数据的缓存和持久化，以免数据丢失。

## TCP三次握手为什么要用随机初始化的序号 `1`


在TCP三次握手过程中，客户端需要向服务器发起连接请求，该请求必须包含一个随机初始化的序列号（SYN）。该序列号的作用是用于标识客户端和服务器之间的数据，确保数据传输的正确性。

具体来说，在TCP连接建立时，客户端会随机生成一个初始序列号（ISN），并将该序列号作为SYN标志位的数据字段传递给服务器。服务器收到该SYN报文段后，会回复ACK报文段，并生成自己的随机序列号（ISN2），并将其发送给客户端。此时，客户端为了验证服务器的身份，需要回复ACK报文段，并将ISN2+1作为确认号（ACK）返回给服务器。服务器接收到该ACK报文段后，客户端和服务器之间的TCP连接完成建立。

采用随机初始化的序列号能够提高TCP连接的安全性。如果采用固定初始化的序列号，攻击者就有可能使用已知的序列号来欺骗服务器建立连接，从而对服务器进行攻击。

因此，随机初始化的序列号可以防止这种攻击，使TCP连接更加安全。

## TCP中nagle算法及其缺点 `1`


TCP中的Nagle算法（Nagle's algorithm）是一种优化TCP传输过程的算法，其目的是将小的TCP报文段合并成一个较大的报文段进行传输。该算法可以提高传输效率，减轻网络拥塞，但同时也会带来一些缺点。

Nagle算法的主要思想是，当发送方要发送数据时，如果发送的数据量很小，即小于MSS（Maximum Segment Size，最大报文段长度），则该数据不立即发送，而是先缓存起来。当发送方收到之前已经发送的数据的确认后，再将缓存中的数据一并发送出去。这样可以减少网络上的报文段数目，避免网络拥塞，提高传输效率。

然而，Nagle算法也会带来一些缺点：

1. 网络延迟增大：由于Nagle算法需要缓存一定量的数据才开始发送数据，因此对于需要实时传输数据的应用，例如在线游戏、视频会议等，Nagle算法会增加网络延迟，影响服务的响应速度。

2. 小数据包延迟增大：Nagle算法会将小的TCP报文段合并成一个较大的报文段进行发送，但这也就意味着较小的数据包需要等待更长的时间才能被传输出去，从而增加了网络延迟。

3. 低效的流控制：由于发送方需要缓存一定量的数据才开始发送数据，从而导致流量控制机制变得低效。如果接收方的处理能力无法跟上发送方的速度，缓存数据会越来越多，直至耗尽内存，导致网络拥塞。

总之，虽然Nagle算法可以提高TCP传输效率，但也需要根据具体场景进行合理的配置，避免其可能带来的一些负面影响。

## TCP的最大传输长度是多大 `1`


TCP协议的最大传输长度由其底层的网络传输技术和路由器等网络设备的最大传输单元(MTU)共同决定。

在现代网络环境中，常用的网络传输技术包括以太网、Wi-Fi和3G/4G等。它们的MTU大小通常为1500字节，也就是说，TCP协议在这些网络中一次最多能传输1500字节的数据。如果数据的大小超过了这个限制，TCP协议就会进行分片，并分别发送各个分片。

但需要注意的是，TCP协议的分片会增加网络开销和传输延迟，因此尽量避免在传输数据时超过MTU的限制，可以通过数据压缩、分批传输等方式来解决这个问题。此外，在一些特定的网络环境中，MTU可能会更小，这就需要根据具体情况进行调整和优化。

## close-wait出现大量堆积的时机 `1`


Close-Wait状态表示TCP连接的一方已经完成了它的数据发送任务，并接收到对方的FIN ACK，进入到Close-Wait状态等待对方关闭连接。如果该状态长时间存在并且积累过多，可能会导致网络堵塞和资源浪费，因此需要及时处理。

Close-Wait出现大量堆积的时机可能有以下几种原因：

1. 服务器处理客户端请求时，未能正确地关闭连接，导致Close-Wait状态长时间存在。

2. 客户端关闭连接太慢，未能及时发送FIN报文给服务器，导致服务器接收到FIN报文后进入Close-Wait状态，等待客户端关闭连接。

3. 网络延迟，FIN报文丢失或延迟，导致TCP连接进入Close-Wait状态等待超时。

4. 操作系统资源不足，导致TCP连接被阻塞，可能会导致Close-Wait状态出现过多。

解决方法如下：

1. 合理设置TCP连接超时时间，及时关闭TCP连接，防止Close-Wait状态积累过多。

2. 在编写程序时，确保及时关闭TCP连接。

3. 检查网络状态和操作系统资源，减少网络延迟和操作系统负荷。

4. 使用一些工具，例如 TCPView 等监控工具来排查网络连接问题，发现是否存在Close-Wait状态出现大量堆积的情况，及时进行调整。

## TCP快重传如何判断丢失 `1`


TCP快重传是指当发送的数据包被接收方确认时，发送方并没有收到确认信号，此时发送方不会等待重传超时时间，而是立即重传该数据包。当快重传被触发时，表明之前发送的数据包有可能已经丢失了。

判断TCP数据包是否丢失通常有两种方式：

1. 超时重传机制：发送方会在发送数据包后启动一个定时器，若在规定时间内未收到接收确认，则认为该数据包丢失并进行重传。但是该机制却存在一定的缺陷，因为根据网络延迟或拥塞情况不同，重传超时时间也不同，如果设置的时间过短，则可能出现不必要的重传；设置过长，会延迟数据的传输效率。

2. 快速恢复机制：该机制是指接收方在收到TCP数据包之后，发送一个重复确认（Duplicate ACK）消息表示已经收到该数据包，但是之前还没有收到自己下次期待的数据包。如果发送方收到3个相同的重复确认，表明之前发送的数据包被接收方重复确认了3次，这个意味着接收方已经收到了最后一个应该接收的数据包，但是中途有数据包丢失，此时发送方会采取快重传机制，立即重传丢失的数据包，然后进入拥塞避免状态。

因此，在一般情况下，TCP快重传是通过快速恢复机制来判断数据包是否丢失，当发送方收到连续的重复确认后立即重传丢失的数据包。

## 页面渲染过程中是否会建立TCP连接 `1`


页面渲染过程中不会建立TCP连接，因为TCP连接是用于在客户端和服务器之间进行数据传输的，而页面渲染的过程主要是发生在客户端（即浏览器）中。当浏览器请求页面资源时，会先通过DNS解析获取服务器的IP地址，然后向该IP地址发送HTTP请求，服务器收到请求后通过HTTP协议响应数据返回给客户端，此过程使用的是已经建立好的TCP连接。在此过程中，TCP连接的建立是在浏览器向服务器发送HTTP请求时完成的，而不是在页面渲染过程中建立的。

## Tcp四次挥手何时断开连接？ `1`


TCP四次挥手是指在TCP连接中，终止方向需要发出终止连接请求，另一方确认收到终止请求后再发送自己的终止请求，最后收到确认终止请求。

具体来说，四次挥手的流程如下：

1. 第一次挥手：终止方向的主机发送一个FIN（终止请求）标志位，请求关闭连接，进入FIN_WAIT_1状态。

2. 第二次挥手：另一方主机收到FIN标志，发送ACK（确认请求）标志位作为回应，进入CLOSE_WAIT状态。

3. 第三次挥手：另一方主机发送一个FIN标志位，请求关闭连接，进入LAST_ACK状态。

4. 第四次挥手：终止方向的主机收到FIN标志位，发送ACK标志位确认，进入TIME_WAIT状态。等待2MSL的时间后，进入CLOSE状态，连接断开。

因此，TCP连接的正常断开是在双方都告知对方自己要关闭的情况下，才会真正关闭连接。其中，需要注意的是TIME_WAIT状态的存在，它是为了确保迟到的报文不会干扰新的连接，可以避免数据包从旧连接到达新连接，造成数据混乱。

## 传输层如何标识进程间通信 `1`


传输层使用端口号标识进程间通信。端口号是一个16位的数字，它唯一地标识了网络上运行的每个应用程序。在传输层协议如TCP或UDP中，每个数据包的源端口和目的端口都被标识出来，以便将数据包正确地传输到目的地。 

例如，在应用程序中，当你使用Web浏览器向Web服务器发送HTTP请求时，Web浏览器使用“80”端口号，而Web服务器使用“8080”端口号来接收并响应请求。如果端口号不正确，那么数据包可能会被发送到错误的地方或被丢弃，导致通信失败。因此，端口号是网络通信中非常重要的一部分，它确保了正确的数据传输和通信的稳定性。

## TCP是怎么判断丢包的？ `1`


TCP（传输控制协议）使用序号和确认应答来判断丢包。

- 序号：在数据传输中，每个TCP报文段都会携带一个唯一的序号（seq number），用于标识所发数据的顺序。而接收方则会根据序号来确认当前接收到的数据是否是正确的，如果当前接收到的数据的序号不连续，那么就判断为收到了丢失的报文段或重传的报文段。
- 确认应答：当接收方成功接收到数据后，会向发送方回应确认应答（acknowledgment），其中确认应答的序号是上一次成功接收的数据序号+1。如果发送方在等待超时时间内没有接收到确认应答，就认为数据包已经丢失，此时进行重传。

需要注意的是，TCP并不能直接检测出数据包丢失的原因，只能通过序号和确认应答来判断是否丢包，具体丢失的原因需要通过网络协议栈、链路状态等信息进行排查。

## TCP是5元组，UDP是几元组 `1`
TCP 是一个5元组协议，包括源IP地址、源端口、目标IP地址、目标端口、协议类型。这5个元素组成了唯一的网络连接，可以确保数据在不同主机之间的可靠传输。其中，每个网络连接都由唯一的IP地址和端口组成，因此TCP在数据传输之前需要建立连接，协商传输方式。

UDP 是一个2元组协议，只包括源端口和目标端口。它不需要建立连接，也没有确认机制和重传机制，因此传输速度更快，但是可靠性较差。UDP 最常用的应用场景是实时应用，如视频、音频、游戏等，因为这些应用要求即时传输，而对于一些数据丢失或者延迟不敏感。

## TCP头部大小是固定的吗？ `1`
不完全正确。TCP头部包含一些必需的字段（如源端口、目标端口、序列号等），同时也包含一些可选字段（如窗口大小、选项等）。TCP头部的大小取决于它所包含的字段和选项，因为不同的选项有不同的长度。TCP头部的最小大小是20字节，但是如果有选项的话，可以达到最大为60个字节。因此，TCP头部的大小不是固定的，它是根据TCP连接所需的字段和选项而变化的。

## 如果晚上0点有大量请求，如何区分恶意与善意请求？ `1`


在晚上0点有大量请求，如何区分恶意与善意请求，这是一个网络安全问题。

一些可能的区分方法如下：

1. IP地址：查看请求的IP地址，如果有多个相同的IP地址，可能是一个恶意攻击或者僵尸网络。还可以使用黑名单机制来拦截被发现的恶意IP地址，这样可以防止它们再次发出请求。

2. 请求的速率：如果同时有大量的请求，且请求的速率非常快，那么很可能是一个恶意攻击，正常请求的速度相对较慢。因此可以通过限制每个IP地址的请求速率来避免这种攻击。

3. 请求的内容：分析请求的内容以及请求的来源，如果有大量来自同一来源的请求，那么就可能是一次恶意攻击。可以通过分析请求的关键字来判断是否是垃圾请求。

需要注意的是，在实际操作中，应该综合多种方法来判断每个请求的类型，同时还应该考虑可能的误判率。如果有成本可以考虑调用一些第三方的服务商做这件事情。

## 简述黑客攻击某个主机的方法与过程 `1`


黑客攻击某个主机的方法和过程是多种多样的，以下是一般情况下的攻击方式和过程：

1. 识别目标：黑客通常会先探测目标的 IP 地址、开放的端口、操作系统和服务等信息。这可以通过网络扫描工具、在线搜索引擎和信息收集等方式获取。

2. 收集漏洞信息：黑客会利用自动化工具或手工的方式寻找系统或服务中存在的漏洞，如软件版本过旧、默认密码、配置不当等。这些漏洞可能会被黑客利用来获取 root 访问权限。

3. 利用漏洞进行入侵：当黑客找到漏洞后，他们可以使用漏洞利用程序进行入侵。这些程序能够在目标系统上执行命令、上传、下载和删除文件，甚至在系统内部执行代码，以实现控制目标的目的。

4. 隐藏攻击痕迹：一旦入侵成功，黑客会开始隐藏其攻击痕迹，以尽可能长时间地控制系统。这可能包括删除 log 日志、清除命令历史和隐藏进程等。

5. 扩大攻击面：攻击者可能会利用目标系统上存储的凭据，例如密码和 SSH 密钥等信息，从而深入到内部网络，并攻击其他系统和服务。

6. 维持控制：黑客会尽可能保持在受攻击系统中的控制权，通过植入后门、定时任务等方法，以确保即使系统管理员发现攻击，他们仍能够继续控制目标。

总体而言，黑客攻击主机的过程是非常复杂的。它需要黑客通过各种手段逐步获得对系统的控制权，同时在获得控制权后需要采取措施以隐藏攻击痕迹，并扩大攻击面。因此，对于系统管理员而言，保持系统安全性是至关重要的。

## 网关同时接到10个请求，是并行处理还是串行处理？ `1`


一般来说，网关会采用并行处理的方式来处理同时接到的多个请求。这是因为并行处理能够提高性能和并发能力，缩短响应时间。而串行处理则会影响整体的响应速度和性能。

在并行处理请求时，网关通常会采用多线程或者多进程的方式来实现。这些线程或进程会同时处理不同的请求，以达到并行处理的效果。如果采用多线程的方式，还可以使用线程池技术来更好地管理和利用线程资源，避免不必要的线程创建和销毁开销。

需要注意的是，并行处理也有可能引发一些新问题，比如线程安全、锁竞争、资源竞争等。在设计并行处理系统时，我们需要充分考虑这些问题，保证系统的可靠性和稳定性。

## dns除了能查ip还能查到什么 `1`
DNS（Domain Name System）除了能将域名解析为对应的IP地址，还能查到以下信息：

1. 域名的所有记录类型：除了A记录（将域名解析为IPv4地址）和AAAA记录（将域名解析为IPv6地址）以外，还包括MX记录（指定邮件服务器的地址）、CNAME记录（为域名指定别名）、NS记录（指定该域名的DNS服务器的地址）等。

2. 域名的缓存：DNS服务器会将查询到的域名的IP地址缓存一段时间，以便下次查询时可以快速响应，同时也减轻了DNS的负担。

3. 域名的使用情况：DNS服务器会记录每个域名被查询的次数、查询的来源以及响应的时间等信息，这些信息可以用于域名的管理和优化。

## 列举不同的编码方式，并分析其区别 `1`
在计算机领域中，经常需要将文本、数字、图形等数据转换成二进制码，便于计算机进行存储和处理。编码方式就是将特定数据转换成二进制码的方式。目前常见的编码方式有以下几种：

1. ASCII编码：ASCII是英文字符集编码方式，可以将所有的英文字符、数字、符号等等转换成7位二进制码，最高位为0。缺点是不能表示中文、日语、韩语等非拉丁语系字符。

2. Unicode编码：Unicode是一种国际通用的字符集编码方式，通过多字节的形式，可以表示世界上大部分的语言文字，包括拉丁文、中文、日文、韩文等等。UTF-8、UTF-16等多种不同的编码方式都是Unicode的实现方式。

3. UTF-8编码：UTF-8是Unicode最常用的一种编码方式。UTF-8使用1到4个字节来表示每一个字符。英文字母、数字和常见符号仍然是1个字节，中文通常是3个字节，而一些罕见的字符可能需要4个字节。缺点是相比ASCII编码，编码长度变长，需要更多的存储空间。

4. GBK编码：GBK是中文编码方式，在GB2312（ISO/IEC-646标准的国家扩展标准 GB 2312-80）的基础上扩展而来，能够表示全面的中文字符，包括繁体字。GBK使用2个字节表示每个字符，能够满足中文处理需求。

总之，不同的编码方式有着不同的应用场景和适用范围。对于不同的文本内容和处理需求，需要选择合适的编码方式来表示和处理数据，以保证正确性和高效性。

## URL中的中文字符为什么需要转码 `1`


在URL（Uniform Resource Locator，统一资源定位符）中，每个字符都有特定的含义和作用，用于定位资源和标识访问方式。但是，URL中只支持ASCII字符集，而对于其他字符集（包括中文字符），需要进行编码转换，以便服务器和浏览器正确解析并处理。

URL中的中文字符采用了Unicode字符集，即全球通用的字符编码标准。然而，URL中的字符必须按照特定的编码方式进行转换，才能被服务器和浏览器正确解析。最常用的编码方式是UTF-8，它可以将任意Unicode字符转换成ASCII字符或者其他特定字符集的字符。

因此，将URL中的中文字符进行转码，可以保证其能被服务器和浏览器正确识别并处理，避免出现乱码或错误的路径访问等问题。

## 浏览器内核的组成 `1`
浏览器内核由两个主要组件组成：

1. 渲染引擎：负责解析 HTML、CSS 和 JavaScript，将网页的代码转换成用户所看到的视觉效果。渲染引擎的主要任务是将 HTML 文档中的标记转换成可视化内容，例如对 HTML 标签的解释并将其转换成屏幕上的文本和图像等元素。不同浏览器使用不同的渲染引擎，例如Chrome浏览器使用的是Webkit引擎。

2. JavaScript 引擎：负责解析和执行 JavaScript 代码。JavaScript 引擎会将 JavaScript 代码翻译成计算机能够理解的机器码，并运行这些机器码以实现操作。不同浏览器使用不同的 JavaScript 引擎，例如 Chrome 浏览器使用的是 V8 引擎。

除了上面这两个主要的组件之外，浏览器内核还包括其他组件，如网络协议栈、Cookie 管理器、安全框架等。这些组件一起工作，完成整个页面加载和渲染过程，给用户呈现出最终的页面效果。

## 浏览器如何获取HTML文件并渲染 `1`


浏览器获取HTML文件并渲染的过程可以分为以下几个步骤：

1. DNS解析

在访问特定网站时，浏览器首先需要将该网站的域名解析为IP地址，以便浏览器能够找到该网站的服务器。浏览器会通过DNS查询来完成这个过程。

2. 建立TCP连接

一旦浏览器成功解析域名，它将根据域名获取服务器的IP地址，并建立与服务器的TCP连接。

3. 发送HTTP请求

在建立了TCP连接后，浏览器向服务器发送HTTP请求。该请求告诉服务器浏览器希望获取特定资源（例如HTML文件）的副本。

4. 接收响应

如果服务器认为浏览器有权获得该资源的副本，它将返回该文件作为HTTP响应。该响应通常由HTTP状态码、HTTP头和响应体三部分组成。

5. 渲染页面

一旦浏览器收到HTML文件，它开始解析该文件以构建DOM（文档对象模型）树。然后，浏览器利用CSS和JavaScript等其他资源来构建渲染树，并根据此渲染树来显示页面内容。

6. 关闭TCP连接

一旦浏览器成功获取并渲染页面，它将通过TCP连接发送连接释放信号，从而关闭与服务器之间的连接。

以上就是浏览器获取HTML文件并渲染的基本过程。

## 抖音直播用的什么协议？ `1`
抖音直播使用的是RTMP协议。RTMP是Real-Time Messaging Protocol的缩写，是一种用于传输音频、视频等流媒体数据的协议，由Adobe公司开发，主要用于Flash播放器与服务器之间的音视频通信。

在抖音直播中，主播端使用抖音App进行直播，推流到RTMP服务器端口，用户端通过抖音App观看直播，通过RTMP协议从服务器端口拉流，完成直播过程。

## 浏览器的缓存策略（强缓存和协商缓存） `1`


浏览器的缓存策略是指在用户请求一个页面时，浏览器如何决定是否需要从服务器获取新数据或者使用缓存数据。常用的缓存策略包括强缓存和协商缓存。

1. 强缓存

当强缓存生效时，浏览器不会向服务器发送请求，而是直接从本地缓存中获取数据。强缓存可以通过设置HTTP响应头中的`Cache-Control`和`Expires`字段来控制。

`Cache-Control`的值可以是以下几种：

- no-cache：表示用户端每次请求都要向服务器发送请求，即不使用本地缓存。
- no-store：禁止浏览器缓存响应，每次都会向服务器请求响应。
- public：指定响应比较适合被公共缓存，可以被任何中间节点（如CDN）缓存。
- private：指定响应只能被单个用户缓存，中间节点不能缓存。
- max-age：指定缓存时间，单位为秒。如`max-age=3600`表示缓存1小时。

`Expires`指定响应过期时间，是一个绝对时间。如`Expires: Tue, 28 Sep 2021 14:12:30 GMT`表示响应在该时间后过期。

2. 协商缓存

当浏览器向服务器发送请求时，如果强缓存失效，服务器会根据请求头中的`If-Modified-Since`和`If-None-Match`字段，来判断是否需要重新发送数据。这种缓存策略叫做协商缓存。

如果服务器判断数据未发生变化，则会返回一个`304 Not Modified`响应码，告诉浏览器可以继续使用缓存数据。否则，服务器返回新的数据，并更新缓存。

`If-Modified-Since`表示上一次响应的修改时间，如`If-Modified-Since: Fri, 03 Sep 2021 09:18:21 GMT`。

`If-None-Match`表示响应的唯一标识符，如`If-None-Match: "etagvalue"`。

协商缓存的实现需要服务器的支持，需要在响应头中包含`Last-Modified`和`ETag`字段，分别表示响应修改时间和唯一标识符。

## Session是什么？什么时候消失？ `1`


Session是指在服务器端存储的一个数据结构，用于维护用户的登录状态、使用过程中的数据等信息。HTTP协议是无状态的，因此客户端每次与服务器交互时都需要重新发送身份认证等信息。为了解决这个问题，Web应用程序通常会在客户端完成身份认证后为其生成一个Session ID，并将Session ID存储在客户端的Cookie中。之后客户端每次与服务器交互时，会将Cookie中的Session ID发送至服务器，服务器通过该ID找到对应的Session数据，从而实现状态维护。

Session通常在以下情况下会消失：

1.超时：服务器通常会为Session设置一个超时时间，如果超过这个时间，该Session将被销毁。

2.手动销毁：在某些情况下，应用程序可能需要手动销毁Session，以释放资源或保障安全。

3.修改Session ID：当需要修改Session ID时，旧的Session将会被销毁，新的Session将会被创建。这通常发生在用户登录时，为了避免Session劫持等安全问题。

4.浏览器关闭：当用户关闭浏览器时，浏览器通常会删除与之相关的Cookie信息，从而导致Session ID失效。

## 售票系统里用的什么协议？ `1`
售票系统通常会使用HTTP协议来进行客户端和服务器之间的通信。HTTP是一种基于请求-响应模式的协议，客户端发送请求给服务器，服务器接收并处理请求后返回响应给客户端。在售票系统中，客户端通过HTTP请求购票或查询票务信息，服务器接收并处理请求后返回相应结果。此外，售票系统还可能涉及到支付交易，这时会使用HTTPS协议来进行加密传输保障交易安全。

## 如何设计一个应用协议 `1`


设计一个应用协议通常包括以下步骤：确定需求、制定协议格式、制定通信规则和协议实现。

1. 确定需求

首先需要明确应用协议的目的和需求，例如协议的功能、数据传输方式、数据格式、数据安全机制等。

2. 制定协议格式

根据需求制定协议格式，包括请求消息和响应消息格式、消息头信息、消息体信息等。

3. 制定通信规则

确定协议的通信规则，例如请求消息的响应时间规定、通信数据流向、数据传输方式（同步或异步）、重发机制（定时重发、确认重发、滑动窗口重发）等。

4. 协议实现

根据制定的格式和规则实现应用协议，主要涉及编程技术和网络通信知识。

在实现应用协议时，需要注意以下问题：

1.数据安全和可靠性：在协议设计过程中，需要考虑到通信数据的安全性和可靠性，例如数据加密、身份验证、数据完整性检验等。

2.可扩展性：协议应该具有很好的可扩展性，能够灵活地应对新的需求和变化。

3.易用性：协议应该设计得易于使用和理解，避免繁琐的设置和使用方法。

总的来说，设计一个好的应用协议需要综合考虑需求、格式、规则和实现等多方面因素，并根据实际情况灵活调整。

## 如何断点续传？ `1`


断点续传是指在文件传输过程中，如果传输中断了，可以利用已经传输好的部分继续进行传输，从而大大提高文件传输的效率和稳定性。以下是基本的断点续传的流程：

1.客户端首先向服务器发送GET请求，并且在HTTP头中以Range头域指定需要传输的文件内容区间。

2.如果服务器支持断点续传，那么将返回HTTP 206 Partial Content状态码，并在HTTP头中以Content-Range头域返回已经传输的数据区间和整个文件的大小等信息。

3.客户端接收到服务器返回的HTTP 206 Partial Content状态码，首先获取到已经传输的数据长度，计算出下一次需要传输的数据区间，然后向服务器发送GET请求。

4.服务器收到请求后，从上次传输的数据长度位置开始向客户端传输文件数据。

5.客户端接收到文件数据后，将数据写入到本地文件中，并且发送下一次GET请求，直到传输完整个文件。

需要注意的是，在进行断点续传的时候，客户端和服务器之间需要保持一定的状态信息，例如已经传输的数据长度等。因此，在实现断点续传的时候，我们通常会使用Cookie或者Session等技术来维护状态信息。

## HTTP无状态，如何标注用户身份 `1`


HTTP是一种无状态协议，指的是每个HTTP请求之间是相互独立的，服务器不能从一个请求中知道关于用户的任何信息，也不能将一个请求与另一个请求关联起来。因此，为了标识用户身份，需要采用一些额外的机制。

一些可行的身份标识方式包括：

1. Cookie：Cookie是一种存储在客户端的小型数据文件。当客户端向服务器发送请求时，该客户端的Cookie也随着请求一同发送。服务器通过读取Cookie中存储的信息来确定用户身份。

2. Session：Session是一种服务器端的机制，它能够在多个请求之间保持用户信息。服务器生成一个唯一的Session ID（会话ID），并将该ID存储在Cookie中发送给客户端。当客户端向服务器发送请求时，服务器会读取该请求中的Session ID，并检查该ID对应的用户信息。

3. Token：Token是一种相对较新的身份认证方式，它通常使用JSON Web Token（JWT）格式储存。Token的生成和传输过程相对简单，只需要将Token附加在请求头中即可。服务器通过读取请求头中的Token来确定用户身份。

总体来说，这些方式都使用了一些附加机制来标识用户身份。具体采用哪种方式还需要根据实际情况进行选择。

## POST 有哪几种编码方式 `1`


POST 是 HTTP 协议中一种常见的请求方式，一般用于向服务器提交数据。POST 请求中可以使用多种编码方式，包括以下几种：

1. application/x-www-form-urlencoded 编码方式：
在这种编码方式下，POST 请求中的参数会被编码成键值对的形式，并且 key 和 value 之间用等号 ( = ) 连接，不同键值对之间用 & 符号连接。例如，下面是一个使用了 x-www-form-urlencoded 编码方式的 POST 请求示例：
```POST /login HTTP/1.1
Host: example.com
Content-Type: application/x-www-form-urlencoded
username=admin&password=123456```

2. multipart/form-data 编码方式：
这种编码方式常用于文件上传，它将每个表单元素分别编码，并且在相应的边界处进行分隔。在 multipart/form-data 编码方式下，每个表单元素由表单元素的名称和对应的值构成，对应的值可以是文件流或普通文本。例如，下面是一个使用了 multipart/form-data 编码方式的 POST 请求示例：
```
POST /upload HTTP/1.1
Host: example.com
Content-Type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW

------WebKitFormBoundary7MA4YWxkTrZu0gW
Content-Disposition: form-data; name="file"; filename="example.jpg"
Content-Type: image/jpeg

[文件流]

------WebKitFormBoundary7MA4YWxkTrZu0gW
Content-Disposition: form-data; name="description"

这是一张图片
------WebKitFormBoundary7MA4YWxkTrZu0gW--
```

3. application/json 编码方式：
这种编码方式常用于将 JSON 数据提交到服务器。在这种编码方式下，POST 请求的正文是一个 JSON 对象，并且 Content-Type 头部字段的值为 application/json。例如，下面是一个使用了 application/json 编码方式的 POST 请求示例：
```POST /api/create-user HTTP/1.1
Host: example.com
Content-Type: application/json

{
  "name": "test",
  "age": 20,
  "email": "test@example.com"
}
```

## Https建立连接时服务器返回的证书的内容 `1`


当客户端尝试连接https网站时，服务器会返回一个数字证书，用于建立安全连接。该数字证书是由证书颁发机构（CA）签发的，其中包含以下信息：

1. 证书颁发机构信息（CA）

证书中包含颁发该证书的机构的名称和公钥。当客户端收到证书时，会使用证书颁发机构的公钥来验证该证书的合法性。

2. 证书持有人信息

证书中包含持有人的名称和公钥。客户端使用该公钥来建立安全连接。

3. 证书有效期

证书包含有效期开始和结束的时间。如果证书在有效期内，则它是可信的。

4. 数字签名

证书必须被签名，以确保证书的真实性和完整性。当证书被签发时，颁发CA会使用自己的私钥对证书进行数字签名。客户端使用颁发CA的公钥来验证签名的真实性。

5. 证书扩展信息

证书可能包含一些扩展，例如额外的CA信息、使用扩展密钥用于特定目的等。

客户端使用证书中的信息来验证服务器的身份和建立安全连接。如果证书无效或不受信任，则建立连接会失败。

## Http1.1线头阻塞问题 `1`


在HTTP1.1协议中，每个请求/响应都需要使用到线头（header）来传递相关信息，例如请求/响应的数据类型、长度、缓存控制、身份验证等等。线头的长度往往比较长，而且每个请求/响应都需要发送一个完整的线头，这就导致了一个问题：当一个请求/响应正在传输线头时，后续的请求/响应必须等待前面的线头传输完成才能开始发送，从而导致了阻塞。

具体来说，假设我们有一个包含4个请求的HTTP请求队列，它们的线头分别为A、B、C和D。下图展示了在HTTP1.1中可能出现的线头阻塞情况。

![http1_1_blocked](https://user-images.githubusercontent.com/45757422/122414097-7c2b5880-cfd3-11eb-8f2d-c15fd28fee38.png)

从上图可以看出，当第1个请求（即A）提交后，服务器开始传输线头并处理相应的请求。但由于线头传输所需时间较长，后续的请求（B、C和D）都必须等待前面的请求线头传输完成才能发送。这就导致了阻塞，即其他请求被迫等待，从而影响了整个请求队列的响应时间。

为了解决线头阻塞问题，HTTP2.0采用了二进制格式传输数据，并采用了多路复用技术，即在同一个连接上可以同时传输多个请求和响应，从而避免了HTTP1.1中的线头阻塞问题。

## 请求页面的资源分布在不同服务器，
需要建立几次Http和TCP连接？ `1`


如果一个页面的资源分布在不同服务器上，那么在客户端请求这个页面的过程中，需要建立多个HTTP和TCP连接。每一个请求资源的服务器都需要建立一次Http和TCP连接。例如，如果一个网页包含了10张图片，这些图片分别存储在不同的服务器上，那么客户端请求这个网页时需要建立11次Http和TCP连接。其中，一次是请求网页本身的连接，其余10次是分别请求每张图片的连接。 

需要注意的是，对于HTTP/1.1协议的浏览器来说，可以使用持久连接来重复利用同一个TCP连接请求多个资源，从而减少建立连接的开销，提高效率。但对于HTTP/1.0协议的浏览器，每个资源请求都需要建立一个新的TCP连接。此外，对于一些现代化的浏览器，还会对请求进行优化，如DNS缓存等，从而进一步减少HTTP和TCP连接的次数。

## Http的缺点 `1`


HTTP（超文本传输协议）是一种用于传输数据的协议，它有以下几个缺点：

1. 无状态：HTTP是一种无状态协议，即每个请求都是独立的，服务器不能在不同请求之间保持状态。这导致无法支持一些应用场景，如在线游戏和购物车等。

2. 安全性差：HTTP协议传输的数据是明文的，容易被截获和窃取，需要使用HTTPS等协议进行加密。

3. 性能问题：HTTP协议在传输大量数据时可能会出现阻塞和延迟，并且每个请求都需要创建和关闭连接，这会消耗系统资源。

4. 可靠性问题：HTTP协议不具备重传机制，即如果一次传输失败，就需要重新发起请求。

5. 端口限制：HTTP默认的端口号是80，如果需要使用其他端口需要在URL中指定，这增加了URL的复杂性。

6. 无法支持多媒体处理：HTTP协议无法直接支持多媒体的处理，需要借助其他协议和技术。

以上就是HTTP的一些缺点。为了解决这些问题，人们开发了HTTP/2协议和一些其他的高级协议和技术，如WebSocket、SPDY和QUIC等。

## 全双工通信和半双工通信的差别 `1`


全双工通信和半双工通信是两种通信方式。

全双工通信是指通信双方可以同时发送和接收数据，犹如两人进行面对面交流，可以同时说话和听取对方的回答。在全双工通信中，数据可以同时双向传输，不需要先等待对方的响应，也不会发生冲突。

半双工通信是指通信双方在同一时间只能发送或接收数据，不像全双工通信可以同时发送和接收数据。犹如两个人通过对讲机交流，必须分别说话和听取对方的回答。在半双工通信中，数据不能同时双向传输，需要进行时间上的分配，不能保证通信的效率。

总的来说，全双工通信比半双工通信更加高效，但是半双工通信在通信距离较远，或是需要节省通信带宽时，也有其应用价值。

## Https如何断定恶意网址 `1`


HTTPS 是一种在计算机网络上进行安全通信的传输协议，它使用了 SSL/TLS 协议来对网络通信进行加密，以保证通信的安全性。但是即使使用了 HTTPS，仍然可能存在恶意网站。以下是几种断定恶意网址的方法：

1. 网站信誉等级评估：可以通过搜索引擎或第三方安全评估网站查询目标网站的信誉等级，了解其是否存在安全问题；

2. SSL/TLS 证书验证：通过查看网站的 SSL/TLS 证书来证明网站身份的合法性。如果证书存在问题，如到期、伪造等，则说明该网站可能不是正常的网站，存在恶意行为；

3. URL 分析：检查 URL 中是否包含可疑字符或词语，如 "login"、"bank"等，这些词语通常是钓鱼网站的重点攻击对象；

4. 远程评估技术：使用远程评估技术扫描目标网站，包括端口扫描、漏洞扫描等，以检查目标网站是否存在安全漏洞，并评估其安全风险；

5. 黑名单监控：使用黑名单监控工具检查目标网站是否在黑名单中，有过恶意行为的网站会被列入黑名单中。

综上，对于 HTTPS 网站，我们还需要对其进行综合性的评估，以判定其是否存在恶意行为。

## Web服务器是如何解析HTTP请求报文 `1`


Web服务器从客户端接收到HTTP请求报文后，需要对其进行解析，以便服务器能够理解请求以及返回对应的响应。解析过程大致包含以下步骤：

1. 首先，服务器需要读取请求报文中的请求行，其包含了请求的方法、请求的URI以及HTTP协议的版本信息。一个典型的请求行如下所示：

   GET /index.html HTTP/1.1

   这个请求行表示客户端发起了一次GET请求来获取URI为/index.html的资源，并使用HTTP/1.1协议通讯。

2. 接着，服务器需要读取请求报文中的请求头，以获取关于请求的更多信息。请求头中主要包含一些元数据，例如Accept、Accept-Language、User-Agent等。其中有些请求头是必要的，例如Host头，而有些则可选。

3. 当读取完请求头后，服务器接着读取请求体（如果有的话）。请求体包含了传输数据，例如对于POST请求，请求体中通常包含了要上传的数据。

4. 当服务器完全读取请求报文后，它将根据请求中指定的URI以及请求方法去匹配对应的处理器，处理器将会对请求进行处理，然后生成响应报文返回给客户端。

以上就是Web服务器解析HTTP请求报文的大致过程，当然每个服务器都可能会有不同的实现方式和细节处理。

## HTTP的get方法如何判断数据传输完毕 `1`


HTTP的get方法在数据传输完毕后会自动关闭连接，通信双方会自动判断数据的传输状态。在HTTP的响应头中，通过Content-Length头部字段可以获取响应体的长度，当客户端接收到的内容长度等于Content-Length字段时，就可以判断数据传输完毕。同时，服务器也可以在响应头中使用Connection: keep-alive字段来指定保持连接，这样客户端就能够持续接收服务器端发回的数据。


同时，客户端也可以通过接收到的数据长度和Content-Length来计算剩余未接收的数据长度，并将其与接下来接收到的数据长度相加，从而判断数据是否传输完毕。另外，客户端还可以根据TCP的超时机制判断数据传输是否完成，当连接被超时销毁时即可判断传输完成。

## 介绍Https中间安全层 `1`


HTTPS中间安全层，也称为TLS（Transport Layer Security）协议。它是一种基于非对称加密技术的应用层协议，主要用于在网络通信过程中提供数据安全保护。

具体来说，HTTPS中间安全层的工作原理是：客户端向服务器发起HTTPS请求时，客户端利用公钥加密服务器需要传输的数据，并将加密后的数据发送给服务器。服务器接收到客户端的请求后，利用私钥解密客户端发送的数据，然后根据请求进行相应的处理，并将各种操作的结果利用公钥加密，并将加密后的结果返回给客户端。客户端接收到服务器返回的数据后利用私钥解密进行解密操作，最终得到数据结果。

在这个过程中，HTTPS中间安全层扮演了重要的角色，它实现了数据的加密、解密和身份验证等功能，同时还可以防止数据在传输过程中被中途窃取或篡改，从而保证了数据的安全性。

总之，HTTPS中间安全层是一种重要保障数据安全的技术，应用广泛，能够在网络通信过程中起到重要的保护作用。

## http3.0解决了http2.0的什么问题 `1`


HTTP/3.0 是基于 UDP 协议来传输数据的，而不是依赖于 TCP 协议，这解决了 HTTP/2.0 的一个主要问题，即 "队头拥塞" 问题。

在 HTTP/2.0 中，多个请求通过同一个 TCP 连接来传输，如果某个请求阻塞了，会导致该 TCP 连接中所有请求的数据都被延迟传输，这种情况被称为 "队头拥塞"。而 HTTP/3.0 的基于 UDP 协议的设计，每个请求都是通过独立的 UDP 数据包进行传输，因此不存在 "队头拥塞" 问题。

此外，HTTP/3.0 还采用了 QUIC 协议，并内建了 TLS 1.3，从而解决了 HTTP/2.0 中的连接建立时 RTT 轻微增加的问题，提高了网络连接速度和安全性。

## 如果现在建立一个tcp连接，是不是对单个文件中所有的外部资源都复用这个连接？ `1`


TCP是一种面向连接的传输层协议，用于在计算机网络中提供可靠的数据传输。在建立TCP连接时，将会建立一个端到端的“虚拟电路”，这个“虚拟电路”可以用于数据的双向传输。

对于一个TCP连接，可以在连接建立之后复用这个连接进行多次数据传输，不必每次都建立新的连接。复用一个连接可以避免频繁建立和断开连接带来的性能开销。

但是，对于外部资源的访问，TCP连接并不一定会复用。比如，在获取网页时，网页中可能包含了很多的图片、CSS文件、JavaScript文件等外部资源，这些资源可能来自不同的服务器，每个资源都需要单独的连接进行访问。此外，HTTP2.0协议有个特性就是可以通过复用TCP连接来并发下载多张图片，以此来提高网页的性能。

因此，是否复用TCP连接取决于具体的应用场景和协议的实现方式。

## 如何判断并开启Http长连接 `1`
HTTP 是一种无状态的请求-响应协议，客户端发出请求，服务器返回响应。默认情况下，每个 HTTP 请求都会建立一个新的连接，发送完请求后立刻关闭，因此 HTTP 请求的时间较短，无法承载大量的高并发访问。为了解决这个问题，HTTP 长连接应运而生。

HTTP 长连接是指在同一个TCP连接上，客户端和服务器之间可以多次交换HTTP请求和响应，直到结束HTTP请求的交互，再关闭TCP连接。HTTP长连接可以减少TCP连接的建立和关闭开销，提高网络传输效率，以及减轻服务器端的负担。

判断长连接是否开启通常有两种方式：

1.查看响应头中是否存在 Connection 字段，并且该字段的值为 "keep-alive"，如下所示：

```
Connection: keep-alive
```

2.查看请求头中是否存在 Connection 字段，并且该字段的值为 "keep-alive"，如下所示：

```
Connection: keep-alive
```

如果上述条件成立，说明该 HTTP 连接是开启了长连接的，否则就是短连接。

如何开启 HTTP 长连接，需要在服务端和客户端分别进行配置。

对于服务端，我们需要在 HTTP 响应头中添加 Connection: keep-alive 字段，如下所示：

```
HTTP/1.1 200 OK
Content-Type: text/html
Connection: keep-alive
```

对于客户端，我们需要在 HTTP 请求头中添加 Connection: keep-alive 字段，如下所示：

```
GET /index.html HTTP/1.1
Host: www.example.com
Connection: keep-alive
```

当客户端和服务端都支持 HTTP 长连接时，服务端会在响应头中添加 Keep-Alive: timeout=15,max=100 字段，其中 timeout 表示连接的超时时间，max 表示在连接超时前，最多可以接收的请求数。

HTTP 长连接的开启可以在一定程度上提高网络传输效率和性能，并有助于应对高并发访问的情况。

## 为什么post要分两次发送 `1`


在 HTTP 协议中，客户端发送 POST 请求时需要在请求头中指定 Content-Length 字段，该字段的值表示请求正文的长度。因此，如果一次性将请求的所有数据都发送到服务器，那么客户端需要先将所有数据写入缓冲区，然后才能计算出正确的 Content-Length 值，此时再将请求正文通过网络发送到服务端。

然而，在实际网络环境中，由于网络的不稳定性和延迟性，可能会出现以下情况：

1. 客户端发送请求正文造成的网络传输延迟；
2. 服务端在接收请求时出现的网络延迟。

以上情况可能导致请求正文无法在一次传输中到达服务端，导致服务端无法正确解析请求数据，从而造成请求失败。

为了避免以上问题，一般会将 POST 请求分为两次发送，即先发送请求头和部分请求正文，然后通过读取服务端返回的响应信息中的 Content-Length 字段计算出剩余的请求正文长度，再发送剩余的请求正文。这样就能保证请求正文不会被拆分，并且可以准确计算出 Content-Length 字段的值，确保数据能够正确地被服务端接收处理。

## HTTPS怎么保证数据安全 `1`


HTTPS是一种安全的超文本传输协议，它在HTTP协议的基础上加入了SSL/TLS协议提供了加密和认证的安全机制，主要通过以下两种方式来保障数据安全：

1. 数据加密

HTTPS通过使用SSL/TLS协议对数据进行加密。数据在传输过程中经过加密处理，黑客即使截获了数据也难以解密，这样可以保证用户隐私不被非法获取。

2. 身份认证

HTTPS使用数字证书进行身份认证，数字证书是一种由可信第三方机构颁发的数据文件，用于证明网站的身份，可以防止黑客伪造网站进行钓鱼欺诈等活动。只要数字证书有效，用户就可以放心地信任该网站，保证数据不会被中间人窃取。

同时，HTTPS还有以下优点：

1. 数据完整性

HTTPS通过使用消息摘要算法对数据进行完整性检测，防止数据在传输过程中被篡改。

2. 可信任的第三方机构

HTTPS中使用的数字证书可以由被大家广泛信任的第三方机构颁发，保证了数字证书的真实性和可信度，有效地防止了黑客伪造数字证书进行恶意攻击的可能。

总而言之，HTTPS通过数据加密和身份认证等手段实现了对数据的保护，使得数据在传输过程中不容易被黑客窃取或篡改，为用户的网络安全提供了可靠保障。

## 如何改善https构建请求速度慢的情况 `1`


HTTPS协议因为加密解密等过程，相较于HTTP协议，构建请求速度确实会慢一些。但是，可以通过以下几个方面改善HTTPS构建请求速度慢的情况：

1. 合理配置SSL加速器：由于HTTPS协议计算密集，可以使用SSL加速器将重载任务卸载到专门的加速硬件上，以提高请求的处理速度。

2. 利用SSL会话缓存：在SSL握手过程中，服务器和客户端每个握手过程均需要进行数学运算。但是，可以通过保存每次的SSL会话缓存，以便在后续的对话中快速处理请求，减少加密负荷和服务器负载。

3. 减少证书链的长度：尽可能选择SSL证书链更短的SSL证书来减少相关计算和添加证书的时间。

4. 部署CDN网络：如果部署了全球性的CDN网络，可以将SSL证书部署在CDN上，从而实现SSL带宽、加密运算等工作在CDN节点上的负载均衡处理。

5. 减少HTTPS资源的数量：减少使用HTTPS请求的数量，例如通过合并CSS文件和JavaScript文件等静态资源，以减少HTTPS的请求次数和带宽负荷，从而提升请求速度。

总之，不同的网站可能需要采取不同的措施来提高HTTPS请求速度，需要根据实际情况选择合适的方案来实现。

## 503，504错误原因是什么 `1`


HTTP协议中，状态码是一种表示网站服务器响应状态的3位数字代码。其中5xx类的状态码都代表着服务器端出现错误，无法正常处理客户端请求。其中503和504错误是比较常见的，下面分别对它们进行解释。

503错误代表“Service Unavailable（服务不可用）”，表示服务器当前无法处理客户端请求，通常是由于服务器过载或正在进行维护等原因导致的。常见的原因包括服务器硬件故障、数据库异常、网络拥堵等。此时客户端可以尝试稍后再次请求，或与网站管理员联系以解决问题。

504错误代表“Gateway Timeout（网关超时）”，通常是客户端向服务器发起请求后，在规定的时间内未收到响应。这个问题原因一般是服务器没有及时响应，或者是客户端没有等待足够长的时间，就再次发出请求导致问题。此时客户端可以尝试减少请求次数，增加请求等待时间等等，以便更好地处理问题。

无论是503错误还是504错误，都是服务器端出现故障所带来的结果。客户端可以尝试重新请求，或与网站管理员联系以解决问题。

## 502错误一般什么原因导致？如何排查 `1`


502错误是HTTP状态码之一，表示网关错误，通常发生在客户端通过代理服务器访问后端服务器时，代理服务器无法从后端服务器获得有效响应。

这种错误可能由多种原因引起，以下是一些常见的原因：

1. 后端服务器宕机或未启动；
2. 后端服务器响应时间过长；
3. 代理服务器配置错误；
4. 网络问题。

要排查502错误，可以采取以下步骤：

1. 确定是否存在后端服务器宕机或未启动的情况；
2. 检查后端服务器的日志，确认是否有异常或错误；
3. 检查代理服务器的配置，可能需要修改代理服务器配置；
4. 检查网络连接是否稳定，例如ping后端服务器；
5. 如果以上步骤都没有问题，可以尝试升级代理服务器或更换代理服务器软件。

综上所述，502错误可能由多种原因引起，需要仔细排查才能确定具体原因，常见的排查步骤包括确定后端服务器状态、检查服务器日志、检查代理服务器配置、检查网络连接等。

## Socket建立连接时的工作流程 `1`


Socket 是一种常见的网络通信协议，它可以让计算机程序之间通信，实现数据传输和交换。建立 Socket 连接时的工作流程如下：

1. 服务器端在调用 `socket()` 函数创建套接字后，会使用 `bind()` 函数将 IP 地址和端口号绑定到套接字上。

2. 服务器端在绑定好套接字后，使用 `listen()` 函数使套接字处于监听状态，等待客户端连接。

3. 客户端通过 `socket()` 函数创建套接字，并使用 `connect()` 函数向服务器发起连接请求。

4. 服务器如果接收到客户端发来的连接请求，使用 `accept()` 函数接受连接请求，创建一个新的套接字来处理该连接，并返回新套接字的文件描述符给客户端。

5. 客户端成功连接后，可以开始进行数据传输。服务器和客户端之间可以使用 `send()` 和 `recv()` 函数进行数据传输，直到某一方调用 `close()` 函数关闭套接字，连接结束。

总体来说，Socket 建立连接的流程可以归纳为以下几个步骤：创建套接字，绑定地址和端口号，监听连接请求，发起连接请求，接受连接请求，进行数据传输。

## websocket 和传统的http的区别 `1`


WebSocket是一种强大的协议，可以在Web客户端和服务器之间建立长时间的、双向通信的连接，而传统的HTTP是一种无状态协议，每次请求都需要建立一个新的连接。

具体来说，以下是WebSocket和HTTP的区别：

1. 建立连接方式不同

在HTTP中，客户端通过发送HTTP请求来连接服务器，服务器返回HTTP响应。接下来，客户端和服务端之间就没有任何通讯了。而在WebSocket中，客户端首先发送一个特殊的HTTP请求以启动连接，然后服务器回复一个协议升级响应。之后，客户端和服务器之间的通信就使用了WebSocket协议进行。

2. 通讯方式不同

Http协议的数据传输是单向的，从客户端传输到服务器端；而WebSocket支持服务器端和客户端之间的双向通讯，可以在任何时间发送消息。这样实现了真正意义上的实时通讯。在WebSocket中，客户端和服务端可以随时互相发送消息。

3. 发送数据格式不同

Http协议虽然可以发送任意数据类型，但需要在消息体里传输数据。而Websocket不仅可以发送文本消息，也可以发送二进制数据（如文件）。

4. 实时性和效率

在Http中，需要不断地发送请求和接收响应才能获取数据，流程繁琐且效率低下。而在Websocket中，只需要建立一次连接，数据传输更快更实时。

因此，WebSocket比HTTP更加适用于实时通讯、在线游戏/直播等场景。

## RPC框架如何实现监控上报 `1`
RPC（Remote Procedure Call）框架的监控上报，通常分为两种形式：主动上报和被动上报。

在主动上报中，RPC框架会定时或者根据一定条件上报当前系统的运行情况。例如，可以通过定时任务或者信号量的方式，定时统计RPC框架的运行情况，将统计结果上报给监控系统。这种方式相对简单，但会增加系统的负担。

被动上报方式则是在系统发生异常或者错误等情况下自动上报。例如，当服务调用出错或者响应时间较长时，RPC框架会自动上报服务调用信息，从而帮助运维人员及时发现问题并进行相应的处理。这种方式相对比较复杂，但更加精准和有效。

在实现RPC框架的监控上报时，一般会使用一些专业的监控工具，例如Prometheus、Grafana等，这些工具可以提供完善的数据分析和可视化，帮助运维人员更好地监控和管理RPC框架的运行情况。另外，为了保证监控上报的可靠性和稳定性，还需要注意一些运维方面的规范和要求，例如分布式锁、数据备份等。

## RPC框架的应用场景 `1`
RPC（Remote Procedure Call）框架是一种通信协议，用于在分布式系统中不同的进程或服务器之间进行远程过程调用。RPC框架的应用场景如下：

1. 分布式系统：在分布式系统中，不同的服务器之间需要通过RPC框架进行通讯。例如，一个电商系统可以将订单服务、库存服务、支付服务等模块分别部署在不同的服务器上，这些模块之间需要进行远程调用，这时可以使用RPC框架来实现。

2. 微服务架构：RPC框架是微服务架构中实现微服务间通讯的常用方式。微服务架构将一个大型应用拆分为多个小型服务，每个服务都是一个独立的进程，它们之间需要通过RPC框架进行通讯。

3. 负载均衡：RPC框架可以与负载均衡器整合使用，使得对于一个请求，负载均衡器可以根据负载情况分配到最合适的服务器上，提高系统的吞吐量和性能。

4. 高并发场景：在高并发场景下，单个服务可能会出现瓶颈问题，需要将服务水平拆分成多个节点，通过RPC框架进行协同处理。

总的来说，RPC框架在分布式系统、微服务架构、负载均衡、高并发场景等方面拥有广泛的应用。

## RPC如何进行路由寻址 `1`


RPC（Remote Procedure Call，远程过程调用）框架是一种常用的分布式应用架构模式，其中路由寻址是一项重要的功能。

在RPC系统中，路由寻址是指根据请求消息的目标地址和服务标识，将请求消息发送到正确的服务提供者节点。路由寻址通常由一个中心化的服务注册与发现机制实现，例如Zookeeper、Consul等。

以下是RPC的路由寻址的一般流程：

1. 当客户端发起请求时，请求中包含了目标服务的名称和方法名，这些信息被称为服务标识。

2. RPC框架通过查询注册中心，获取目标服务的地址。如果是负载均衡的RPC框架，可能会获取多个服务提供者节点的地址，并根据负载均衡策略选择其中一个节点。

3. 如果目标服务有多个实例，那么RPC框架会选择一个通信通道，可以用来与服务实例进行通信，这个通信通道可以是连接池。

4. RPC框架将请求消息打包，并使用所选的通信通道将请求消息发送给服务实例。

5. 服务实例接收到请求后，进行方法调用，并将结果返回给RPC框架。RPC框架将结果封装成响应消息，并将响应消息发送会客户端。

需要注意的是，路由寻址是一项比较耗时的操作，它会占用一定的系统资源。因此，对于高流量的系统，我们需要使用一些高效的路由寻址算法，避免成为系统的瓶颈。

## Dubbo如何实现一致性哈希 `1`


Dubbo实现一致性哈希主要分为以下几个步骤：

1. 确定哈希函数

Dubbo使用的哈希函数有两种，分别是一致性哈希（ConsistentHashLoadBalance）和基于IP地址的哈希（IpHashLoadBalance）。一致性哈希会根据每台机器的哈希值，将服务提供者的地址映射到环上，而基于IP地址的哈希则使用IP地址计算出一个哈希值。

2. 构建环

通过哈希函数，将服务提供者的地址映射到一个环上，每个服务提供者的地址对应环上的一个节点。环的大小一般取一个比较大的质数，比如231。

3. 查找服务提供者

当消费者需要访问某个服务提供者时，会根据负载均衡策略选择一个节点，再根据某个具体的哈希函数算出一个哈希值。然后在环上顺时针查找离这个哈希值最近的一个节点，这个节点则对应着服务提供者的地址。

4. 节点增加或删除

如果有新的服务提供者加入或者某个服务提供者宕机，则会改变环的大小。当节点增加时，需要重新计算每个服务提供者地址的哈希值，并将新的节点插入到环上。当节点删除时，需要将该节点从环上移除，然后重新计算每个服务提供者地址的哈希值。

总的来说，Dubbo实现一致性哈希的原理和其他一致性哈希的实现原理相似，但是在具体实现过程中，Dubbo会自定义哈希函数和环的大小，并根据实际情况灵活调整节点的增加和删除。

## RPC服务注销需考虑问题 `1`


RPC (Remote Procedure Call) 是分布式系统中常用的一种通信方式，它可以使得不在同一个进程或者不在同一台计算机上的程序之间互相调用，从而提高了系统的可扩展性和协作性。

当一个 RPC 服务需要下线（注销）时，需要考虑以下问题：

1. 连接的断开：RPC 服务在启动时会监听某个端口，客户端通过该端口建立连接并调用服务。在注销服务时，需要保证已有的连接能够正确地关闭，以免给客户端带来负面影响。 

2. 请求的处理：如果一个客户端在服务下线之前发出了RPC请求，那么服务需要保证该请求可以得到正确的响应，因为客户端可能会在请求完成之前关闭连接。

3. 服务的可用性：当服务下线时，需要考虑它所提供的服务是否可以暂时替代。例如，可以通过备份服务来保证某个服务下线后数据的可用性。

4. 数据一致性：如果 RPC 服务在下线前存在未完成的事务，则需要保证这些事务能够正确地完成，以避免数据不一致的情况发生。

5. 其他相关服务的影响：当一个 RPC 服务下线时，会对其他与之关联的服务产生影响，在注销服务时需要确保这些服务不会受到过大的干扰。

## 如何处理服务不能调用的情况 `1`


服务不能调用的情况一般是由于网络故障、服务端宕机、资源不足等问题导致的。为了解决此类问题，我们可以采取以下措施：

1. 异常处理机制：在程序设计上，应该实现异常处理机制，对服务调用失败时进行处理。例如，捕捉异常并记录日志，返回友好提示信息给用户等。

2. 重试机制：对于一些应用场景不是特别严格的服务，我们可以采取重试机制，即在服务调用失败时，自动重试调用服务。重试的次数可以根据具体需求来设定。

3. 容灾机制：在系统设计上，可以采取容灾机制，即将服务部署在多台服务器上，并在出现故障时自动切换到备份服务器。还可以采用负载均衡的方式，将服务请求均衡地分配到多个服务器上，避免单机资源耗尽。

4. 监控系统：可以采用监控系统来实时监控服务的运行状态，及时发现问题并进行处理。监控系统可以通过收集日志、指标数据等方式来进行实现。

5. 自动化故障恢复：可以采用自动化故障恢复技术，在服务出现故障时，能够自动进行恢复操作。例如，自动重启服务、自动切换到备份服务器等。这些操作都可以通过脚本或自动化工具来实现。

## RPC如何实现请求解析映射 `1`


RPC（Remote Procedure Call）是一种通过网络从远程计算机上请求服务或调用函数的协议。RPC的基本原理是将函数调用的过程封装成一个网络通信过程，客户端通过协议传递请求给服务器端，服务器端执行该请求并将结果返回给客户端。而请求解析映射，是实现RPC的重要步骤之一。

下面简单介绍一下RPC的请求解析映射实现：

1. 客户端发出请求：首先，客户端会根据调用的RPC函数名称、参数等信息构造出一个请求消息，通常使用序列化方式将消息序列化为二进制格式。

2. 网络传输：客户端将请求消息发送到服务器端。消息的传输可以使用TCP、HTTP等协议，要求传输协议稳定可靠。

3. 服务器端接收请求：服务器端接收到客户端传来的请求消息，然后根据消息中的相关信息，将请求解析成相应的函数调用。

4. 函数调用：服务器端执行相应的函数调用，并将执行结果返回给客户端。在函数调用的过程中，可能需要进行读写数据库、访问缓存等操作。

5. 序列化返回值：服务器端返回结果，客户端需要将结果反序列化。

6. 客户端处理结果：客户端接收到服务器返回的结果后，通常需要根据结果进行一些业务逻辑处理，展示给用户或者进行其他操作。

以上就是RPC的请求解析映射实现的基本流程，该过程中涉及到序列化、网络传输、函数调用等技术。为了实现高效、可靠的RPC调用，需要深入理解并熟练应用这些技术。

## 服务节点不稳定，如何避免调用该节点 `1`


当服务节点不稳定时，可以通过以下方式避免调用该节点:

1. 通过负载均衡进行策略性地调度请求，避免过度压力落在某一特定节点上。负载均衡可以采用硬件负载均衡器，也可采用软件负载均衡器。常用的软件负载均衡器包括：Nginx、Apache、HAProxy等。

2. 在最初设计时，就应该考虑到高可用性，并且在设计阶段就部署多节点集群，在各节点之间进行数据同步，避免单点故障；

3. 配置故障转移机制，一旦发现某节点出现问题就会自动切换到备用节点;

4. 做好服务监控，及时发现和定位故障点，进行快速响应和修复。

5. 备份数据，习惯性地进行数据备份，确保数据不会因为节点失效而丢失。

需要注意的是，以上是避免调用失败节点的方法，但是解决故障节点的最终方法则是尽快排除故障点，尽量避免故障的发生。

## 页面上存在上百个请求，如何使用websocket进行优化 `1`


在面对大量请求的情况下，使用 WebSocket 技术可以极大地提高页面的性能和响应速度。以下是利用 WebSocket 进行优化的一些方法：

1. 减少请求次数：将原本需要通过 AJAX 或者后台接口进行轮询的请求，换成使用 WebSocket 一次性完成。这样可以避免过多请求造成的响应延迟和服务器压力增加。

2. 压缩数据量：通过对数据进行压缩和精简，减少 WebSocket 传输的数据量。这样可以缩短传输时间，在保证数据正确性的前提下提高数据的传输速度。

3. 合理利用缓存：对于一些需要频繁更新的数据，可以将其缓存在客户端，当数据发生变化时再通过 WebSocket 进行传输。这种方式可以减少服务器压力和网络传输量。

4. 分布式架构：使用分布式架构可以将服务器负载均衡到多个节点上，减少单点故障，提高系统可靠性和性能。

5. 客户端缓存：利用浏览器自身的缓存机制，将一些静态文件和数据缓存在客户端，减少服务器请求压力和网络传输量。

综上所述，WebSocket 技术可以很好地帮助我们解决大量请求时出现的性能问题，但需要注意合理利用缓存和分布式架构等技术手段。

